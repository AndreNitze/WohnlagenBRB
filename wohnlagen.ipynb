{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e58eeaf9ab328ebb",
   "metadata": {},
   "source": [
    "# Datenvorbereitung\n",
    "Zunächst werden für alle gewünschten Einflussfaktoren die Daten beschafft und in ein CSV-Format mit lat/lon oder GeoJSON-Geoemtry gebracht, sodass zu allen Adressen die gewünschten Eigenschaften vorliegen."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from shapely.geometry import box\n",
    "\n",
    "from helper import load_geocsv, s, clean_index_cols\n",
    "\n",
    "EPSG_4326 = \"EPSG:4326\"\n",
    "\n",
    "# BBOX für Brandenburg an der Havel\n",
    "CITY_BOUNDING_BOX = box(12.3120236786, 52.2938432979, 12.7562682548, 52.5594777244)\n",
    "\n",
    "#  Stadtzentrum für Brandenburg an der Havel\n",
    "CITY_CENTER = (52.4116351153561, 12.556331280534392)"
   ],
   "id": "c50d60922d6f74cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Adressen einlesen\n",
    "Alle Adressen des Zielgebiets als CSV in einen GeoDataFrame einlesen."
   ],
   "id": "5112fadb5098e98"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gdf = load_geocsv(\"out/adressen_mit_zentrum_routen.csv\")\n",
    "\n",
    "# Adressen ohne Geometrie entfernen\n",
    "gdf = gdf[~gdf.geometry.isna()].copy()"
   ],
   "id": "ef79a64303652c4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Nutzungsart als Merkmal ergänzen\n",
    "One-Hot-Encoding für spätere Modellierung der Bebauungsdichte / Nutzungsart der Adresse."
   ],
   "id": "fe2c80156cb02d38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "gdf_bebauung = gpd.read_file(\"data/Bebauungsdichte/2025_Bebauungsdichte.shp\")\n",
    "gdf_bebauung = gdf_bebauung.to_crs(EPSG_4326)\n",
    "\n",
    "gdf = gpd.sjoin(\n",
    "    gdf,                                    # Punkte\n",
    "    gdf_bebauung[[\"nutzart\", \"geometry\"]],  # Polygone + Nutzungsart\n",
    "    how=\"left\",\n",
    "    predicate=\"within\"                      # point-in-polygon\n",
    ")\n",
    "\n",
    "gdf[\"nutzart\"] = gdf[\"nutzart\"].fillna(\"Unbekannt\")\n"
   ],
   "id": "fe5b562211015fbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mapping = {\n",
    "    \"Wohnbaufläche\": \"Wohnen\",\n",
    "    \"Sport-, Freizeit- und Erholungsfläche\": \"Gruen\",\n",
    "    \"Fläche gemischter Nutzung\": \"Gemischt\",\n",
    "    \"Industrie- und Gewerbefläche\": \"Gewerbe\",\n",
    "    \"Straßenverkehr\": \"Verkehr\",\n",
    "    \"Weg\": \"Verkehr\",\n",
    "    \"Platz\": \"Verkehr\",\n",
    "    \"Friedhof\": \"Gruen\",\n",
    "    \"Wald\": \"Gruen\",\n",
    "    \"Fläche besonderer funktionaler Prägung\": \"Sonstiges\",\n",
    "}\n",
    "\n",
    "# Neues zusammengefasstes Merkmal hinzufügen\n",
    "gdf[\"nutzklasse\"] = gdf[\"nutzart\"].map(mapping).fillna(\"Sonstiges\")\n",
    "\n",
    "# One-Hot-Encoding der Nutzungsklasse für numerische Verarbeitung\n",
    "# neu erzeugen\n",
    "gdf_onehot = pd.get_dummies(gdf[\"nutzklasse\"], prefix=\"nutz\", dtype=int)\n",
    "gdf = gdf.join(gdf_onehot)\n",
    "\n",
    "# Fläche berechnen (in Meter-CRS)\n",
    "gdf_bebauung_m = gdf_bebauung.to_crs(32633)\n",
    "gdf_bebauung[\"area_sqm\"] = gdf_bebauung_m.area\n",
    "\n",
    "# Klassifizierung NACH mapping\n",
    "gdf_bebauung[\"nutzklasse\"] = gdf_bebauung[\"nutzart\"].map(mapping).fillna(\"Sonstiges\")\n",
    "\n",
    "# Filter große Flächen (Schwellwert flexibel)\n",
    "MIN_AREA = 100000\n",
    "gdf_large = gdf_bebauung[gdf_bebauung[\"area_sqm\"] > MIN_AREA].copy()\n",
    "gdf\n"
   ],
   "id": "24f82d6f2ca4b91a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Farben für jede nutzklasse\n",
    "klassen = gdf_large[\"nutzklasse\"].unique()\n",
    "cmap = plt.colormaps[\"Set2\"]\n",
    "colors = {k: mcolors.to_hex(cmap(i / len(klassen))) for i, k in enumerate(klassen)}\n",
    "\n",
    "# Karte initialisieren\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"OpenStreetMap\")\n",
    "\n",
    "# Ein Layer pro Klasse anlegen\n",
    "layer_map = {}\n",
    "for k in klassen:\n",
    "    layer = folium.FeatureGroup(name=f\"Große {k}-Flächen (> {MIN_AREA} m²)\", show=True)\n",
    "    layer_map[k] = layer\n",
    "    m.add_child(layer)\n",
    "\n",
    "# Große Flächen einzeichnen\n",
    "# Transformieren\n",
    "gdf_large_4326 = gdf_large.to_crs(4326)\n",
    "\n",
    "# Vereinfachung (wichtig für Performance!)\n",
    "gdf_large_4326[\"geometry\"] = gdf_large_4326.geometry.simplify(\n",
    "    tolerance=0.0002,  # ~20 m\n",
    "    preserve_topology=True\n",
    ")\n",
    "\n",
    "\n",
    "for _, row in gdf_large_4326.iterrows():\n",
    "    kls = row[\"nutzklasse\"]\n",
    "    layer = layer_map[kls]\n",
    "\n",
    "    folium.GeoJson(\n",
    "        row.geometry,\n",
    "        style_function=lambda x, k=kls: {\n",
    "            'color': 'black',\n",
    "            'weight': 1,\n",
    "            'fillColor': colors[k],\n",
    "            'fillOpacity': 0.6\n",
    "        },\n",
    "        tooltip=folium.Tooltip(\n",
    "            f\"<b>{row['bez']}</b><br>\"\n",
    "            f\"{kls}<br>\"\n",
    "            f\"Fläche: {row['area_sqm']:.0f} m²\"\n",
    "        )\n",
    "    ).add_to(layer)\n",
    "\n",
    "# LayerControl aktivieren\n",
    "folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "# open map in browser\n",
    "m"
   ],
   "id": "bf01154dea7a2cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Explorative Datenanalyse",
   "id": "d082da0d61c0f1d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns           # nur für schönere Plots\n",
    "from helper import load_geocsv, make_merge_addr\n",
    "\n",
    "# Eindeutigen Merge-baren String aus Adresse erzeugen\n",
    "gdf[\"Adresse_merge\"] = gdf.apply(make_merge_addr, axis=1)\n",
    "\n",
    "gdf = gdf.rename(columns={\"geojson\": \"center_route\",\n",
    "                                    \"distance_m\" : \"center_distance_m\"})\n",
    "\n",
    "# Ein paar unbenötigte Spalten entfernen\n",
    "gdf = gdf.drop(columns=[\"index_right\", \"duration_s\", \"display_name\", \"type\", \"category\", \"Adresse_query\"], errors=\"ignore\")\n",
    "\n",
    "# Histogramm der Distanzen zum Zentrum\n",
    "plt.figure(figsize=(6,3))\n",
    "sns.histplot(gdf[\"center_distance_m\"], bins=60, kde=False)\n",
    "plt.title(\"Verteilung der Fußentfernung zum Zentrum\")\n",
    "plt.xlabel(\"Distanz (Meter)\")\n",
    "plt.ylabel(\"Häufigkeit\")\n",
    "plt.show()\n",
    "print(gdf.shape)\n",
    "print(gdf.columns)"
   ],
   "id": "de62fa81b281925b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Daten bereinigen",
   "id": "f14dc6214657a08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(gdf.shape)\n",
    "# Dubletten aus Adressen entfernen\n",
    "dups = gdf[\"Adresse_merge\"].value_counts()\n",
    "dups = dups[dups > 1]\n",
    "print(f\"{len(dups)} doppelte Adressen gefunden\")\n",
    "print(dups.head())\n",
    "\n",
    "# Ersten Treffer behalten\n",
    "gdf = gdf.sort_values(\"Adresse_merge\").drop_duplicates(\"Adresse_merge\", keep=\"first\")\n",
    "print(gdf.shape)\n"
   ],
   "id": "af2201946c11980d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Einzelhandel\n",
    "Separates Skript ```einzelhandel-adressen.py``` ausfühen, um Datei \"adressen_mit_einzelhandel.csv\" zu erzeugen.\n",
    "Durch fußläufiges Routing berechnete Faktoren:\n",
    "- Anzahl von Einkaufsmöglichkeiten im Umkreis von 500 m\n",
    "- Anzahl von Einkaufsmöglichkeiten im Umkreis von 800 m\n",
    "- Geringste Distanz zum nächsten Einzelhandel"
   ],
   "id": "fb6d05a628d926b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns, matplotlib.pyplot as plt\n",
    "\n",
    "# Lade vorberechnete Einzelhandel-Faktoren\n",
    "gdf_retail = load_geocsv(\"out/adressen_mit_einzelhandel_routen.csv\")\n",
    "\n",
    "# Merge mit Haupt-GDF\n",
    "gdf_retail[\"Adresse_merge\"] = gdf_retail.apply(make_merge_addr, axis=1)\n",
    "gdf_retail = gdf_retail.sort_values(\"Adresse_merge\").drop_duplicates(\"Adresse_merge\", keep=\"first\")\n",
    "\n",
    "dups = gdf_retail[\"Adresse_merge\"].value_counts()\n",
    "print(dups[dups > 1])\n",
    "\n",
    "einzelhandel_attribute = [\"einzelhandel_route\",\"einzelhandel_min_distance_m\", \"einzelhandel_500m_count\", \"einzelhandel_800m_count\", \"einzelhandel_1000m_count\"]\n",
    "\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_retail[[\"Adresse_merge\"] + einzelhandel_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "print(gdf.shape)\n",
    "print(gdf[[\"Adresse_merge\", \"einzelhandel_min_distance_m\"]].head())\n",
    "\n",
    "print(gdf.shape)\n",
    "\n",
    "# Speicher freigeben\n",
    "del(gdf_retail)"
   ],
   "id": "14c882fa9c070677",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Verteilung Distanz zum nächsten Markt\n",
    "print(gdf.columns)\n",
    "sns.histplot(gdf[\"einzelhandel_min_distance_m\"].dropna(), bins=40, kde=False)\n",
    "plt.title(\"Distanz zum nächsten Lebensmittel­markt\")\n",
    "plt.xlabel(\"Meter Fußweg\"); plt.ylabel(\"Adressen\")\n",
    "plt.show()\n",
    "\n",
    "# Scatter Zentralität vs. Nahversorgung\n",
    "sns.scatterplot(x=\"center_distance_m\", y=\"einzelhandel_min_distance_m\", data=gdf, alpha=.3)\n",
    "plt.xlabel(\"Distanz Zentrum (m)\"); plt.ylabel(\"Distanz nächster Markt (m)\")\n",
    "plt.show()"
   ],
   "id": "2425ee38a7ebf529",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Lärmbelastung\n",
    "Siehe ```laerm.ipynb``` zur Erzeugung, ansonsten einfach ```data/adressen_mit_laerm.csv``` verwenden und per Spalte 'geometry' verschneiden.\n",
    "\n",
    "Definition Lärm-Index:\n",
    "- NaN / leer: kein gemessener Straßenlärm\n",
    "- 0: 55 - 59 dB\n",
    "- 1: 60 - 64 dB\n",
    "- 2: 65 - 69 dB\n",
    "- 3: 70 - 74 dB\n",
    "- 4: >= 75 db"
   ],
   "id": "d0c2655c478327a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gdf_laerm_karte = load_geocsv(\"out/adressen_mit_laerm.csv\")\n",
    "print(gdf_laerm_karte.shape)\n",
    "print(gdf.shape)\n",
    "\n",
    "# Merge des Lärmindex mit Haupt-GDF\n",
    "gdf_laerm_karte[\"Adresse_merge\"] = gdf_laerm_karte.apply(make_merge_addr, axis=1)\n",
    "gdf_laerm_karte[\"laerm_index_tag\"] = gdf_laerm_karte[\"Laerm_index_tag\"].fillna(-0.1) # lowercase\n",
    "\n",
    "# Deduplicate, im Zweifel nimm den lautesten Wert\n",
    "gdf_laerm_karte = (\n",
    "    gdf_laerm_karte\n",
    "    .sort_values(\"laerm_index_tag\", ascending=False)\n",
    "    .drop_duplicates(\"Adresse_merge\", keep=\"first\")\n",
    ")\n",
    "\n",
    "laerm_attribute = [\"laerm_index_tag\"]\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_laerm_karte[[\"Adresse_merge\"] + laerm_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "\n",
    "#print(gdf.columns)\n",
    "print(gdf.shape)"
   ],
   "id": "f991ebcdf50656b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Bildung\n",
    "Weitere Faktoren\n",
    "- Fußläufige Entfernung zur nächstgelegenen Kita\n",
    "- Fußläufige Entfernung zur nächstgelegenen Schule\n",
    "- Anzahl Kitas im Umkreis von 500, 800 und 1000 Metern\n",
    "- Anzahl Schulen im Umkreis von 500, 800 und 1000 Metern"
   ],
   "id": "87cef8c157d06d58"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Daten als GeoDataFrame einlesen\n",
    "gdf_kitas = load_geocsv(\"out/adressen_mit_kitas_routen.csv\")\n",
    "gdf_grundschulen = load_geocsv(\"out/adressen_mit_grundschulen_routen.csv\")\n",
    "print(gdf_kitas.shape)\n",
    "print(gdf_grundschulen.shape)\n",
    "print(gdf.shape)\n",
    "\n",
    "# Eindeutige Adresse für den Merge generieren\n",
    "gdf_kitas[\"Adresse_merge\"] = gdf_kitas.apply(make_merge_addr, axis=1)\n",
    "gdf_kitas = gdf_kitas.drop_duplicates(\"Adresse_merge\")\n",
    "gdf_grundschulen[\"Adresse_merge\"] = gdf_grundschulen.apply(make_merge_addr, axis=1)\n",
    "gdf_grundschulen = gdf_grundschulen.drop_duplicates(\"Adresse_merge\")\n",
    "\n",
    "# Rename kitas_geometry column to kitas_route in gfd_kitas\n",
    "\n",
    "\n",
    "# Merge into main gdf\n",
    "kitas_attribute = [\"kitas_min_distance_m\", \"kitas_route\", \"kitas_count_within_500m\", \"kitas_count_within_800m\", \"kitas_count_within_1000m\"]\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_kitas[[\"Adresse_merge\"] + kitas_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "\n",
    "grundschulen_attribute = [\"grundschulen_min_distance_m\", \"grundschulen_route\", \"grundschulen_count_within_500m\", \"grundschulen_count_within_800m\", \"grundschulen_count_within_1000m\"]\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_grundschulen[[\"Adresse_merge\"] + grundschulen_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "del(gdf_kitas, gdf_grundschulen)  # Speicher freigeben\n",
    "\n",
    "print(gdf.columns)\n",
    "print(gdf.shape)"
   ],
   "id": "f3a118199fb1be23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Medizinische Versorgung\n",
    "Ein \"medizinisches Zentrum\" wurde definiert als eine Apotheke mit zwei Ärzten im Umkreis von 100 Metern. Diese Zentren werden separat in ```medizinische-zentren.py``` berechnet. Dazu wird die euklidische Distanz (\"Luftlinie\") zwischen Apotheken und umgebenden Ärzten berechnet.\n",
    "Dadurch entstehen für den Datensatz folgende neue Attribute:\n",
    "- Anzahl von medizinischen Zentren im Umkreis von 500 m\n",
    "- Anzahl von medizinischen Zentren im Umkreis von 800 m\n",
    "- Anzahl von medizinischen Zentren im Umkreis von 1000 m\n",
    "- Fußläufige Distanz zum nächsten medizinischen Zentrum\n",
    "\n",
    "Die vollständige Erklärung der Felder findet sich im Anhang.\n",
    "\n",
    "Die fußläufige Distanz zum nächstgelegenen medizinischen Zentrum wird per ```routing.py``` für jede Adresse einzeln ermittelt und als Weg gespeichert (```adressen_mit_medzentren_routen```)."
   ],
   "id": "a8b3a7b9ddd38f8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "# Zentren / Apothekenstandorte mit Klassifikation\n",
    "df_centers = pd.read_csv(\"out/medzentren_geocoded.csv\")\n",
    "\n",
    "# Normiere Bool-Spalte\n",
    "df_centers[\"is_med_center\"] = (df_centers[\"is_med_center\"].astype(str).str.lower().isin([\"true\", \"1\", \"yes\", \"y\"]))\n",
    "\n",
    "# Einzel-Apotheken ausblenden?\n",
    "# df_centers = df_centers[df_centers[\"is_med_center\"] == True].copy()\n",
    "\n",
    "def build_popup(row):\n",
    "    lines = []\n",
    "\n",
    "    if bool(row[\"is_med_center\"]):\n",
    "        lines.append(f\"<b>Medizinisches Zentrum \\\"{str(row['Strassenname'])}\\\"</b><br>\")\n",
    "\n",
    "    # Name\n",
    "    if pd.notna(row.get(\"Name_Apotheke\")) and str(row[\"Name_Apotheke\"]).strip() != \"\":\n",
    "        lines.append(str(row[\"Name_Apotheke\"]))\n",
    "\n",
    "    # Ärztedichte im 100m Radius\n",
    "    if \"arzt_count_100m\" in row:\n",
    "        lines.append(f\"<br><b>{int(row['arzt_count_100m'])}</b> Arzt-Praxen\")\n",
    "\n",
    "    return \"<br>\".join(lines)\n",
    "\n",
    "def pick_icon(row):\n",
    "    if bool(row[\"is_med_center\"]):\n",
    "        return folium.Icon(color=\"green\", icon=\"plus-sign\", prefix=\"glyphicon\")\n",
    "    else:\n",
    "        return folium.Icon(color=\"gray\", icon=\"staff-snake\", prefix=\"fa\")\n",
    "\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=14)\n",
    "cluster = MarkerCluster(name=\"Medizinische Zentren / Apotheken\")\n",
    "cluster.add_to(m)\n",
    "\n",
    "# Marker setzen\n",
    "for _, row in df_centers.iterrows():\n",
    "    lat = row[\"lat\"]\n",
    "    lon = row[\"lon\"]\n",
    "\n",
    "    if pd.isna(lat) or pd.isna(lon):\n",
    "        continue\n",
    "\n",
    "    popup_html = build_popup(row)\n",
    "    icon = pick_icon(row)\n",
    "\n",
    "    folium.Marker(\n",
    "        location=[lat, lon],\n",
    "        popup=popup_html,\n",
    "        tooltip=row.get(\"Strassenname\", \"Apotheke\"),\n",
    "        icon=icon,\n",
    "    ).add_to(cluster)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "m"
   ],
   "id": "a4533f83433b8618",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Medizinische Felder in gdf übernehmen\n",
    "# 1. Routing-Ergebnis für medizinische Versorgung laden\n",
    "gdf_med = load_geocsv(\"out/adressen_mit_medzentren_routen.csv\")\n",
    "print(\"gdf_med shape:\", gdf_med.shape)\n",
    "print(\"gdf shape (vor Merge):\", gdf.shape)\n",
    "\n",
    "# 2. Merge-Key bauen (Adresse normalisieren)\n",
    "gdf_med[\"Adresse_merge\"] = gdf_med.apply(make_merge_addr, axis=1)\n",
    "gdf_med = gdf_med.drop_duplicates(\"Adresse_merge\")\n",
    "\n",
    "# 3. Relevante Attributspalten aus der medizinischen Versorgung definieren\n",
    "medzentren_attribute = [\n",
    "    \"medzentren_min_distance_m\",\n",
    "    \"medzentren_route\",\n",
    "    \"medzentren_count_within_500m\",\n",
    "    \"medzentren_count_within_800m\",\n",
    "    \"medzentren_count_within_1000m\",\n",
    "]\n",
    "\n",
    "# 4. Merge in Haupt-GDF\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_med[[\"Adresse_merge\"] + medzentren_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_one\",\n",
    ")\n",
    "\n",
    "print(\"gdf shape (nach Merge):\", gdf.shape)"
   ],
   "id": "2e57b491ca5f7e24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ÖPNV-Qualität\n",
    "\n",
    "Die Qualität des ÖPNV wird anhand der Fußläufigkeit zur nächsten Haltestelle und der Häufigkeit von Abfahrten (Headway) bewertet. Die Daten stammen vom Verkehrsverbund Berlin-Brandenburg (VBB), Lizenz: CC BY 4.0, [zu den Daten](https://unternehmen.vbb.de/digitale-services/datensaetze).\n",
    "\n",
    "Vorausgesetzte Datensätze:\n",
    "- ```data/GTFS/stops.txt```, der die Haltestellen mit ihren Geokoordinaten enthält.\n",
    "- ```data/adressen_mit_haltestellen_routen.csv```, der die Routen zu den Haltestellen und Anzahl von Haltestellen im Radius 500m und 800m enthält.\n",
    "\n",
    "Probleme mit Datenqualität:\n",
    "- In der \"2024_Haltestellen.csv\" fehlen die Haltestellen \"Libellenweg\" und \"Immenweg\" (Linie B). Dadurch werden diese Haltestellen nicht berücksichtigt und Wege zur nächsten Haltestelle werden länger eingeschätzt."
   ],
   "id": "97d042d0ef303f6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from shapely.geometry import Point\n",
    "\n",
    "# Load GTFS stops data\n",
    "stops = pd.read_csv(\"data/GTFS/stops.txt\")\n",
    "stops[\"geometry\"] = stops.apply(lambda row: Point(row[\"stop_lon\"], row[\"stop_lat\"]), axis=1)\n",
    "gdf_stops = gpd.GeoDataFrame(stops, geometry=\"geometry\", crs=EPSG_4326)\n",
    "\n",
    "# Convert to UTM for precise metric distance calculations\n",
    "gdf = gdf.to_crs(epsg=32633)\n",
    "gdf_stops = gdf_stops.to_crs(epsg=32633)\n",
    "\n",
    "# Assign nearest stop to each address based on Point(X, Y) geometry\n",
    "gdf[\"nearest_stop_id\"] = gdf.geometry.apply(\n",
    "    lambda pt: gdf_stops.loc[gdf_stops.distance(pt).idxmin(), \"stop_id\"]\n",
    ")\n",
    "\n",
    "# Read routes from adresses to stops and stop count from prepared CSV\n",
    "gdf_haltestellen = load_geocsv(\"out/adressen_mit_haltestellen_routen.csv\")\n",
    "gdf_haltestellen[\"Adresse_merge\"] = gdf_haltestellen.apply(make_merge_addr, axis=1)\n",
    "gdf_haltestellen = gdf_haltestellen.drop_duplicates(\"Adresse_merge\").copy()\n",
    "\n",
    "print(\"gdf_haltestellen shape:\", gdf_haltestellen.shape)\n",
    "print(\"gdf shape (vor Merge):\", gdf.shape)\n",
    "\n",
    "# Merge haltestellen attributes into main GeoDataFrame\n",
    "haltestellen_attribute = [\"haltestellen_route\", \"haltestellen_min_distance_m\", \"haltestellen_count_within_500m\", \"haltestellen_count_within_800m\"]\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_haltestellen[[\"Adresse_merge\"] + haltestellen_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_one\"\n",
    ")\n",
    "\n",
    "print(\"gdf shape (nach Merge):\", gdf.shape)\n",
    "\n",
    "# Speicher freigeben\n",
    "del gdf_haltestellen"
   ],
   "id": "b032c3c18de695a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Berechnung der ÖPNV-Taktung",
   "id": "9b1c9bc9b0c3c80d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. GTFS laden\n",
    "# -------------------------------------------------\n",
    "stops = pd.read_csv(\"data/GTFS/stops.txt\")\n",
    "stop_times = pd.read_csv(\"data/GTFS/stop_times.txt\", low_memory=False)\n",
    "trips = pd.read_csv(\"data/GTFS/trips.txt\")\n",
    "calendar = pd.read_csv(\"data/GTFS/calendar.txt\")  # behalten wir für evtl. spätere Filter\n",
    "# optional:\n",
    "# calendar_dates = pd.read_csv(\"data/GTFS/calendar_dates.txt\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Zeitspalte -> Minuten ab Mitternacht\n",
    "# -------------------------------------------------\n",
    "def parse_time_to_minutes(t):\n",
    "    if pd.isna(t):\n",
    "        return None\n",
    "    parts = str(t).split(\":\")\n",
    "    if len(parts) == 2:\n",
    "        h, m = parts\n",
    "    elif len(parts) == 3:\n",
    "        h, m, _s = parts\n",
    "    else:\n",
    "        return None\n",
    "    try:\n",
    "        h = int(h)\n",
    "        m = int(m)\n",
    "        return h * 60 + m\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "stop_times = stop_times.copy()\n",
    "stop_times[\"minutes\"] = stop_times[\"arrival_time\"].apply(parse_time_to_minutes)\n",
    "stop_times = stop_times.dropna(subset=[\"minutes\"])\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3. Wir interessieren uns für HVZ-Fenster\n",
    "#    Wir extrahieren NUR Stop-Zeiten, die überhaupt in diesen Fenstern liegen.\n",
    "#    Damit behalten wir reale Pendlerfahrten selbst dann,\n",
    "#    wenn calendar.monday == 0 gesagt hätte.\n",
    "# -------------------------------------------------\n",
    "\n",
    "HVZ_WINDOWS = [\n",
    "    (360, 540),   # 06:00–09:00\n",
    "    (960, 1140),  # 16:00–19:00\n",
    "]\n",
    "\n",
    "def in_any_window(mins, windows):\n",
    "    for lo, hi in windows:\n",
    "        if lo <= mins <= hi:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "stop_times_hvz = stop_times[stop_times[\"minutes\"].apply(lambda mm: in_any_window(mm, HVZ_WINDOWS))].copy()\n",
    "\n",
    "# 3. Filter nur auf werktägliche Dienste\n",
    "trips_filtered = trips.merge(calendar, on=\"service_id\")\n",
    "trips_filtered = trips_filtered[trips_filtered[\"monday\"] == 1]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4. stop_times_hvz ↔ trips (route_id etc.)\n",
    "# -------------------------------------------------\n",
    "trips[\"trip_id\"] = trips[\"trip_id\"].astype(str)\n",
    "\n",
    "stop_times_hvz[\"trip_id\"] = stop_times_hvz[\"trip_id\"].astype(str)\n",
    "\n",
    "stopdata = stop_times_hvz.merge(\n",
    "    trips[[\"trip_id\", \"route_id\", \"service_id\"]],\n",
    "    on=\"trip_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 5. Haltestellengeometrie + Clusterbildung (DBSCAN)\n",
    "# -------------------------------------------------\n",
    "stops = stops.copy()\n",
    "stops[\"stop_id\"] = stops[\"stop_id\"].astype(str)\n",
    "\n",
    "gdf_stops_all = gpd.GeoDataFrame(\n",
    "    stops,\n",
    "    geometry=gpd.points_from_xy(stops[\"stop_lon\"], stops[\"stop_lat\"]),\n",
    "    crs=EPSG_4326\n",
    ")\n",
    "\n",
    "gdf_stops_metric = gdf_stops_all.to_crs(epsg=25833).copy()\n",
    "coords = np.vstack([\n",
    "    gdf_stops_metric.geometry.x.values,\n",
    "    gdf_stops_metric.geometry.y.values\n",
    "]).T\n",
    "\n",
    "db = DBSCAN(eps=100, min_samples=1).fit(coords)\n",
    "gdf_stops_all[\"pt_cluster_id\"] = db.labels_.astype(int)\n",
    "\n",
    "stop_to_cluster = dict(zip(gdf_stops_all[\"stop_id\"], gdf_stops_all[\"pt_cluster_id\"]))\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 6. Cluster-ID an stopdata hängen\n",
    "# -------------------------------------------------\n",
    "stopdata[\"stop_id\"] = stopdata[\"stop_id\"].astype(str)\n",
    "stopdata[\"pt_cluster_id\"] = stopdata[\"stop_id\"].map(stop_to_cluster)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 7. Headway je Cluster berechnen\n",
    "#    jetzt auf Basis ALLER HVZ-Fahrten, die tatsächlich vorkommen,\n",
    "#    statt nur calendar.monday==1\n",
    "# -------------------------------------------------\n",
    "def compute_headway_for_window(df, lo, hi, group_col=\"pt_cluster_id\", time_col=\"minutes\"):\n",
    "    result = {}\n",
    "    for clus, group in df.groupby(group_col):\n",
    "        if pd.isna(clus):\n",
    "            continue\n",
    "        # nur Zeiten im Fenster\n",
    "        times = sorted([t for t in group[time_col] if lo <= t <= hi])\n",
    "        if len(times) < 2:\n",
    "            continue\n",
    "        diffs = [b - a for a, b in zip(times, times[1:])]\n",
    "        result[clus] = sum(diffs) / len(diffs)\n",
    "    return result\n",
    "\n",
    "headway_morning = compute_headway_for_window(stopdata, 360, 540)\n",
    "headway_evening = compute_headway_for_window(stopdata, 960, 1140)\n",
    "\n",
    "df_hm = (\n",
    "    pd.DataFrame.from_dict(headway_morning, orient=\"index\", columns=[\"headway_morning\"])\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"pt_cluster_id\"})\n",
    ")\n",
    "df_he = (\n",
    "    pd.DataFrame.from_dict(headway_evening, orient=\"index\", columns=[\"headway_evening\"])\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"pt_cluster_id\"})\n",
    ")\n",
    "\n",
    "df_headways = df_hm.merge(df_he, on=\"pt_cluster_id\", how=\"outer\", validate=\"one_to_one\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 8. Merge in gdf\n",
    "# -------------------------------------------------\n",
    "gdf[\"nearest_stop_id\"] = gdf[\"nearest_stop_id\"].astype(str)\n",
    "gdf[\"pt_cluster_id\"] = gdf[\"nearest_stop_id\"].map(stop_to_cluster)\n",
    "\n",
    "# weg mit alten Spalten falls rerun\n",
    "for col in [\n",
    "    \"headway_morning\", \"headway_evening\", \"headway_avg\",\n",
    "    \"headway_morning_score_fixed\", \"headway_evening_score_fixed\",\n",
    "    \"headway_avg_score_fixed\",\n",
    "]:\n",
    "    if col in gdf.columns:\n",
    "        gdf = gdf.drop(columns=[col])\n",
    "\n",
    "gdf = gdf.merge(\n",
    "    df_headways,\n",
    "    on=\"pt_cluster_id\",\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 9. Kennzahlen\n",
    "# -------------------------------------------------\n",
    "for col in [\"headway_morning\", \"headway_evening\"]:\n",
    "    gdf[col] = pd.to_numeric(gdf[col], errors=\"coerce\")\n",
    "\n",
    "gdf[\"headway_avg\"] = gdf[[\"headway_morning\", \"headway_evening\"]].mean(axis=1)\n",
    "\n",
    "fixed_min, fixed_max = 5, 60\n",
    "def scoreify(series):\n",
    "    return 1 - ((series - fixed_min) / (fixed_max - fixed_min)).clip(lower=0, upper=1)\n",
    "\n",
    "gdf[\"headway_morning_score_fixed\"] = scoreify(gdf[\"headway_morning\"])\n",
    "gdf[\"headway_evening_score_fixed\"] = scoreify(gdf[\"headway_evening\"])\n",
    "gdf[\"headway_avg_score_fixed\"]     = scoreify(gdf[\"headway_avg\"])\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 10. Debug neu\n",
    "# -------------------------------------------------\n",
    "no_headway_mask = gdf[\"headway_avg\"].isna()\n",
    "\n",
    "print(\"Adressen ohne Headway_avg:\", int(no_headway_mask.sum()))\n",
    "\n",
    "na_clusters = (\n",
    "    gdf.loc[no_headway_mask, \"pt_cluster_id\"]\n",
    "    .value_counts()\n",
    ")\n",
    "print(\"Problem-Cluster:\", len(na_clusters))\n",
    "print(na_clusters.head(20))\n",
    "\n",
    "# sicherstellen, dass wir wirklich noch Stops ohne Window-Fahrten haben\n",
    "clusters_with_headway = set(df_headways[\"pt_cluster_id\"].tolist())\n",
    "clusters_without = [cid for cid in gdf[\"pt_cluster_id\"].dropna().unique()\n",
    "                    if cid not in clusters_with_headway]\n",
    "print(\"Cluster ohne Eintrag in df_headways:\", len(clusters_without))\n",
    "print(clusters_without[:20])\n",
    "\n",
    "# Spot-check: nimm den größten Problem-Cluster\n",
    "if len(clusters_without) > 0:\n",
    "    test_cluster = clusters_without[0]\n",
    "    sample_times = stopdata.loc[stopdata[\"pt_cluster_id\"] == test_cluster, \"minutes\"]\n",
    "    print(\"Beispiel-Cluster\", test_cluster, \"HVZ Zeiten:\",\n",
    "          sorted([t for t in sample_times if 360 <= t <= 540])[:20])\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 11. Debug: Wo fehlen noch Headways?\n",
    "# -------------------------------------------------\n",
    "no_headway_mask = gdf[\"headway_avg\"].isna()\n",
    "\n",
    "print(\"Adressen ohne Headway_avg:\", int(no_headway_mask.sum()))\n",
    "\n",
    "# Welche Stop-IDs sind schuld, nach nearest_stop_id\n",
    "na_stops = (\n",
    "    gdf.loc[no_headway_mask, \"nearest_stop_id\"]\n",
    "    .value_counts()\n",
    ")\n",
    "print(\"Anzahl unterschiedlicher problematischer Haltestellen (Steig-Ebene):\", len(na_stops))\n",
    "print(na_stops.head(20))\n",
    "\n",
    "# Welche Cluster sind schuld\n",
    "na_clusters = (\n",
    "    gdf.loc[no_headway_mask, \"pt_cluster_id\"]\n",
    "    .value_counts()\n",
    ")\n",
    "print(\"Anzahl problematischer Cluster:\", len(na_clusters))\n",
    "print(na_clusters.head(20))\n",
    "\n",
    "# Prüfen, ob diese Cluster überhaupt Headways in df_headways haben\n",
    "clusters_with_headway = set(df_headways[\"pt_cluster_id\"].astype(int).tolist())\n",
    "clusters_without = [cid for cid in na_clusters.index if cid not in clusters_with_headway]\n",
    "print(\"Cluster ohne Eintrag in df_headways:\", len(clusters_without))\n",
    "print(clusters_without[:20])\n",
    "\n",
    "# Sanity check: für einen der Top-Cluster, zeig alle Abfahrtszeiten morgens\n",
    "if len(clusters_without) > 0:\n",
    "    test_cluster = clusters_without[0]\n",
    "    sample_times = stopdata.loc[stopdata[\"pt_cluster_id\"] == test_cluster, \"minutes\"]\n",
    "    print(\"Beispiel-Cluster\", test_cluster, \"hat morgens Zeiten in 6-9?:\",\n",
    "          sample_times[(sample_times>=360)&(sample_times<=540)].sort_values().head(20).tolist())\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 12. Cleanup (optional)\n",
    "# -------------------------------------------------\n",
    "#del(stop_times, trips, calendar, trips_filtered,\n",
    "#    stopdata, df_hm, df_he, df_headways,\n",
    "#    gdf_stops_metric, coords, db)\n"
   ],
   "id": "ad2f3fdb3ae58eb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ÖPMV in gdf mergen\n",
    "headway_attribute = [\"headway_avg\"]"
   ],
   "id": "a1e92bc343809d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualisierung der ÖPNV-Taktung",
   "id": "f3be44369f64d5db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "from branca.colormap import linear, LinearColormap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Convert gdf_stops geometry to WGS84\n",
    "gdf_stops = gdf_stops.to_crs(epsg=4326).copy()\n",
    "\n",
    "# Haltestellen innerhalb Stadt\n",
    "gdf_stops_clip = gdf_stops[gdf_stops.geometry.within(CITY_BOUNDING_BOX)].copy()\n",
    "print(\"Haltestellen im Stadtpolygon:\", len(gdf_stops_clip))\n",
    "\n",
    "#\n",
    "# 2. Farbskala nur aus Adressen-Headway\n",
    "#\n",
    "# headway_avg = durchschnittliche Taktzeit (Minuten) für diese Adresse\n",
    "# Annahme: kleiner Wert = besser (häufigere Bedienung)\n",
    "addr_headway = pd.to_numeric(gdf[\"headway_avg\"], errors=\"coerce\")\n",
    "\n",
    "hv_valid = addr_headway.dropna()\n",
    "if len(hv_valid) > 0:\n",
    "    vmin, vmax = hv_valid.quantile([0.01, 0.99])\n",
    "    if vmin == vmax:\n",
    "        # falls alles gleich (z. B. nur eine Linie), spreizen für die Farbskala\n",
    "        vmin = vmin - 0.1\n",
    "        vmax = vmax + 0.1\n",
    "else:\n",
    "    # Fallback, falls ALLE Adressen NaN sind\n",
    "    vmin, vmax = (0, 1)\n",
    "\n",
    "palette_normal = list(linear.RdYlGn_11.colors)\n",
    "palette_inverted = palette_normal[::-1]\n",
    "colormap = LinearColormap(\n",
    "    colors=palette_inverted,\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    ").to_step(n=9)\n",
    "colormap.caption = \"Headway pro Adresse (Minuten, kleiner = besser)\"\n",
    "\n",
    "# 3. Karte initialisieren\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"cartodbpositron\")\n",
    "\n",
    "# 4. Adressen plotten (farbig nach headway_avg)\n",
    "#    - Farbig wenn headway_avg da\n",
    "#    - Hellgrau wenn kein Wert\n",
    "for _, row in gdf.iterrows():\n",
    "    hv_addr = row.get(\"headway_avg\", np.nan)\n",
    "    hv_morning = row.get(\"headway_morning\", np.nan)\n",
    "    hv_evening = row.get(\"headway_evening\", np.nan)\n",
    "\n",
    "    if pd.isna(hv_addr):\n",
    "        # Kein Wert berechnet -> zeichne neutral\n",
    "        color = \"#BBBBBB\"\n",
    "        fill_color = \"#BBBBBB\"\n",
    "        hv_label = \"kein Wert\"\n",
    "    else:\n",
    "        color = colormap(hv_addr)\n",
    "        fill_color = colormap(hv_addr)\n",
    "        hv_label = f\"{hv_addr:.1f} min\"\n",
    "\n",
    "    # Popup mit allen Headways, falls vorhanden\n",
    "    popup_lines = [\n",
    "        f\"{row.get('Straßenname', '')} {row.get('Hsnr', '')}\",\n",
    "        f\"<b>Headway (avg):</b> {hv_label}\",\n",
    "    ]\n",
    "    if pd.notna(hv_morning):\n",
    "        popup_lines.append(f\"Frühspitze: {hv_morning:.1f} min\")\n",
    "    if pd.notna(hv_evening):\n",
    "        popup_lines.append(f\"Abendspitze: {hv_evening:.1f} min\")\n",
    "\n",
    "    popup_html = \"<br>\".join(popup_lines)\n",
    "\n",
    "    folium.CircleMarker(\n",
    "        location=[row.lat, row.lon],\n",
    "        radius=5,\n",
    "        color=color,\n",
    "        fill=True,\n",
    "        fill_color=fill_color,\n",
    "        fill_opacity=0.8,\n",
    "        weight=1,\n",
    "        popup=popup_html,\n",
    "    ).add_to(m)\n",
    "\n",
    "# 5. Haltestellen plotten (schwarz, neutral)\n",
    "#    Du zeigst hier die Infrastrukturpunkte, ohne Qualitätsfarbe.\n",
    "for _, row in gdf_stops_clip.iterrows():\n",
    "    lat_s = row[\"stop_lat\"]\n",
    "    lon_s = row[\"stop_lon\"]\n",
    "\n",
    "    # Popup Haltestellenname\n",
    "    stop_label = row.get(\"stop_name\", row.get(\"stop_id\", \"Haltestelle\"))\n",
    "\n",
    "    folium.CircleMarker(\n",
    "        location=[lat_s, lon_s],\n",
    "        radius=3,\n",
    "        color=\"black\",\n",
    "        fill=True,\n",
    "        fill_color=\"black\",\n",
    "        fill_opacity=1,\n",
    "        weight=1,\n",
    "        popup=f\"<b>Haltestelle:</b> {stop_label}<br>\",\n",
    "    ).add_to(m)\n",
    "\n",
    "# 6. Legende für die Adressen-Headways\n",
    "colormap.add_to(m)\n",
    "m\n"
   ],
   "id": "24544ac9ee9f7dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Umwelt\n",
    "### Großflächen\n",
    "- Luftlinie in m zum nächsten großen Wald oder See\n",
    "- Luftlinie in m zum nächsten großen Gewerbe- oder Industriegebiet\n"
   ],
   "id": "51f2302c42d26989"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "TARGET_CLASSES = [\"Gewerbe\", \"Gruen\", \"Sonstiges\"]\n",
    "\n",
    "# --- 1) metrische Projektion ---\n",
    "gdf_m = gdf.to_crs(32633)\n",
    "gdf_large_m = gdf_large.to_crs(32633)\n",
    "\n",
    "# --- 2) Zentroid ---\n",
    "gdf_large_m[\"centroid\"] = gdf_large_m.geometry.centroid\n",
    "\n",
    "# --- 3) Robuste Distanzfunktion ---\n",
    "import numpy as np\n",
    "\n",
    "def compute_min_distance(point, target_series):\n",
    "    sindex = target_series.sindex\n",
    "    idx = sindex.nearest(point)\n",
    "\n",
    "    # ndarray → normaler Fall unter RTree\n",
    "    if isinstance(idx, (list, tuple, np.ndarray)):\n",
    "        if len(idx) == 0:\n",
    "            return None\n",
    "        nearest_idx = idx[0]\n",
    "\n",
    "    elif isinstance(idx, tuple):\n",
    "        nearest_idx = idx[0][0]\n",
    "\n",
    "    else:\n",
    "        raise TypeError(f\"Unexpected type from sindex.nearest: {type(idx)}\")\n",
    "\n",
    "    nearest_geom = target_series.iloc[nearest_idx]\n",
    "    return point.distance(nearest_geom)\n",
    "\n",
    "# --- 4) große Flächen pro Klasse sammeln ---\n",
    "large_by_class = {\n",
    "    k: gdf_large_m[gdf_large_m[\"nutzklasse\"] == k][\"centroid\"]\n",
    "    for k in TARGET_CLASSES\n",
    "}\n",
    "\n",
    "# --- 5) Distanz berechnen ---\n",
    "for k, centroids in large_by_class.items():\n",
    "    gdf_m[f\"dist_gross_{k.lower()}\"] = gdf_m.geometry.apply(\n",
    "        lambda pt, centroids=centroids: compute_min_distance(pt, centroids)\n",
    "    )\n",
    "\n",
    "# --- 6) zurück in WGS84 ---\n",
    "gdf_back = gdf_m.to_crs(4326)\n",
    "\n",
    "# --- 7) neue Distanzfelder zurück in das ursprüngliche gdf mergen ---\n",
    "dist_cols = [f\"dist_gross_{k.lower()}\" for k in TARGET_CLASSES]\n",
    "gdf[dist_cols] = gdf_back[dist_cols]\n",
    "\n",
    "del gdf_back"
   ],
   "id": "6c748ab230ad8d61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Freizeit- und Erholungsflächen\n",
    "\n",
    "- Fußläufige Distanz zur nächstgelegenen Freizeit- und Erholungsflächen (Parks, Grünanlagen)\n",
    "\n",
    "Die Freizeit- und Erholungsflächen laut Auftrag sind:\n",
    "- Marienberg\n",
    "- Humboldthain\n",
    "- Salzhofufer\n",
    "- Wallpromenade\n",
    "- Theaterpark\n",
    "- Grabenpromenade\n",
    "- Schlosspark Plaue\n",
    "- Schlosspark Gollwitz\n",
    "- Krugpark\n",
    "\n",
    "Aus den bereitgestellten Shape-Dateien werden anhand der Objektbezeichnung (Spalte \"objektbeze\") im Routing-Skript ca. 100 zusammenhängende Flächen gebildet, deren Ränder als Ziele für die fußläufige Distanzberechnung genutzt werden. Dadurch werden mehr als die angegebenen Flächen genutzt.\n",
    "\n",
    "Einschränkung der Validität: Durch die Beschränkung auf diese Flächenarten erhalten zentrumsferne Adressen trotz der Lage z. B. an Wäldern schlechtere Bewertungen."
   ],
   "id": "94649ee801aa7560"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "path = \"data/Grünflächen_Verkehrszeichen/20251029_Vegetation_KSP_GP_31.shp\"\n",
    "gdf_gruen_shape = gpd.read_file(path)\n",
    "#gdf_gruen"
   ],
   "id": "aa43fe538b4bc67a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=14)\n",
    "\n",
    "def random_color(seed):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    r = rng.integers(80, 200)\n",
    "    g = rng.integers(80, 200)\n",
    "    b = rng.integers(80, 200)\n",
    "    return f\"#{r:02x}{g:02x}{b:02x}\"\n",
    "\n",
    "# Ein Farbschema erzeugen\n",
    "unique_ids = gdf_gruen_shape[\"objektbeze\"].unique()\n",
    "color_map = {uid: random_color(i) for i, uid in enumerate(unique_ids)}\n",
    "\n",
    "# Polygone hinzufügen\n",
    "folium.GeoJson(\n",
    "    gdf_gruen_shape,\n",
    "    style_function=lambda feature: {\n",
    "        \"color\": \"black\",\n",
    "        \"weight\": 0.5,\n",
    "        \"fillOpacity\": 0.9,\n",
    "        \"fillColor\": color_map[feature[\"properties\"][\"objektbeze\"]]\n",
    "    },\n",
    "    tooltip=folium.GeoJsonTooltip(fields=[\"objektbeze\"])\n",
    ").add_to(m)\n",
    "\n",
    "m"
   ],
   "id": "2ae81272462576a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gdf_gruen_m = gdf_gruen_shape.to_crs(32633)\n",
    "\n",
    "# Gruppieren & union der Flächen\n",
    "gdf_gruen_area = (gdf_gruen_shape.dissolve(by=\"objektbeze\").reset_index())\n",
    "\n",
    "# Fläche berechnen (m²)\n",
    "gdf_gruen_area[\"flaeche_m2\"] = gdf_gruen_area.area\n",
    "gdf_gruen_area[\"flaeche_ha\"] = gdf_gruen_area[\"flaeche_m2\"] / 10_000\n",
    "\n",
    "bad = gdf_gruen_area.geometry.apply(lambda g: not g.is_valid)\n",
    "print(\"Ungültige Geometrien:\", bad.sum())\n",
    "\n",
    "bb = gdf_gruen_area.geometry.boundary\n",
    "print(\"Boundary is empty:\", sum(bb.is_empty))\n",
    "\n",
    "# Optional: Die Fläche der nächstgelegenen Anlage könnte noch als Qualitätskriterium hinzugefügt werden. Vorerst nutzen wir nur die Entfernung zu den Anlagen.\n",
    "\n",
    "del(gdf_gruen_m, gdf_gruen_area)"
   ],
   "id": "70328158908d4bc8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Lade vorberechnete Routen zur nächstgelegenen Anlage und Anzahl von Funden im Umkreis\n",
    "gdf_gruen = load_geocsv(\"out/adressen_mit_gruen_routen.csv\")\n",
    "gdf_gruen"
   ],
   "id": "aa74c34fdcf6a9a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Merge mit Haupt-GDF\n",
    "gdf_gruen[\"Adresse_merge\"] = gdf_gruen.apply(make_merge_addr, axis=1)\n",
    "gdf_gruen = gdf_gruen.sort_values(\"Adresse_merge\").drop_duplicates(\"Adresse_merge\", keep=\"first\")\n",
    "\n",
    "dups = gdf_gruen[\"Adresse_merge\"].value_counts()\n",
    "print(dups[dups > 1])\n",
    "\n",
    "gruen_attribute = [\"gruen_route\",\"gruen_min_distance_m\", \"gruen_count_within_500m\", \"gruen_count_within_800m\", \"gruen_count_within_1000m\"]\n",
    "\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_gruen[[\"Adresse_merge\"] + gruen_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "\n",
    "# Plausibiliätsprüfung\n",
    "print(gdf[[\"Adresse_merge\", \"gruen_min_distance_m\", \"gruen_route\"]].head())\n",
    "print(gdf.shape)"
   ],
   "id": "7390decad77bb1da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Begenzung durch dauerhafte Bahnlininen / Schranken\n",
    "Als zusätzlicher Indikator wird berechnet, ob eine Adresse durch eine Bahnlinie oder eine stark befahrene Straße (Autobahn, Bundesstraße) vom Stadtzentrum getrennt ist. Damit wird abgebildet, ob eine Adresse trotz Nähe zum Zentrum durch eine Barriere erschwerten Zugang hat (z. B., durch Wartezeiten an Bahnübergängen)."
   ],
   "id": "9d1da8cf2f7610c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import osmnx as ox\n",
    "\n",
    "# Schritt 1: Bahnlinien von OSM laden\n",
    "\n",
    "place = \"Brandenburg an der Havel, Germany\"\n",
    "\n",
    "# Eisenbahnlinien holen\n",
    "rails = ox.features_from_place(\n",
    "    place,\n",
    "    tags={\"railway\": True}  # includes rail, light_rail, tram, etc.\n",
    ")\n",
    "\n",
    "# nur Schienenverkehr (keine Haltestellen)\n",
    "rails = rails[rails[\"railway\"].isin([\"rail\"])]"
   ],
   "id": "d902584f88044dd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "# Schritt 2: Fußĺäufige Routen zum Stadtzentrum auf Schnittpunkt mit Bahnlinie prüfen und im Datensatz speichern\n",
    "\n",
    "def route_crosses_rail(route_geojson_str, rail_geom):\n",
    "    if not isinstance(route_geojson_str, str):\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        geo = json.loads(route_geojson_str)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "    if geo.get(\"type\") != \"LineString\":\n",
    "        return False\n",
    "\n",
    "    # Koordinaten (lon, lat) → Shapely LineString nutzen\n",
    "    coords = geo[\"coordinates\"]\n",
    "    line = LineString(coords)\n",
    "\n",
    "    # Schnitt-Test\n",
    "    return line.intersects(rail_geom)\n",
    "\n",
    "rail_union = rails.union_all()\n",
    "gdf[\"behind_rail_from_center\"] = gdf[\"center_route\"].apply(\n",
    "    lambda r: int(route_crosses_rail(r, rail_union))\n",
    ")\n"
   ],
   "id": "e81e3b0dad416510",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "import json\n",
    "import folium\n",
    "\n",
    "# 10 zufällige Adressen ziehen\n",
    "sample_gdf = gdf.sample(10, random_state=42)\n",
    "\n",
    "center_lat, center_lon = CITY_CENTER  # CITY_CENTER ist [lat, lon]\n",
    "center_point = (center_lat, center_lon)\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Zentrum markieren\n",
    "folium.Marker(\n",
    "    location=CITY_CENTER,\n",
    "    tooltip=\"Stadtzentrum\",\n",
    "    icon=folium.Icon(color=\"red\", icon=\"star\")\n",
    ").add_to(m)\n",
    "\n",
    "# Route + Marker je Adresse\n",
    "for idx, row in sample_gdf.iterrows():\n",
    "    if pd.isna(row[\"lat\"]) or pd.isna(row[\"lon\"]):\n",
    "        continue\n",
    "\n",
    "    addr_point = (row[\"lat\"], row[\"lon\"])\n",
    "    behind_flag = row.get(\"behind_rail_from_center\", None)\n",
    "\n",
    "    tooltip = f\"Adresse {idx}<br>behind_rail_from_center: {behind_flag}\"\n",
    "\n",
    "    # Route zum Zentrum (GeoJSON)\n",
    "    route_json = row.get(\"center_route\")\n",
    "\n",
    "    if isinstance(route_json, str):\n",
    "        try:\n",
    "            route_geo = json.loads(route_json)\n",
    "\n",
    "            if route_geo.get(\"type\") == \"LineString\":\n",
    "                # GeoJSON Koordinaten sind (lon, lat)\n",
    "                coords = [(c[1], c[0]) for c in route_geo[\"coordinates\"]]\n",
    "\n",
    "                folium.PolyLine(\n",
    "                    locations=coords,\n",
    "                    color=\"blue\",\n",
    "                    weight=4,\n",
    "                    opacity=0.7,\n",
    "                    tooltip=f\"Route zu Adresse {idx}\"\n",
    "                ).add_to(m)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Zeichnen der Route für Adresse {idx}: {e}\")\n",
    "\n",
    "    # Adressmarker\n",
    "    folium.CircleMarker(\n",
    "        location=addr_point,\n",
    "        radius=4,\n",
    "        color=\"blue\",\n",
    "        fill=True,\n",
    "        fill_opacity=0.8,\n",
    "        tooltip=folium.Tooltip(tooltip)\n",
    "    ).add_to(m)\n",
    "\n",
    "# Bahnlinien-Layer\n",
    "bahn_layer = folium.FeatureGroup(name=\"Bahnlinien (OSM)\", show=True)\n",
    "\n",
    "for _, row in rails.iterrows():\n",
    "    geom = row.geometry\n",
    "    if geom is None:\n",
    "        continue\n",
    "\n",
    "    if geom.geom_type == \"LineString\":\n",
    "        coords = [(y, x) for x, y in geom.coords]\n",
    "        folium.PolyLine(\n",
    "            locations=coords,\n",
    "            color=\"darkred\",\n",
    "            weight=4,\n",
    "            opacity=0.8\n",
    "        ).add_to(bahn_layer)\n",
    "\n",
    "    elif geom.geom_type == \"MultiLineString\":\n",
    "        for part in geom:\n",
    "            coords = [(y, x) for x, y in part.coords]\n",
    "            folium.PolyLine(\n",
    "                locations=coords,\n",
    "                color=\"darkred\",\n",
    "                weight=4,\n",
    "                opacity=0.8\n",
    "            ).add_to(bahn_layer)\n",
    "\n",
    "bahn_layer.add_to(m)\n",
    "\n",
    "m"
   ],
   "id": "44fcb8f889ac1cf4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Visualisierung aller Indikatoren\n",
    "Alle Einflussfaktoren (Supermärkte, Ärzte, Schulen etc.) werden zur Plausibilitätsprüfung auf einer Karte visualisiert."
   ],
   "id": "1a1d9689bda3a442"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "import branca.colormap as cm\n",
    "from helper import add_markers_from_csv, STRASSENNAME, HAUSNUMMER, HAUSNUMMERZUSATZ\n",
    "\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Add layer markers\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/einzelhandel_geocoded.csv\", color=\"blue\", icon=\"shopping-cart\", layer_name=\"Einzelhandel\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/grundschulen_geocoded.csv\", color=\"green\", icon=\"graduation-cap\", layer_name=\"Grundschulen\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/kitas_geocoded.csv\", color=\"beige\", icon=\"child\", layer_name=\"Kitas\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/haltestellen_geocoded.csv\", color=\"lightgray\", icon=\"bus\", layer_name=\"Haltestellen\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/medzentren_geocoded.csv\", color=\"red\", icon=\"staff-snake\", layer_name=\"Medizinische Zentren\")\n",
    "\n",
    "# Lärmindex aus dem Geopackage\n",
    "gdf_laerm_karte = gpd.read_file(\"data/laerm.gpkg\", layer=\"laerm\")\n",
    "gdf_laerm_karte = gdf_laerm_karte.clip(CITY_BOUNDING_BOX)\n",
    "value_column = \"isov1\"\n",
    "min_val = gdf_laerm_karte[value_column].min()\n",
    "max_val = gdf_laerm_karte[value_column].max()\n",
    "colormap = cm.LinearColormap(colors=[\"green\", \"yellow\", \"red\"], vmin=min_val, vmax=max_val)\n",
    "colormap.caption = \"Lärmpegel (LDEN in dB)\"\n",
    "\n",
    "# Alle Adressen als Punkte\n",
    "adress_layer = folium.FeatureGroup(name=\"Wohnadressen\", show=False)\n",
    "for _, row in gdf.iterrows():\n",
    "    if pd.notna(row[\"lat\"]) and pd.notna(row[\"lon\"]):\n",
    "        strasse = s(row.get(STRASSENNAME))\n",
    "        hsnr = s(row.get(HAUSNUMMER))\n",
    "        hsnrzus = s(row.get(HAUSNUMMERZUSATZ))\n",
    "\n",
    "        tooltip = strasse + \" \" + hsnr\n",
    "\n",
    "        adressen_map = folium.CircleMarker(\n",
    "            location=[row[\"lat\"], row[\"lon\"]],\n",
    "            radius=3,\n",
    "            color=\"lightgray\",\n",
    "            fill=True,\n",
    "            fill_opacity=0.6,\n",
    "            tooltip=tooltip\n",
    "        ).add_to(adress_layer)\n",
    "adress_layer.add_to(m)\n",
    "\n",
    "def style_function(feature):\n",
    "    value = feature[\"properties\"][value_column]\n",
    "    return {\n",
    "        \"fillColor\": colormap(value),\n",
    "        \"color\": \"black\",\n",
    "        \"weight\": 0.3,\n",
    "        \"fillOpacity\": 0.2\n",
    "    }\n",
    "\n",
    "laerm_layer = folium.FeatureGroup(name=\"Lärmkarte (LDEN 2022)\")\n",
    "folium.GeoJson(\n",
    "    gdf_laerm_karte,\n",
    "    style_function=style_function,\n",
    ").add_to(laerm_layer)\n",
    "laerm_layer.add_to(m)\n",
    "colormap.add_to(m)\n",
    "\n",
    "# Grünflächen hinzufügen\n",
    "gruen_layer = folium.FeatureGroup(name=\"Freizeit- und Erholungsflächen\")\n",
    "folium.GeoJson(\n",
    "    gdf_gruen_shape,\n",
    "    style_function=lambda feature: {\n",
    "        \"color\": \"black\",\n",
    "        \"weight\": 0.2,\n",
    "        \"fillOpacity\": 0.9,\n",
    "        \"fillColor\": \"green\"\n",
    "    }\n",
    ").add_to(gruen_layer)\n",
    "gruen_layer.add_to(m)\n",
    "\n",
    "# Bahnlinien layer hinzufügen\n",
    "bahn_layer = folium.FeatureGroup(name=\"Bahnlinien (OSM)\", show=True)\n",
    "\n",
    "for _, row in rails.iterrows():\n",
    "    geom = row.geometry\n",
    "    if geom is None:\n",
    "        continue\n",
    "\n",
    "    if geom.geom_type == \"LineString\":\n",
    "        coords = [(y, x) for x, y in geom.coords]\n",
    "        folium.PolyLine(\n",
    "            locations=coords,\n",
    "            color=\"darkred\",\n",
    "            weight=4,\n",
    "            opacity=0.8\n",
    "        ).add_to(bahn_layer)\n",
    "\n",
    "    elif geom.geom_type == \"MultiLineString\":\n",
    "        for part in geom:\n",
    "            coords = [(y, x) for x, y in part.coords]\n",
    "            folium.PolyLine(\n",
    "                locations=coords,\n",
    "                color=\"darkred\",\n",
    "                weight=4,\n",
    "                opacity=0.8\n",
    "            ).add_to(bahn_layer)\n",
    "\n",
    "bahn_layer.add_to(m)\n",
    "\n",
    "# Schaltbare Layer\n",
    "folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "del gdf_laerm_karte  # Speicher freigeben\n",
    "\n",
    "m\n"
   ],
   "id": "779464ac37bb84c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Scoring / Punktesystem\n",
    "Hier werden z-Werte zu alle **Einflussfaktoren** gebildet, um die Abweichung einer Ausprägung vom Standard (im betrachteten Gebiet) zu erfassen. Weiterhin werden die **Gewichte** festgelegt, mit denen die Faktoren in die Wohnlagenbewertung eingehen."
   ],
   "id": "92944c1fbc1d51d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# ---------------------------------------\n",
    "# 1) Numerische & binäre Features\n",
    "# ---------------------------------------\n",
    "numeric_features = (\n",
    "        [\"center_distance_m\"] +\n",
    "        haltestellen_attribute +\n",
    "        headway_attribute +\n",
    "        einzelhandel_attribute +\n",
    "        laerm_attribute +\n",
    "        kitas_attribute +\n",
    "        grundschulen_attribute +\n",
    "        medzentren_attribute +\n",
    "        gruen_attribute\n",
    ")\n",
    "\n",
    "binary_features = [\"behind_rail_from_center\"]\n",
    "\n",
    "score_vars = numeric_features + binary_features\n",
    "\n",
    "# Masken nur auf numerische Daten!\n",
    "mask_all = gdf[numeric_features].notna().all(axis=1)\n",
    "\n",
    "# ---------------------------------------\n",
    "# 2) Z-Scores für numerische Variablen\n",
    "#    (immer: hoch = gut!)\n",
    "# ---------------------------------------\n",
    "\n",
    "# Zentralität\n",
    "gdf.loc[mask_all, \"z_centrality\"] = -zscore(gdf.loc[mask_all, \"center_distance_m\"])\n",
    "\n",
    "# Einzelhandel\n",
    "gdf.loc[mask_all, \"z_einzelhandel_distance\"]    = -zscore(gdf.loc[mask_all, \"einzelhandel_min_distance_m\"])\n",
    "gdf.loc[mask_all, \"z_einzelhandel_near_500\"]    =  zscore(gdf.loc[mask_all, \"einzelhandel_500m_count\"])\n",
    "gdf.loc[mask_all, \"z_einzelhandel_near_800\"]    =  zscore(gdf.loc[mask_all, \"einzelhandel_800m_count\"])\n",
    "gdf.loc[mask_all, \"z_einzelhandel_near_1000\"]   =  zscore(gdf.loc[mask_all, \"einzelhandel_1000m_count\"])\n",
    "\n",
    "# Lärm\n",
    "gdf.loc[mask_all, \"z_laerm_index_tag\"]          = -zscore(gdf.loc[mask_all, \"laerm_index_tag\"])\n",
    "\n",
    "# Kitas\n",
    "gdf.loc[mask_all, \"z_kita_distance\"]            = -zscore(gdf.loc[mask_all, \"kitas_min_distance_m\"])\n",
    "gdf.loc[mask_all, \"z_kita_near_500\"]            =  zscore(gdf.loc[mask_all, \"kitas_count_within_500m\"])\n",
    "gdf.loc[mask_all, \"z_kita_near_800\"]            =  zscore(gdf.loc[mask_all, \"kitas_count_within_800m\"])\n",
    "gdf.loc[mask_all, \"z_kita_near_1000\"]           =  zscore(gdf.loc[mask_all, \"kitas_count_within_1000m\"])\n",
    "\n",
    "# Grundschulen\n",
    "gdf.loc[mask_all, \"z_grundschulen_distance\"]    = -zscore(gdf.loc[mask_all, \"grundschulen_min_distance_m\"])\n",
    "gdf.loc[mask_all, \"z_grundschulen_near_500\"]    =  zscore(gdf.loc[mask_all, \"grundschulen_count_within_500m\"])\n",
    "gdf.loc[mask_all, \"z_grundschulen_near_800\"]    =  zscore(gdf.loc[mask_all, \"grundschulen_count_within_800m\"])\n",
    "gdf.loc[mask_all, \"z_grundschulen_near_1000\"]   =  zscore(gdf.loc[mask_all, \"grundschulen_count_within_1000m\"])\n",
    "\n",
    "# Mobilität\n",
    "gdf.loc[mask_all, \"z_haltestelle_distance\"]     = -zscore(gdf.loc[mask_all, \"haltestellen_min_distance_m\"])\n",
    "gdf.loc[mask_all, \"z_haltestellen_count_within_500m\"] =  zscore(gdf.loc[mask_all, \"haltestellen_count_within_500m\"])\n",
    "gdf.loc[mask_all, \"z_haltestellen_count_within_800m\"] =  zscore(gdf.loc[mask_all, \"haltestellen_count_within_800m\"])\n",
    "gdf.loc[mask_all, \"z_headway_score\"]            = -zscore(gdf.loc[mask_all, \"headway_avg\"])\n",
    "\n",
    "# Medizinische Versorgung\n",
    "gdf.loc[mask_all, \"z_medzentrum_distance\"]      = -zscore(gdf.loc[mask_all, \"medzentren_min_distance_m\"])\n",
    "gdf.loc[mask_all, \"z_medzentrum_near_500\"]      =  zscore(gdf.loc[mask_all, \"medzentren_count_within_500m\"])\n",
    "gdf.loc[mask_all, \"z_medzentrum_near_800\"]      =  zscore(gdf.loc[mask_all, \"medzentren_count_within_800m\"])\n",
    "gdf.loc[mask_all, \"z_medzentrum_near_1000\"]     =  zscore(gdf.loc[mask_all, \"medzentren_count_within_1000m\"])\n",
    "\n",
    "# Grünflächen\n",
    "gdf.loc[mask_all, \"z_gruen_distance\"]           = -zscore(gdf.loc[mask_all, \"gruen_min_distance_m\"])\n",
    "gdf.loc[mask_all, \"z_gruen_near_500\"]           =  zscore(gdf.loc[mask_all, \"gruen_count_within_500m\"])\n",
    "gdf.loc[mask_all, \"z_gruen_near_800\"]           =  zscore(gdf.loc[mask_all, \"gruen_count_within_800m\"])\n",
    "gdf.loc[mask_all, \"z_gruen_near_1000\"]          =  zscore(gdf.loc[mask_all, \"gruen_count_within_1000m\"])\n",
    "\n",
    "# Gewerbe (Industrie) -> weiter weg = gut\n",
    "mask_mm_gewerbe = gdf[\"dist_gross_gewerbe\"].notna()\n",
    "gdf.loc[mask_mm_gewerbe, \"z_dist_gross_gewerbe\"] = zscore(gdf.loc[mask_mm_gewerbe, \"dist_gross_gewerbe\"])\n",
    "\n",
    "# Gruen -> näher = gut\n",
    "mask_mm_gruen = gdf[\"dist_gross_gruen\"].notna()\n",
    "gdf.loc[mask_mm_gruen, \"z_dist_gross_gruen\"]    = -zscore(gdf.loc[mask_mm_gruen, \"dist_gross_gruen\"])\n",
    "\n",
    "# Sonstiges (Wasser) -> näher = gut\n",
    "mask_mm_sonst = gdf[\"dist_gross_sonstiges\"].notna()\n",
    "gdf.loc[mask_mm_sonst, \"z_dist_gross_sonstiges\"] = -zscore(gdf.loc[mask_mm_sonst, \"dist_gross_sonstiges\"])\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# 3) Score-Dimensionen (alle Summen = 1.0)\n",
    "# ---------------------------------------\n",
    "\n",
    "### 3.1 Zentralität (1 Dimension, Summe = 1.0)\n",
    "mask_mm_central = gdf[\"center_distance_m\"].notna()\n",
    "gdf.loc[mask_mm_central, \"score_zentralitaet\"] = gdf.loc[mask_mm_central, \"z_centrality\"]\n",
    "\n",
    "\n",
    "### 3.2 Versorgung (Summe = 1.0)\n",
    "mask_mm_versorgung = gdf[[\n",
    "    \"einzelhandel_min_distance_m\",\n",
    "    \"einzelhandel_500m_count\",\n",
    "    \"einzelhandel_800m_count\",\n",
    "    \"einzelhandel_1000m_count\",\n",
    "    \"medzentren_min_distance_m\",\n",
    "    \"medzentren_count_within_500m\",\n",
    "    \"medzentren_count_within_800m\",\n",
    "    \"medzentren_count_within_1000m\"\n",
    "]].notna().all(axis=1)\n",
    "\n",
    "gdf.loc[mask_mm_versorgung, \"score_versorgung\"] = (\n",
    "      0.15 * gdf.loc[mask_mm_versorgung, \"z_einzelhandel_distance\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_versorgung, \"z_einzelhandel_near_500\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_versorgung, \"z_einzelhandel_near_800\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_versorgung, \"z_einzelhandel_near_1000\"]\n",
    "    + 0.15 * gdf.loc[mask_mm_versorgung, \"z_medzentrum_distance\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_versorgung, \"z_medzentrum_near_500\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_versorgung, \"z_medzentrum_near_800\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_versorgung, \"z_medzentrum_near_1000\"]\n",
    ")\n",
    "\n",
    "\n",
    "### 3.3 Mobilität (Summe = 1.0)\n",
    "mask_mm_mobilitaet = gdf[[\n",
    "    \"headway_avg\",\n",
    "    \"haltestellen_min_distance_m\",\n",
    "    \"haltestellen_count_within_500m\",\n",
    "    \"haltestellen_count_within_800m\"\n",
    "]].notna().all(axis=1)\n",
    "\n",
    "gdf.loc[mask_mm_mobilitaet, \"score_mobilitaet\"] = (\n",
    "      0.40 * gdf.loc[mask_mm_mobilitaet, \"z_headway_score\"]\n",
    "    + 0.40 * gdf.loc[mask_mm_mobilitaet, \"z_haltestelle_distance\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_mobilitaet, \"z_haltestellen_count_within_500m\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_mobilitaet, \"z_haltestellen_count_within_800m\"]\n",
    ")\n",
    "\n",
    "\n",
    "### 3.4 Bildung (Summe = 1.0)\n",
    "mask_mm_bildung = gdf[[\n",
    "    \"kitas_min_distance_m\",\n",
    "    \"kitas_count_within_500m\",\n",
    "    \"kitas_count_within_800m\",\n",
    "    \"kitas_count_within_1000m\",\n",
    "    \"grundschulen_min_distance_m\",\n",
    "    \"grundschulen_count_within_500m\",\n",
    "    \"grundschulen_count_within_800m\",\n",
    "    \"grundschulen_count_within_1000m\"\n",
    "]].notna().all(axis=1)\n",
    "\n",
    "gdf.loc[mask_mm_bildung, \"score_bildung\"] = (\n",
    "      0.15 * gdf.loc[mask_mm_bildung, \"z_kita_distance\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_bildung, \"z_kita_near_500\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_bildung, \"z_kita_near_800\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_bildung, \"z_kita_near_1000\"]\n",
    "    + 0.15 * gdf.loc[mask_mm_bildung, \"z_grundschulen_distance\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_bildung, \"z_grundschulen_near_500\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_bildung, \"z_grundschulen_near_800\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_bildung, \"z_grundschulen_near_1000\"]\n",
    ")\n",
    "\n",
    "\n",
    "### 3.5 Umwelt (Summe = 1.0)\n",
    "# Umwelt (Summe = 1.0)\n",
    "mask_mm_umwelt = gdf[[\n",
    "    \"gruen_min_distance_m\",\n",
    "    \"gruen_count_within_500m\",\n",
    "    \"gruen_count_within_800m\",\n",
    "    \"gruen_count_within_1000m\",\n",
    "    \"laerm_index_tag\",\n",
    "    \"z_dist_gross_gewerbe\",\n",
    "    \"z_dist_gross_gruen\",\n",
    "    \"z_dist_gross_sonstiges\"\n",
    "]].notna().all(axis=1)\n",
    "\n",
    "gdf.loc[mask_mm_umwelt, \"score_umwelt\"] = (\n",
    "      0.30 * gdf.loc[mask_mm_umwelt, \"z_gruen_distance\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_umwelt, \"z_gruen_near_500\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_umwelt, \"z_gruen_near_800\"]\n",
    "    + 0.05 * gdf.loc[mask_mm_umwelt, \"z_gruen_near_1000\"]\n",
    "    + 0.15 * gdf.loc[mask_mm_umwelt, \"z_laerm_index_tag\"]\n",
    "    + 0.15 * gdf.loc[mask_mm_umwelt, \"z_dist_gross_gewerbe\"]     # Industrie\n",
    "    + 0.10 * gdf.loc[mask_mm_umwelt, \"z_dist_gross_gruen\"]       # Grün\n",
    "    + 0.05 * gdf.loc[mask_mm_umwelt, \"z_dist_gross_sonstiges\"]   # Wasser\n",
    ")\n",
    "\n",
    "# ---------------------------------------\n",
    "# 4) Gesamt-Score (alle Dimensionen verfügbar)\n",
    "# ---------------------------------------\n",
    "score_all_vars = [\n",
    "    \"score_zentralitaet\",\n",
    "    \"score_bildung\",\n",
    "    \"score_versorgung\",\n",
    "    \"score_umwelt\",\n",
    "    \"score_mobilitaet\"\n",
    "]\n",
    "\n",
    "mask_all_scores = gdf[score_all_vars].notna().all(axis=1)\n",
    "\n",
    "gdf.loc[mask_all_scores, \"score_total\"] = (\n",
    "      0.20 * gdf.loc[mask_all_scores, \"score_zentralitaet\"]\n",
    "    + 0.20 * gdf.loc[mask_all_scores, \"score_bildung\"]\n",
    "    + 0.20 * gdf.loc[mask_all_scores, \"score_versorgung\"]\n",
    "    + 0.20 * gdf.loc[mask_all_scores, \"score_umwelt\"]\n",
    "    + 0.20 * gdf.loc[mask_all_scores, \"score_mobilitaet\"]\n",
    ")\n",
    "\n",
    "print(\"Anzahl gültiger Gesamt-Scores:\", gdf[\"score_total\"].notna().sum())\n"
   ],
   "id": "36111c65c1e0e5b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Validierung\n",
    "\n",
    "Im Folgenden werden die Z-Variablen genutzt, um mittels K-Means-Clustering Wohnlagen zu identifizieren. Zunächst wird die optimale Clusteranzahl mittels Elbow-Methode und Silhouetten-Analyse bestimmt. Danach wird das finale K-Means-Modell mit der gewählten Clusteranzahl trainiert und die Wohnlagen den Adressen zugewiesen."
   ],
   "id": "38efad5274a30e01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------\n",
    "# Z-Variablen aus allen Kategorien\n",
    "# ---------------------------------------\n",
    "z_vars = [\n",
    "    # Zentralität\n",
    "    \"z_centrality\",\n",
    "\n",
    "    # Einzelhandel\n",
    "    \"z_einzelhandel_distance\",\n",
    "    \"z_einzelhandel_near_500\",\n",
    "    \"z_einzelhandel_near_800\",\n",
    "    \"z_einzelhandel_near_1000\",\n",
    "\n",
    "    # Lärm\n",
    "    \"z_laerm_index_tag\",\n",
    "\n",
    "    # Kitas\n",
    "    \"z_kita_distance\",\n",
    "    \"z_kita_near_500\",\n",
    "    \"z_kita_near_800\",\n",
    "    \"z_kita_near_1000\",\n",
    "\n",
    "    # Grundschulen\n",
    "    \"z_grundschulen_distance\",\n",
    "    \"z_grundschulen_near_500\",\n",
    "    \"z_grundschulen_near_800\",\n",
    "    \"z_grundschulen_near_1000\",\n",
    "\n",
    "    # Haltestellen / Headway\n",
    "    \"z_haltestelle_distance\",\n",
    "    \"z_haltestellen_count_within_500m\",\n",
    "    \"z_haltestellen_count_within_800m\",\n",
    "    \"z_headway_score\",\n",
    "\n",
    "    # MedZentren\n",
    "    \"z_medzentrum_distance\",\n",
    "    \"z_medzentrum_near_500\",\n",
    "    \"z_medzentrum_near_800\",\n",
    "    \"z_medzentrum_near_1000\",\n",
    "\n",
    "    # Grünflächen\n",
    "    \"z_gruen_distance\",\n",
    "    \"z_gruen_near_500\",\n",
    "    \"z_gruen_near_800\",\n",
    "    \"z_gruen_near_1000\",\n",
    "\n",
    "    # Distanzen zu Großflächen\n",
    "    \"z_dist_gross_gewerbe\",\n",
    "    \"z_dist_gross_gruen\",\n",
    "    \"z_dist_gross_sonstiges\",\n",
    "\n",
    "    # Barriere\n",
    "    \"behind_rail_from_center\"\n",
    "]\n",
    "\n",
    "# ---------------------------------------\n",
    "# Validierung\n",
    "# ---------------------------------------\n",
    "missing = [c for c in z_vars if c not in gdf.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Diese Z-Variablen fehlen im gdf: {missing}\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# Datenmatrix: nur vollständige Zeilen\n",
    "# ---------------------------------------\n",
    "X = gdf[z_vars].dropna().values\n",
    "\n",
    "# ---------------------------------------\n",
    "# Elbow-Methode\n",
    "# ---------------------------------------\n",
    "inertia = []\n",
    "cluster_range = range(2, 20)\n",
    "\n",
    "for k in cluster_range:\n",
    "    model = KMeans(n_clusters=k, random_state=42)\n",
    "    model.fit(X)\n",
    "    inertia.append(model.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(cluster_range, inertia, marker='o')\n",
    "plt.title(\"Elbow-Methode: KMeans-Inertia vs. Clusteranzahl\")\n",
    "plt.xlabel(\"Anzahl Cluster (k)\")\n",
    "plt.ylabel(\"Inertia (Distanz innerhalb der Cluster)\")\n",
    "plt.xticks(cluster_range)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "a25fef9d8bf060c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Silhouetten-Analyse\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouettes = []\n",
    "\n",
    "for k in cluster_range:\n",
    "    model = KMeans(n_clusters=k, random_state=42)\n",
    "    labels = model.fit_predict(X)\n",
    "    score = silhouette_score(X, labels, random_state=42)\n",
    "    silhouettes.append(score)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(cluster_range, silhouettes, marker='o', color=\"green\")\n",
    "plt.title(\"Silhouetten-Score pro Clusteranzahl\")\n",
    "plt.xlabel(\"Anzahl Cluster (k)\")\n",
    "plt.ylabel(\"Durchschn. Silhouetten-Koeffizient\")\n",
    "plt.xticks(cluster_range)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "dd61e3f41e78504d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------\n",
    "# 1) KMeans\n",
    "# ----------------------------\n",
    "X = gdf[z_vars].dropna().values  # Nur vollständige Zeilen\n",
    "\n",
    "# Die Anzahl der Cluster muss anhand der obigen Scores eingeschätzt und festgelegt werden\n",
    "NUMBER_OF_CLUSTERS = 13\n",
    "\n",
    "model = KMeans(n_clusters=NUMBER_OF_CLUSTERS, random_state=42).fit(X)\n",
    "\n",
    "mask_complete = gdf[z_vars].notna().all(axis=1)\n",
    "gdf.loc[mask_complete, \"cluster\"] = model.labels_\n",
    "\n",
    "cluster_centers = pd.DataFrame(model.cluster_centers_, columns=z_vars)\n",
    "cluster_centers.index.name = \"Cluster\"\n",
    "print(cluster_centers.round(2))\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2) PCA (3D + 2D)\n",
    "# ----------------------------\n",
    "X_scaled = X  # Z-Scores → keine Skalierung nötig\n",
    "\n",
    "# 3 Komponenten für 3D-Plot\n",
    "pca3 = PCA(n_components=3, random_state=42)\n",
    "X_pca3 = pca3.fit_transform(X_scaled)\n",
    "print(\"Explained variance ratio (3 PCs):\", pca3.explained_variance_ratio_)\n",
    "\n",
    "# ----------------------------\n",
    "# 3) 3D-PCA Scatterplot\n",
    "# ----------------------------\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "cmap = plt.get_cmap(\"tab10\")\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    X_pca3[:, 0],\n",
    "    X_pca3[:, 1],\n",
    "    X_pca3[:, 2],\n",
    "    c=model.labels_,\n",
    "    cmap=cmap,\n",
    "    s=20,\n",
    "    alpha=0.6\n",
    ")\n",
    "\n",
    "# Optional: Cluster-Zentren im PCA Raum\n",
    "centers_pca3 = pca3.transform(cluster_centers.to_numpy())\n",
    "ax.scatter(\n",
    "    centers_pca3[:, 0],\n",
    "    centers_pca3[:, 1],\n",
    "    centers_pca3[:, 2],\n",
    "    c=range(NUMBER_OF_CLUSTERS),\n",
    "    cmap=cmap,\n",
    "    s=200,\n",
    "    marker=\"X\",\n",
    "    edgecolor=\"black\"\n",
    ")\n",
    "\n",
    "ax.set_title(\"KMeans-Cluster (3D PCA Projektion)\")\n",
    "ax.set_xlabel(\"PC1\")\n",
    "ax.set_ylabel(\"PC2\")\n",
    "ax.set_zlabel(\"PC3\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Klassischer 2D PCA Plot\n",
    "# ----------------------------\n",
    "pca2 = PCA(n_components=2, random_state=42)\n",
    "X_pca2 = pca2.fit_transform(X_scaled)\n",
    "print(\"Explained variance ratio (2 PCs):\", pca2.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_pca2[:,0], X_pca2[:,1], c=model.labels_, cmap=cmap, alpha=0.6)\n",
    "plt.title(\"KMeans-Cluster (PCA 2D-Projektion)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()\n"
   ],
   "id": "2a3ba24b6de7a923",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "\n",
    "gdf = gdf[gdf[\"lat\"].notna() & gdf[\"lon\"].notna() & gdf[\"cluster\"].notna()]\n",
    "gdf[\"cluster\"] = gdf[\"cluster\"].astype(int)\n",
    "\n",
    "# Farbpalette für Cluster\n",
    "cluster_colors = {\n",
    "    0:  \"#e41a1c\",  # kräftiges Rot\n",
    "    1:  \"#377eb8\",  # kräftiges Blau\n",
    "    2:  \"#4daf4a\",  # kräftiges Grün\n",
    "    3:  \"#984ea3\",  # kräftiges Lila\n",
    "    4:  \"#ff7f00\",  # Orange\n",
    "    5:  \"#ffff33\",  # Gelb (klar sichtbar)\n",
    "    6:  \"#a65628\",  # Braun\n",
    "    7:  \"#f781bf\",  # Pink\n",
    "    8:  \"#999999\",  # Mittelgrau\n",
    "    9:  \"#1b9e77\",  # türkis-grün (klar unterscheidbar von grün)\n",
    "    10: \"#d95f02\",  # warmes Orange (andere Familie als #ff7f00)\n",
    "    11: \"#7570b3\",  # Blau-Lila (gut unterscheidbar von 1 & 3)\n",
    "    12: \"#e7298a\",  # Magenta\n",
    "    13: \"#66a61e\",  # Olivgrün (Matt → weit von #4daf4a)\n",
    "    14: \"#e6ab02\",  # Senfgelb\n",
    "    15: \"#a6761d\",  # Ocker\n",
    "    16: \"#666666\",  # Dunkelgrau\n",
    "    17: \"#1f78b4\",  # Dunkelblau (kräftig unterscheidbar)\n",
    "    18: \"#b2df8a\",  # helles, aber eindeutig blasses Grün\n",
    "    19: \"#6a3d9a\",  # Dunkellila\n",
    "}\n",
    "\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Add layer markers\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/einzelhandel_geocoded.csv\", color=\"blue\", icon=\"shopping-cart\", layer_name=\"Einzelhandel\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/grundschulen_geocoded.csv\", color=\"green\", icon=\"graduation-cap\", layer_name=\"Grundschulen\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/kitas_geocoded.csv\", color=\"beige\", icon=\"child\", layer_name=\"Kitas\")\n",
    "#add_markers_from_csv(map_obj=m,csv_path=\"data/haltestellen_geocoded.csv\",color=\"lightgray\", icon=\"bus\", layer_name=\"Haltestellen\")\n",
    "\n",
    "valid_kita_json = gdf[\"kitas_route\"].apply(lambda x: isinstance(x, str))\n",
    "print(\"Gültige JSON-Einträge:\", valid_kita_json.sum(), \"/\", len(gdf))\n",
    "\n",
    "for _, r in gdf.iterrows():\n",
    "    c = cluster_colors.get(r.cluster, \"#666666\")\n",
    "    folium.CircleMarker(\n",
    "        location=[r.lat, r.lon],\n",
    "        radius=3,\n",
    "        color=c,\n",
    "        fill=True,\n",
    "        fill_color=c,\n",
    "        fill_opacity=0.85,\n",
    "        tooltip=f\"{r.Straßenname} {r.Hsnr} – Cluster {r.cluster}\"\n",
    "    ).add_to(m)\n",
    "\n",
    "# Optional: Layer Control\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "print(gdf.shape)\n",
    "\n",
    "#m.save(\"wohnlagen_clusterkarte.html\")\n",
    "m"
   ],
   "id": "19db7c7c67edc72a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Nur Spalten verwenden, die im gdf enthalten sind\n",
    "cols = [col for col in z_vars if col in gdf.columns]\n",
    "\n",
    "# Korrelationsmatrix berechnen\n",
    "corr = gdf[cols].corr()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(corr, annot=True, cmap=\"vlag\", center=0)\n",
    "plt.title(\"Korrelationsmatrix der Z-Scores\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "3884a510fe473e01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Die Korrelationsanalyse zeigt, dass einige Variablen stark korreliert sind, z. B. die verschiedenen Distanzen zu Einzelhandelsstandorten und die Anzahl der Standorte in der Nähe. Dies ist zu erwarten, da Adressen, die näher an Einzelhandelsstandorten liegen, tendenziell auch mehr Standorte in ihrer Umgebung haben. Gleichzeitig ist die Zentralität erwartungskonform leicht mit der Verfügbarkeit von Nahversorgung (Einkaufsmöglichkeiten, medizinische Versorgung, Kitas) korreliert. Diese Erkenntnisse sind Hinweise auf die Plausibilität des Modells, wobei gleichzeitg keine perfekten Korrelationen vorliegen, die auf Redundanzen hindeuten würden. Alle bisher betrachteten Kriterien scheinen relevante und unterschiedliche Aspekte der Wohnlage zu erfassen.",
   "id": "93a582f2058f2e79"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Interaktive Karte für Bewertung einzelner Adressen",
   "id": "1495801883de52ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Widget für Adresseingabe\n",
    "text_input = widgets.Text(\n",
    "    value='Immenweg 56',\n",
    "    placeholder='Straßenname Hausnummer',\n",
    "    description='Adresse:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Button\n",
    "button = widgets.Button(description=\"Zeige Routen\")\n",
    "\n",
    "# Ausgabe-Bereich für die Karte\n",
    "output = widgets.Output()\n",
    "\n",
    "# Funktion zum Einfügen einer Route + Zielmarker\n",
    "def add_route(m, geojson_str, color, label, icon, distance=None):\n",
    "    if isinstance(geojson_str, str):\n",
    "        try:\n",
    "            geo = json.loads(geojson_str)\n",
    "            if geo.get(\"type\") == \"LineString\":\n",
    "                coords = [(y, x) for x, y in geo[\"coordinates\"]]\n",
    "                distance_text = f\" – {int(distance)} m\" if distance else \"\"\n",
    "                tooltip_text = f\"{label}{distance_text}\"\n",
    "\n",
    "                folium.PolyLine(\n",
    "                    locations=coords,\n",
    "                    color=color,\n",
    "                    weight=4,\n",
    "                    opacity=0.9,\n",
    "                    tooltip=tooltip_text\n",
    "                ).add_to(m)\n",
    "\n",
    "                end = coords[-1]\n",
    "                folium.Marker(\n",
    "                    location=end,\n",
    "                    icon=folium.Icon(color=color, icon=icon, prefix=\"fa\"),\n",
    "                    tooltip=f\"Ziel: {label}{distance_text}\"\n",
    "                ).add_to(m)\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler bei {label}: {e}\")\n",
    "\n",
    "# Funktion zum Anzeigen der Karte\n",
    "def show_routes():\n",
    "    with output:\n",
    "        clear_output()\n",
    "        addr = text_input.value.strip().lower()\n",
    "\n",
    "        filtered = gdf[gdf[\"Adresse_merge\"].str.lower().str.contains(addr)]\n",
    "        if filtered.empty:\n",
    "            print(\"Keine Adresse gefunden.\")\n",
    "            return\n",
    "\n",
    "        row = filtered.iloc[0]\n",
    "        m = folium.Map(location=[row.lat, row.lon], zoom_start=15, tiles=\"cartodbpositron\")\n",
    "        folium.Marker(location=[row.lat, row.lon], tooltip=\"Adresse\").add_to(m)\n",
    "\n",
    "        # ▸ Routen einfügen\n",
    "        add_route(m, row.get(\"center_route\"), \"lightgray\", \"Weg zum Zentrum\", \"arrows-to-circle\", row.get(\"center_distance_m\"))\n",
    "        add_route(m, row.get(\"kitas_route\"), \"orange\", \"Nächste Kita\", \"child\", row.get(\"kitas_min_distance_m\"))\n",
    "        add_route(m, row.get(\"grundschulen_route\"), \"green\", \"Nächste Grundschule\", \"graduation-cap\", row.get(\"grundschulen_min_distance_m\"))\n",
    "        add_route(m, row.get(\"haltestellen_route\"), \"gray\", \"Nächste Haltestelle\", \"bus\", row.get(\"haltestellen_min_distance_m\"))\n",
    "        add_route(m, row.get(\"medzentren_route\"), \"red\", \"Nächstes Medizinisches Zentrum\", \"staff-snake\", row.get(\"medzentren_min_distance_m\"))\n",
    "        add_route(m, row.get(\"einzelhandel_route\"), \"blue\", \"Nächster Einzelhandel\", \"shop\", row.get(\"einzelhandel_min_distance_m\"))\n",
    "        add_route(m, row.get(\"gruen_route\"), \"green\", \"Nächste Freizeit- und Erholungsfläche\", \"tree\", row.get(\"gruen_min_distance_m\"))\n",
    "        display(m)\n",
    "\n",
    "# Button-Event\n",
    "button.on_click(show_routes)\n",
    "\n",
    "# UI anzeigen\n",
    "display(text_input, button, output)\n",
    "\n",
    "m"
   ],
   "id": "1505678dc5e76d43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Glättung zur Vermeidung von \"Insellagen\"\n",
    "Ein Ziel der Analyse ist die Entwicklung zusammenhängender Gebiete, die einer gemeinsamen Wohnlage zugeordnet werden können. Damit sollen \"Insellagen\", also mehrere abgeschnittene Bereiche mit derselben Wohnlage vermieden werden. Dafür wenden wir im Folgenden eine Glättung mit dem SKATER-Ansatz an (vgl. [Assunção et al. 2006](https://www.tandfonline.com/doi/abs/10.1080/13658810600665111])).\n",
    "\n",
    "Standardmäßig wird Queen-Kontinuität für die Nachbarschaftsdefinition verwendet. Da unsere Adressen jedoch als Punkte vorliegen, verwenden wir stattdessen k-Nearest-Neighbors (kNN) mit k=15, um eine ausreichende Vernetzung sicherzustellen. Zusätzlich wird ein Gabriel-Graph über die Punkte gelegt, um die Konnektivität weiter zu verbessern und Cluster auch über größere Distanzen zu ermöglichen (z. B. entlang von Hauptverkehrsachsen) und räumlich korrekte Cluster zu erzeugen."
   ],
   "id": "e06cb92a06290d6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from libpysal import weights\n",
    "from spopt.region import Skater\n",
    "\n",
    "# Schritt 1: Erzeuge Gewichtsmatrix für SKATER mit Queen-Kontiguität\n",
    "W = weights.contiguity.Queen.from_dataframe(gdf, use_index=True)\n",
    "\n",
    "# Schritt 2: Wähle Attribute für SKATER\n",
    "# ---- SKATER nur mit den Score-Variablen füttern --------\n",
    "# Keine Routen-Variablen\n",
    "score_vars = [var for var in score_vars if not var.endswith(\"_route\")]\n",
    "\n",
    "# Keine Zentrumsdistanz, um konzentrische Cluster zu vermeiden\n",
    "if \"center_distance_m\" in score_vars:\n",
    "    score_vars.remove(\"center_distance_m\")\n",
    "\n",
    "# Auswahl der Variablen basierend auf Korrelationsanalyse und inhaltlicher Relevanz\n",
    "attrs = [\n",
    "    # Lage\n",
    "    \"z_centrality\",\n",
    "    \"z_laerm_index_tag\",\n",
    "\n",
    "    # Grün/Wasser\n",
    "    \"z_gruen_distance\",\n",
    "    \"z_dist_gross_gruen\",\n",
    "    \"z_dist_gross_sonstiges\",\n",
    "\n",
    "    # ÖPNV\n",
    "    \"z_haltestelle_distance\",\n",
    "    \"z_headway_score\",\n",
    "\n",
    "    # Bildung\n",
    "    \"z_kita_distance\",\n",
    "    \"z_grundschulen_distance\",\n",
    "\n",
    "    # Versorgung\n",
    "    \"z_medzentrum_distance\",\n",
    "    \"z_einzelhandel_distance\",\n",
    "\n",
    "    # Industrie (negativ)\n",
    "    \"z_dist_gross_gewerbe\",\n",
    "\n",
    "    # Barriere\n",
    "    \"behind_rail_from_center\",\n",
    "\n",
    "    # Nutzungsklassen (weiche Struktur)\n",
    "    \"nutz_Wohnen\",\n",
    "    \"nutz_Gruen\",\n",
    "    \"nutz_Gemischt\",\n",
    "    \"nutz_Gewerbe\",\n",
    "    \"nutz_Verkehr\",\n",
    "]\n",
    "\n",
    "# Schritt 3: SKATER ausführen\n",
    "sk = Skater(\n",
    "    gdf, W, attrs,\n",
    "    n_clusters=NUMBER_OF_CLUSTERS,\n",
    "    islands = \"increase\",\n",
    ")\n",
    "sk.solve()\n",
    "\n",
    "gdf[\"cluster_skater\"] = sk.labels_"
   ],
   "id": "99063ccb0de835ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd, folium\n",
    "\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"cartodbpositron\")\n",
    "cluster_colors = {\n",
    "    0:  \"#e41a1c\",  # kräftiges Rot\n",
    "    1:  \"#377eb8\",  # kräftiges Blau\n",
    "    2:  \"#4daf4a\",  # kräftiges Grün\n",
    "    3:  \"#984ea3\",  # kräftiges Lila\n",
    "    4:  \"#ff7f00\",  # Orange\n",
    "    5:  \"#ffff33\",  # Gelb\n",
    "    6:  \"#a65628\",  # Braun\n",
    "    7:  \"#f781bf\",  # Pink\n",
    "    8:  \"#999999\",  # Mittelgrau\n",
    "    9:  \"#1b9e77\",  # türkis-grün\n",
    "    10: \"#d95f02\",  # warmes Orange\n",
    "    11: \"#7570b3\",  # Blau-Lila\n",
    "    12: \"#e7298a\",  # Magenta\n",
    "    13: \"#66a61e\",  # Olivgrün\n",
    "    14: \"#e6ab02\",  # Senfgelb\n",
    "    15: \"#a6761d\",  # Ocker\n",
    "    16: \"#666666\",  # Dunkelgrau\n",
    "    17: \"#1f78b4\",  # Dunkelblau\n",
    "    18: \"#b2df8a\",  # blasses Grün\n",
    "    19: \"#6a3d9a\",  # Dunkellila\n",
    "}\n",
    "\n",
    "for _, r in gdf.iterrows():\n",
    "    c = cluster_colors.get(r.cluster_skater, \"#666666\")\n",
    "    folium.CircleMarker(\n",
    "        location=[r.lat, r.lon],\n",
    "        radius=3,\n",
    "        color=c,\n",
    "        fill=True,\n",
    "        fill_color=c,\n",
    "        fill_opacity=0.85,\n",
    "        tooltip=f\"{r.Straßenname} {r.Hsnr} – Cluster {r.cluster_skater}\"\n",
    "    ).add_to(m)\n",
    "\n",
    "m"
   ],
   "id": "37bb9529b5b0103a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Lageklassen\n",
    "Abschließend werden die Adressen basierend auf ihrem Gesamt-Score in Lageklassen eingeteilt."
   ],
   "id": "384123854336c785"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def classify_lage_5(score_series):\n",
    "    \"\"\"\n",
    "    5 Klassen: A–E, basierend auf Quintilen\n",
    "    \"\"\"\n",
    "    q20 = score_series.quantile(0.20)\n",
    "    q40 = score_series.quantile(0.40)\n",
    "    q60 = score_series.quantile(0.60)\n",
    "    q80 = score_series.quantile(0.80)\n",
    "\n",
    "    def classify(x):\n",
    "        if pd.isna(x):\n",
    "            return None\n",
    "        if x >= q80:\n",
    "            return \"A – Höchstlage\"\n",
    "        elif x >= q60:\n",
    "            return \"B – Sehr gute Lage\"\n",
    "        elif x >= q40:\n",
    "            return \"C – Gute Lage\"\n",
    "        elif x >= q20:\n",
    "            return \"D – Mittlere Lage\"\n",
    "        else:\n",
    "            return \"E – Einfache Lage\"\n",
    "\n",
    "    return score_series.apply(classify)\n",
    "\n",
    "# Anwendung:\n",
    "gdf[\"lageklasse_5\"] = classify_lage_5(gdf[\"score_total\"])\n",
    "\n",
    "# Farben für Wohnlagen (grün - gelb)\n",
    "color_map = {\n",
    "    \"A – Höchstlage\":             \"#1a9850\",\n",
    "    \"B – Sehr gute Lage\":         \"#66bd63\",\n",
    "    \"C – Gute Lage\":              \"#a6d96a\",\n",
    "    \"D – Mittlere Lage\":          \"#d9ef8b\",\n",
    "    \"E – Einfache Lage\":          \"#fee08b\",\n",
    "}\n",
    "\n",
    "# Kartendarstellung\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"cartodbpositron\")\n",
    "for _, r in gdf.iterrows():\n",
    "    color = color_map.get(r.lageklasse_5, \"lightgray\")\n",
    "    folium.CircleMarker(\n",
    "        location=[r.lat, r.lon],\n",
    "        radius=3,\n",
    "        color=color,\n",
    "        fill=True,\n",
    "        fill_color=color,\n",
    "        fill_opacity=0.85,\n",
    "        tooltip=f\"{r.Straßenname} {r.Hsnr} – Lageklasse: {r.lageklasse_5}\"\n",
    "    ).add_to(m)\n",
    "# Optional: Layer Control\n",
    "folium.LayerControl().add_to(m)\n",
    "m"
   ],
   "id": "f7d880c3117a24a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Abgleich mit Ortsteilen, Quartieren und Mietkategorien\n",
    "Zum Abgleich der ermittelten Wohnlagen mit bestehenden Strukturen werden die Cluster mit den Quartieren und Ortsteilen der Adressen sowie den Mietkategorien (sofern vorhanden) verglichen. In der Kreuztabelle können die Verteilungen der Cluster über die verschiedenen räumlichen Einheiten analysiert werden."
   ],
   "id": "b6194bac21991433"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Ortsteile ergänzen",
   "id": "12be6a23f0356a20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "\n",
    "# Datei laden\n",
    "with open(\"data/ortsteile_brandenburg.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "# FeatureCollection extrahieren\n",
    "features = raw[\"features\"]\n",
    "gdf_ortsteile = gpd.GeoDataFrame.from_features(features)\n",
    "gdf_ortsteile.set_crs(EPSG_4326, inplace=True)\n",
    "gdf_ortsteile = gdf_ortsteile.clip(CITY_BOUNDING_BOX)\n",
    "\n",
    "# Karte zentrieren\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=12, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Tooltip konfigurieren\n",
    "tooltip_fields = [\"otl_name\"]\n",
    "\n",
    "# GeoJSON mit Tooltip zur Karte hinzufügen\n",
    "folium.GeoJson(\n",
    "    gdf_ortsteile,\n",
    "    name=\"Ortsteile\",\n",
    "    tooltip=folium.GeoJsonTooltip(\n",
    "    fields=tooltip_fields,\n",
    "    aliases=[\"Ortsteil\"],\n",
    "    localize=True,\n",
    "    sticky=True\n",
    ")\n",
    ").add_to(m)\n",
    "\n",
    "gdf = gdf.to_crs(EPSG_4326)\n",
    "gdf_ortsteile = gdf_ortsteile.to_crs(EPSG_4326)\n",
    "\n",
    "assert gdf.crs.to_epsg() == 4326\n",
    "assert gdf_ortsteile.crs.to_epsg() == 4326\n",
    "\n",
    "gdf = clean_index_cols(gdf)\n",
    "gdf = gpd.sjoin(gdf, gdf_ortsteile[[\"geometry\", \"otl_name\"]], how=\"left\", predicate=\"within\")\n",
    "gdf = gdf.rename(columns={\"otl_name\": \"ortsteil\"})\n",
    "gdf = gdf.drop(columns=[\"index_right\"], errors=\"ignore\")\n",
    "\n",
    "# Drop rows with NaN lat/lon\n",
    "gdf = gdf.dropna(subset=[\"lat\"])\n",
    "\n",
    "# Karte anzeigen\n",
    "m"
   ],
   "id": "26ee59f7db25614e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Wohnquartiere ergänzen\n",
    "Innerhalb des Stadtgebiets liegen verschiedene Wohnquartiere mit unterschiedlichen Merkmalen. Diese werden den Adressen zugeordnet und zusammen mit den Wohnbezirken visualisiert."
   ],
   "id": "aab87e4f1fa7b642"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "\n",
    "# Geopackage aus Datei laden\n",
    "gdf_quartiere = gpd.read_file(\"data/Quartiere/2024_Quartiere.gpkg\")\n",
    "\n",
    "# Karte zentrieren\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=12, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Ortsteile hinzufügen (s.o.)\n",
    "tooltip_fields = [\"otl_name\"]\n",
    "folium.GeoJson(\n",
    "    gdf_ortsteile,\n",
    "    name=\"Ortsteile\",\n",
    "    tooltip=folium.GeoJsonTooltip(\n",
    "    fields=tooltip_fields,\n",
    "    aliases=[\"Ortsteil\"],\n",
    "    localize=True,\n",
    "    sticky=True\n",
    ")\n",
    ").add_to(m)\n",
    "\n",
    "# Tooltip konfigurieren\n",
    "tooltip_fields = [\"bezeichnun\", \"mietkatego\"]\n",
    "tooltip = folium.GeoJsonTooltip(\n",
    "    fields=tooltip_fields,\n",
    "    aliases=[\"Quartier\", \"Mietkategorie\"],\n",
    "    localize=True,\n",
    "    sticky=True\n",
    ")\n",
    "\n",
    "# GeoJSON mit Tooltip zur Karte hinzufügen als orangefarbener Layer\n",
    "folium.GeoJson(\n",
    "    gdf_quartiere,\n",
    "        style_function=lambda feature: {\n",
    "            'fillColor': 'orange',\n",
    "            'color': 'orange',\n",
    "            'weight': 1,\n",
    "            'fillOpacity': 0.2,\n",
    "        },\n",
    "    name=\"Ortsteile\",\n",
    "    tooltip=tooltip\n",
    ").add_to(m)\n",
    "\n",
    "# CRS angleichen (WGS84)\n",
    "gdf_quartiere = gdf_quartiere.to_crs(4326)\n",
    "gdf = gdf.to_crs(4326)\n",
    "assert gdf.crs.to_epsg() == 4326\n",
    "assert gdf_quartiere.crs.to_epsg() == 4326\n",
    "\n",
    "# alte Spalten sicher entfernen\n",
    "gdf = gdf.drop(columns=[\"index_right\", \"mietkatego\", \"bezeichnun\"], errors=\"ignore\")\n",
    "# Frühere Merge-Spalten entfernen (endet auf _quartier)\n",
    "cols_to_drop = [col for col in gdf.columns if col.endswith(\"_quartier\")]\n",
    "gdf = gdf.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "# sauberes Spatial Join\n",
    "gdf = gpd.sjoin(\n",
    "    gdf,\n",
    "    gdf_quartiere[[\"bezeichnun\", \"mietkatego\", \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    predicate=\"within\",\n",
    ")\n",
    "\n",
    "# Merkmale benennen\n",
    "gdf = gdf.rename(columns={\n",
    "    \"bezeichnun\": \"quartier\",\n",
    "    \"mietkatego\": \"mietkategorie\"\n",
    "})\n",
    "\n",
    "# Karte anzeigen\n",
    "m"
   ],
   "id": "989267310711fa5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Kreuztabelle\n",
    "Innerhalb des Stadtgebiets liegen verschiedene Wohnquartiere mit unterschiedlichen Merkmalen. Diese werden den Adressen zugeordnet und zusammen mit den Wohnbezirken visualisiert.\n"
   ],
   "id": "8c3b97a7c5b43ca7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ct = pd.crosstab(gdf[\"quartier\"], gdf[\"cluster_skater\"], normalize=\"index\")\n",
    "plt.figure(figsize=(14,10))\n",
    "sns.heatmap(ct, cmap=\"viridis\", annot=False)\n",
    "plt.title(\"Quartier vs. SKATER-Cluster (Zeilen normalize: Anteil pro Quartier)\")\n",
    "plt.xlabel(\"SKATER-Cluster\")\n",
    "plt.ylabel(\"Quartier\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "c1c20c5935a39a9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Die Darstellung zeigt, wie sich die automatisch gebildeten SKATER-Cluster auf die bestehenden Wohnquartiere verteilen. Deutlich wird, dass mehrere Quartiere eine klare Dominanz einzelner Cluster aufweisen (z. B. Zentrum, Nord, Görden oder Hohenstücken), was auf eine vergleichsweise homogene interne Struktur schließen lässt. Andere Quartiere, insbesondere jene mit gemischten Nutzungen oder großen räumlichen Ausdehnungen, verteilen sich stärker auf mehrere Cluster. Diese Heterogenität ist erwartbar und spiegelt eher die interne Vielfalt der Quartiere wider als Schwächen im Clustering. Insgesamt zeigt die Heatmap, dass die Clusterbildung bestehende räumliche Zusammenhänge gut trifft.",
   "id": "c598f2340d709d0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ct = pd.crosstab(gdf[\"ortsteil\"], gdf[\"cluster_skater\"], normalize=\"index\")\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(ct, cmap=\"magma\", annot=False)\n",
    "plt.title(\"Ortsteil vs. SKATER-Cluster\")\n",
    "plt.xlabel(\"SKATER-Cluster\")\n",
    "plt.ylabel(\"Ortsteil\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "4a6e1ed31d9df962",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Die Zuordnung der SKATER-Cluster zu den Ortsteilen zeigt überwiegend klare Muster. Viele Ortsteile werden überwiegend einem oder zwei Clustern zugeordnet, was auf eine konsistente und funktional nachvollziehbare Lagecharakteristik schließen lässt. Dies ist besonders bei peripheren oder dörflichen Ortsteilen sichtbar, die sich typischerweise durch ähnliche Infrastrukturausstattung und Distanzlagen auszeichnen. Gleichzeitig treten - abhängig von Größe und Struktur des Ortsteils – einzelne Streuungen auf, die auf interne Unterschiede oder Übergangsbereiche hindeuten können. Insgesamt bestätigt die Darstellung, dass die Cluster auch außerhalb des Kernstadtgebiets sinnvolle, zusammenhängende Lagemuster abbilden.",
   "id": "1e25aeb4bf491452"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ct = pd.crosstab(gdf[\"mietkategorie\"], gdf[\"cluster_skater\"], normalize=\"columns\")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(ct, cmap=\"coolwarm\", annot=True, fmt=\".2f\")\n",
    "plt.title(\"Mietkategorie vs. SKATER-Cluster (Spalten normalize)\")\n",
    "plt.xlabel(\"SKATER-Cluster\")\n",
    "plt.ylabel(\"Mietkategorie\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "895529dbe50c2b6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Die Kreuztabelle zwischen Mietkategorien und SKATER-Clustern dient der ökonomischen Validierung des Modells. Hier zeigt sich, dass bestimmte Cluster deutlich mit niedrigeren, mittleren oder höheren Mietkategorien assoziiert sind. Mehrere Cluster weisen eine hohe Übereinstimmung mit spezifischen Mietniveaus auf, was darauf hinweist, dass die algorithmisch erkannten Lagegruppen auch sozioökonomische Unterschiede in der Wohnlagequalität widerspiegeln. Streuungen in einzelnen Kategorien sind zu erwarten und spiegeln natürliche Übergänge oder heterogene Straßenzüge wider. Insgesamt deutet die Struktur jedoch auf eine plausibel differenzierende Wirkung der Cluster hin.",
   "id": "2f060d1b7ee1eac5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Alle relevanten Z-Variablen für die Clusterinterpretation\n",
    "z_vars = [col for col in gdf.columns if col.startswith(\"z_\")]\n",
    "\n",
    "cluster_profile = gdf.groupby(\"cluster_skater\")[z_vars].mean()\n",
    "\n",
    "plt.figure(figsize=(18,10))\n",
    "sns.heatmap(cluster_profile, cmap=\"coolwarm\", center=0, annot=False)\n",
    "plt.title(\"Feature-Profil der SKATER-Cluster (alle Z-Scores)\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Cluster\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "afa697c7c36a17d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Export-Pipeline",
   "id": "d630ac1d11f4b4f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save GeoDataFrame with scores and clusters as CSV\n",
    "import os\n",
    "\n",
    "# -------------------------------------------\n",
    "# 0) EXPORT-PFAD\n",
    "# -------------------------------------------\n",
    "EXPORT_PATH = \"out\"\n",
    "EXPORT_FILE = os.path.join(EXPORT_PATH, \"wohnlagen_brb.gpkg\")\n",
    "\n",
    "# Ordner anlegen\n",
    "os.makedirs(EXPORT_PATH, exist_ok=True)\n",
    "\n",
    "# Falls alte Datei existiert: löschen (sonst doppelte Layer)\n",
    "if os.path.exists(EXPORT_FILE):\n",
    "    os.remove(EXPORT_FILE)\n",
    "    print(f\"Alte Datei gelöscht: {EXPORT_FILE}\")\n",
    "\n",
    "# -------------------------------------------\n",
    "# 1) HILFSFUNKTION: Sicheres Schreiben\n",
    "# -------------------------------------------\n",
    "\n",
    "def write_layer(gdf, layer_name, crs=EPSG_4326):\n",
    "    \"\"\"\n",
    "    Schreibt einen GeoDataFrame als Layer in die GeoPackage-Datei.\n",
    "    Stellt sicher, dass das CRS korrekt ist.\n",
    "    \"\"\"\n",
    "    if gdf is None or len(gdf) == 0:\n",
    "        print(f\"⚠ Layer '{layer_name}' übersprungen: leer oder None\")\n",
    "        return\n",
    "\n",
    "    # CRS prüfen\n",
    "    if gdf.crs is None:\n",
    "        print(f\"⚠ GDF '{layer_name}' hat kein CRS – setze auf {crs}\")\n",
    "        gdf = gdf.set_crs(crs)\n",
    "    elif gdf.crs.to_string() != crs:\n",
    "        print(f\"🔄 Reprojiziere '{layer_name}' nach {crs}\")\n",
    "        gdf = gdf.to_crs(crs)\n",
    "\n",
    "    # Schreiben\n",
    "    gdf.to_file(EXPORT_FILE, layer=layer_name, driver=\"GPKG\")\n",
    "    print(f\"✔ Exportiert: {layer_name}  →  {EXPORT_FILE}\")\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# 2) LAYER DEFINIEREN\n",
    "# -------------------------------------------\n",
    "# Du kannst hier ALLE relevanten Datensätze aufnehmen:\n",
    "\n",
    "layers = {\n",
    "    \"wohnadressen\": gdf,\n",
    "    \"wohnlagen_score\": gdf[[col for col in gdf.columns if col.startswith(\"score_\") or col in [\"geometry\"]]],\n",
    "    \"cluster_skater\": gdf[[\"cluster_skater\", \"geometry\"]] if \"cluster_skater\" in gdf.columns else None,\n",
    "    \"cluster_kmeans\": gdf[[\"cluster\", \"geometry\"]] if \"cluster\" in gdf.columns else None,\n",
    "    \"lageklassen\": gdf[[\"lageklasse\", \"score_total\", \"geometry\"]] if \"lageklasse\" in gdf.columns else None,\n",
    "\n",
    "    # Infrastruktur-Daten\n",
    "    \"bahnlinien\": rails,\n",
    "    \"gruenflaechen\": gdf_gruen_shape,\n",
    "    #\"laerm_lden\": gdf_laerm,                      # falls du gdf_laerm heißt\n",
    "    \"haltestellen\": gdf_haltestellen if 'gdf_haltestellen' in globals() else None,\n",
    "    #\"medzentren\": gdf_medzentren if 'gdf_medzentren' in globals() else None,\n",
    "    \"kitas\": gdf_kitas if 'gdf_kitas' in globals() else None,\n",
    "    \"grundschulen\": gdf_grundschulen if 'gdf_grundschulen' in globals() else None,\n",
    "    #\"einzelhandel\": gdf_einzelhandel if 'gdf_einzelhandel' in globals() else None,\n",
    "\n",
    "    # Debug-Daten\n",
    "    \"bahnschnitt_debug\": gdf[[\"behind_rail_from_center\", \"center_route\", \"geometry\"]] if \"behind_rail_from_center\" in gdf.columns else None,\n",
    "}\n",
    "\n",
    "# -------------------------------------------\n",
    "# 3) EXPORT AUSFÜHREN\n",
    "# -------------------------------------------\n",
    "\n",
    "print(\"🔁 Exportiere alle Layer …\\n\")\n",
    "\n",
    "for layer_name, layer_gdf in layers.items():\n",
    "    write_layer(layer_gdf, layer_name)\n",
    "\n",
    "print(\"\\n🎉 Fertig! Die GeoPackage-Datei liegt hier:\")\n",
    "print(f\"📦 {EXPORT_FILE}\")\n"
   ],
   "id": "4856ef3797db369e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WohnlagenBRB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

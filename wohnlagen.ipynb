{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e58eeaf9ab328ebb",
   "metadata": {},
   "source": [
    "# Datenvorbereitung\n",
    "Zun√§chst werden f√ºr alle gew√ºnschten Einflussfaktoren die Daten beschafft und in ein CSV-Format mit lat/lon oder GeoJSON-Geoemtry gebracht, sodass zu allen Adressen die gew√ºnschten Eigenschaften vorliegen."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "from shapely.geometry import box\n",
    "\n",
    "from helper import load_geocsv, s\n",
    "\n",
    "EPSG_4326 = \"EPSG:4326\"\n",
    "\n",
    "# BBOX f√ºr Brandenburg an der Havel\n",
    "CITY_BOUNDING_BOX = box(12.3120236786, 52.2938432979, 12.7562682548, 52.5594777244)\n",
    "\n",
    "#  Stadtzentrum f√ºr Brandenburg an der Havel\n",
    "CITY_CENTER = (52.4116351153561, 12.556331280534392)"
   ],
   "id": "c50d60922d6f74cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Adressen einlesen\n",
    "Alle Adressen des Zielgebiets als CSV in einen GeoDataFrame einlesen."
   ],
   "id": "5112fadb5098e98"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gdf = load_geocsv(\"out/adressen_mit_zentrum_routen.csv\")\n",
    "\n",
    "# Adressen ohne Geometrie entfernen\n",
    "gdf = gdf[~gdf.geometry.isna()].copy()"
   ],
   "id": "ef79a64303652c4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Nutzungsart als Merkmal erg√§nzen\n",
    "One-Hot-Encoding f√ºr sp√§tere Modellierung der Bebauungsdichte / Nutzungsart der Adresse."
   ],
   "id": "fe2c80156cb02d38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "gdf_bebauung = gpd.read_file(\"data/Bebauungsdichte/2025_Bebauungsdichte.shp\")\n",
    "gdf_bebauung = gdf_bebauung.to_crs(EPSG_4326)\n",
    "\n",
    "gdf = gpd.sjoin(\n",
    "    gdf,                                    # Punkte\n",
    "    gdf_bebauung[[\"nutzart\", \"geometry\"]],  # Polygone + Nutzungsart\n",
    "    how=\"left\",\n",
    "    predicate=\"within\"                      # point-in-polygon\n",
    ")\n",
    "\n",
    "gdf[\"nutzart\"] = gdf[\"nutzart\"].fillna(\"Unbekannt\")\n"
   ],
   "id": "fe5b562211015fbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mapping = {\n",
    "    \"Wohnbaufl√§che\": \"Wohnen\",\n",
    "    \"Sport-, Freizeit- und Erholungsfl√§che\": \"Gruen\",\n",
    "    \"Fl√§che gemischter Nutzung\": \"Gemischt\",\n",
    "    \"Industrie- und Gewerbefl√§che\": \"Gewerbe\",\n",
    "    \"Stra√üenverkehr\": \"Verkehr\",\n",
    "    \"Weg\": \"Verkehr\",\n",
    "    \"Platz\": \"Verkehr\",\n",
    "    \"Friedhof\": \"Gruen\",\n",
    "    \"Wald\": \"Gruen\",\n",
    "    \"Fl√§che besonderer funktionaler Pr√§gung\": \"Sonstiges\",\n",
    "}\n",
    "\n",
    "# Neues zusammengefasstes Merkmal hinzuf√ºgen\n",
    "gdf[\"nutzklasse\"] = gdf[\"nutzart\"].map(mapping).fillna(\"Sonstiges\")\n",
    "\n",
    "# One-Hot-Encoding der Nutzungsklasse f√ºr numerische Verarbeitung\n",
    "# neu erzeugen\n",
    "gdf_onehot = pd.get_dummies(gdf[\"nutzklasse\"], prefix=\"nutz\", dtype=int)\n",
    "gdf = gdf.join(gdf_onehot)\n",
    "\n",
    "# Fl√§che berechnen (in Meter-CRS)\n",
    "gdf_bebauung_m = gdf_bebauung.to_crs(32633)\n",
    "gdf_bebauung[\"area_sqm\"] = gdf_bebauung_m.area\n",
    "\n",
    "# Klassifizierung NACH mapping\n",
    "gdf_bebauung[\"nutzklasse\"] = gdf_bebauung[\"nutzart\"].map(mapping).fillna(\"Sonstiges\")\n",
    "\n",
    "# Filter gro√üe Fl√§chen (Schwellwert flexibel)\n",
    "MIN_AREA = 30000\n",
    "gdf_large = gdf_bebauung[gdf_bebauung[\"area_sqm\"] > MIN_AREA].copy()\n",
    "gdf\n"
   ],
   "id": "24f82d6f2ca4b91a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Farben f√ºr jede nutzklasse\n",
    "klassen = gdf_large[\"nutzklasse\"].unique()\n",
    "cmap = plt.colormaps[\"Set2\"]\n",
    "colors = {k: mcolors.to_hex(cmap(i / len(klassen))) for i, k in enumerate(klassen)}\n",
    "\n",
    "# Karte initialisieren\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"OpenStreetMap\")\n",
    "\n",
    "# Ein Layer pro Klasse anlegen\n",
    "layer_map = {}\n",
    "for k in klassen:\n",
    "    layer = folium.FeatureGroup(name=f\"Gro√üe {k}-Fl√§chen (> {MIN_AREA} m¬≤)\", show=True)\n",
    "    layer_map[k] = layer\n",
    "    m.add_child(layer)\n",
    "\n",
    "# Gro√üe Fl√§chen einzeichnen\n",
    "# Transformieren\n",
    "gdf_large_4326 = gdf_large.to_crs(4326)\n",
    "\n",
    "# Vereinfachung (wichtig f√ºr Performance!)\n",
    "gdf_large_4326[\"geometry\"] = gdf_large_4326.geometry.simplify(\n",
    "    tolerance=0.0002,  # ~20 m\n",
    "    preserve_topology=True\n",
    ")\n",
    "\n",
    "\n",
    "for _, row in gdf_large_4326.iterrows():\n",
    "    kls = row[\"nutzklasse\"]\n",
    "    layer = layer_map[kls]\n",
    "\n",
    "    folium.GeoJson(\n",
    "        row.geometry,\n",
    "        style_function=lambda x, k=kls: {\n",
    "            'color': 'black',\n",
    "            'weight': 1,\n",
    "            'fillColor': colors[k],\n",
    "            'fillOpacity': 0.6\n",
    "        },\n",
    "        tooltip=folium.Tooltip(\n",
    "            f\"<b>{row['bez']}</b><br>\"\n",
    "            f\"{kls}<br>\"\n",
    "            f\"Fl√§che: {row['area_sqm']:.0f} m¬≤\"\n",
    "        )\n",
    "    ).add_to(layer)\n",
    "\n",
    "# LayerControl aktivieren\n",
    "folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "# open map in browser\n",
    "m"
   ],
   "id": "bf01154dea7a2cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Explorative Datenanalyse",
   "id": "d082da0d61c0f1d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns           # nur f√ºr sch√∂nere Plots\n",
    "from helper import load_geocsv, make_merge_addr\n",
    "\n",
    "# Eindeutigen Merge-baren String aus Adresse erzeugen\n",
    "gdf[\"Adresse_merge\"] = gdf.apply(make_merge_addr, axis=1)\n",
    "\n",
    "gdf = gdf.rename(columns={\"geojson\": \"center_route\",\n",
    "                                    \"distance_m\" : \"center_distance\"})\n",
    "\n",
    "# Ein paar unben√∂tigte Spalten entfernen\n",
    "gdf = gdf.drop(columns=[\"index_right\", \"duration_s\", \"display_name\", \"type\", \"category\", \"Adresse_query\"], errors=\"ignore\")\n",
    "\n",
    "# Histogramm der Distanzen zum Zentrum\n",
    "plt.figure(figsize=(6,3))\n",
    "sns.histplot(gdf[\"center_distance\"], bins=60, kde=False)\n",
    "plt.title(\"Verteilung der Fu√üentfernung zum Zentrum\")\n",
    "plt.xlabel(\"Distanz (Meter)\")\n",
    "plt.ylabel(\"H√§ufigkeit\")\n",
    "plt.show()\n",
    "print(gdf.shape)\n",
    "print(gdf.columns)"
   ],
   "id": "de62fa81b281925b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Daten bereinigen",
   "id": "f14dc6214657a08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(gdf.shape)\n",
    "# Dubletten aus Adressen entfernen\n",
    "dups = gdf[\"Adresse_merge\"].value_counts()\n",
    "dups = dups[dups > 1]\n",
    "print(f\"{len(dups)} doppelte Adressen gefunden\")\n",
    "print(dups.head())\n",
    "\n",
    "# Ersten Treffer behalten\n",
    "gdf = gdf.sort_values(\"Adresse_merge\").drop_duplicates(\"Adresse_merge\", keep=\"first\")\n",
    "print(gdf.shape)\n"
   ],
   "id": "af2201946c11980d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Einzelhandel\n",
    "Separates Skript ```einzelhandel-adressen.py``` ausf√ºhen, um Datei \"adressen_mit_einzelhandel.csv\" zu erzeugen.\n",
    "Durch fu√ül√§ufiges Routing berechnete Faktoren:\n",
    "- Anzahl von Einkaufsm√∂glichkeiten im Umkreis von 500 m\n",
    "- Anzahl von Einkaufsm√∂glichkeiten im Umkreis von 800 m\n",
    "- Geringste Distanz zum n√§chsten Einzelhandel"
   ],
   "id": "fb6d05a628d926b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns, matplotlib.pyplot as plt\n",
    "\n",
    "# Lade vorberechnete Einzelhandel-Faktoren\n",
    "gdf_retail = load_geocsv(\"out/adressen_mit_einzelhandel_routen.csv\")\n",
    "\n",
    "# Merge mit Haupt-GDF\n",
    "gdf_retail[\"Adresse_merge\"] = gdf_retail.apply(make_merge_addr, axis=1)\n",
    "gdf_retail = gdf_retail.sort_values(\"Adresse_merge\").drop_duplicates(\"Adresse_merge\", keep=\"first\")\n",
    "\n",
    "dups = gdf_retail[\"Adresse_merge\"].value_counts()\n",
    "print(dups[dups > 1])\n",
    "\n",
    "einzelhandel_attribute = [\"einzelhandel_route\",\"einzelhandel_min_distance\", \"einzelhandel_500m_count\", \"einzelhandel_800m_count\", \"einzelhandel_1000m_count\"]\n",
    "\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_retail[[\"Adresse_merge\"] + einzelhandel_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "print(gdf.shape)\n",
    "print(gdf[[\"Adresse_merge\", \"einzelhandel_min_distance\"]].head())\n",
    "\n",
    "print(gdf.shape)\n",
    "\n",
    "# Speicher freigeben\n",
    "del(gdf_retail)"
   ],
   "id": "14c882fa9c070677",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Verteilung Distanz zum n√§chsten Markt\n",
    "print(gdf.columns)\n",
    "sns.histplot(gdf[\"einzelhandel_min_distance\"].dropna(), bins=40, kde=False)\n",
    "plt.title(\"Distanz zum n√§chsten Lebensmittel¬≠markt\")\n",
    "plt.xlabel(\"Meter Fu√üweg\"); plt.ylabel(\"Adressen\")\n",
    "plt.show()\n",
    "\n",
    "# Scatter Zentralit√§t vs. Nahversorgung\n",
    "sns.scatterplot(x=\"center_distance\", y=\"einzelhandel_min_distance\", data=gdf, alpha=.3)\n",
    "plt.xlabel(\"Distanz Zentrum (m)\"); plt.ylabel(\"Distanz n√§chster Markt (m)\")\n",
    "plt.show()"
   ],
   "id": "2425ee38a7ebf529",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## L√§rmbelastung\n",
    "Siehe ```laerm.ipynb``` zur Erzeugung, ansonsten einfach ```data/adressen_mit_laerm.csv``` verwenden und per Spalte 'geometry' verschneiden.\n",
    "\n",
    "Definition L√§rm-Index:\n",
    "- NaN / leer: kein gemessener Stra√üenl√§rm\n",
    "- 0: 55 - 59 dB\n",
    "- 1: 60 - 64 dB\n",
    "- 2: 65 - 69 dB\n",
    "- 3: 70 - 74 dB\n",
    "- 4: >= 75 db"
   ],
   "id": "d0c2655c478327a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gdf_laerm_karte = load_geocsv(\"out/adressen_mit_laerm.csv\")\n",
    "print(gdf_laerm_karte.shape)\n",
    "print(gdf.shape)\n",
    "\n",
    "# Merge des L√§rmindex mit Haupt-GDF\n",
    "gdf_laerm_karte[\"Adresse_merge\"] = gdf_laerm_karte.apply(make_merge_addr, axis=1)\n",
    "gdf_laerm_karte[\"laerm_index_tag\"] = gdf_laerm_karte[\"Laerm_index_tag\"].fillna(-0.1) # lowercase\n",
    "\n",
    "# Deduplicate, im Zweifel nimm den lautesten Wert\n",
    "gdf_laerm_karte = (\n",
    "    gdf_laerm_karte\n",
    "    .sort_values(\"laerm_index_tag\", ascending=False)\n",
    "    .drop_duplicates(\"Adresse_merge\", keep=\"first\")\n",
    ")\n",
    "\n",
    "laerm_attribute = [\"laerm_index_tag\"]\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_laerm_karte[[\"Adresse_merge\"] + laerm_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "\n",
    "#print(gdf.columns)\n",
    "print(gdf.shape)"
   ],
   "id": "f991ebcdf50656b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Bildung\n",
    "Weitere Faktoren\n",
    "- Fu√ül√§ufige Entfernung zur n√§chstgelegenen Kita\n",
    "- Fu√ül√§ufige Entfernung zur n√§chstgelegenen Schule\n",
    "- Anzahl Kitas im Umkreis von 500, 800 und 1000 Metern\n",
    "- Anzahl Schulen im Umkreis von 500, 800 und 1000 Metern"
   ],
   "id": "87cef8c157d06d58"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Daten als GeoDataFrame einlesen\n",
    "gdf_kitas = load_geocsv(\"out/adressen_mit_kitas_routen.csv\")\n",
    "gdf_grundschulen = load_geocsv(\"out/adressen_mit_grundschulen_routen.csv\")\n",
    "print(gdf_kitas.shape)\n",
    "print(gdf_grundschulen.shape)\n",
    "print(gdf.shape)\n",
    "\n",
    "# Eindeutige Adresse f√ºr den Merge generieren\n",
    "gdf_kitas[\"Adresse_merge\"] = gdf_kitas.apply(make_merge_addr, axis=1)\n",
    "gdf_kitas = gdf_kitas.drop_duplicates(\"Adresse_merge\")\n",
    "gdf_grundschulen[\"Adresse_merge\"] = gdf_grundschulen.apply(make_merge_addr, axis=1)\n",
    "gdf_grundschulen = gdf_grundschulen.drop_duplicates(\"Adresse_merge\")\n",
    "\n",
    "# Merge into main gdf\n",
    "kitas_attribute = [\"kitas_min_distance\", \"kitas_route\", \"kitas_count_within_500m\", \"kitas_count_within_800m\", \"kitas_count_within_1000m\"]\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_kitas[[\"Adresse_merge\"] + kitas_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "\n",
    "grundschulen_attribute = [\"grundschulen_min_distance_m\", \"grundschulen_route\", \"grundschulen_count_within_500m\", \"grundschulen_count_within_800m\", \"grundschulen_count_within_1000m\"]\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_grundschulen[[\"Adresse_merge\"] + grundschulen_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "\n",
    "print(gdf.columns)\n",
    "print(gdf.shape)"
   ],
   "id": "f3a118199fb1be23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Medizinische Versorgung\n",
    "Ein \"medizinisches Zentrum\" wurde definiert als eine Apotheke mit zwei √Ñrzten im Umkreis von 100 Metern. Diese Zentren werden separat in ```medizinische-zentren.py``` berechnet. Dazu wird die euklidische Distanz (\"Luftlinie\") zwischen Apotheken und umgebenden √Ñrzten berechnet.\n",
    "Dadurch entstehen f√ºr den Datensatz folgende neue Attribute:\n",
    "- Anzahl von medizinischen Zentren im Umkreis von 500 m\n",
    "- Anzahl von medizinischen Zentren im Umkreis von 800 m\n",
    "- Anzahl von medizinischen Zentren im Umkreis von 1000 m\n",
    "- Fu√ül√§ufige Distanz zum n√§chsten medizinischen Zentrum\n",
    "\n",
    "Die vollst√§ndige Erkl√§rung der Felder findet sich im Anhang.\n",
    "\n",
    "Die fu√ül√§ufige Distanz zum n√§chstgelegenen medizinischen Zentrum wird per ```routing.py``` f√ºr jede Adresse einzeln ermittelt und als Weg gespeichert (```out/adressen_mit_medzentren_routen.csv```)."
   ],
   "id": "a8b3a7b9ddd38f8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import ast\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 1) Daten laden\n",
    "# ------------------------------------------------------\n",
    "df_centers = pd.read_csv(\"out/medzentren_geocoded.csv\")\n",
    "df_arzte = pd.read_csv(\"out/aerzte_geocoded.csv\")\n",
    "\n",
    "# Normalize boolean\n",
    "df_centers[\"is_med_center\"] = (\n",
    "    df_centers[\"is_med_center\"].astype(str).str.lower().isin([\"true\", \"1\", \"yes\", \"y\"])\n",
    ")\n",
    "\n",
    "# Arztname ‚Üí Fachrichtung Mapping\n",
    "arzt_fach_map = (\n",
    "    df_arzte\n",
    "    .dropna(subset=[\"Name_Arztpraxis\"])\n",
    "    .set_index(\"Name_Arztpraxis\")[\"Fachrichtung\"]\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Robust: arzt_keys_100m kann String-List, echte Liste oder leer sein\n",
    "def parse_arzt_list(value):\n",
    "    if isinstance(value, list):\n",
    "        return value\n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            return ast.literal_eval(value)\n",
    "        except Exception:\n",
    "            # fallback: split by comma\n",
    "            return [v.strip() for v in value.split(\",\") if v.strip()]\n",
    "    return []\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 2) Popup Builder\n",
    "# ------------------------------------------------------\n",
    "def build_popup(row):\n",
    "    lines = []\n",
    "\n",
    "    # Titel\n",
    "    if bool(row[\"is_med_center\"]):\n",
    "        lines.append(\n",
    "            f\"<b>Medizinisches Zentrum<br>{row.get('Strassenname','')}</b><br>\"\n",
    "        )\n",
    "\n",
    "    # Apotheken-Name\n",
    "    apo = str(row.get(\"Name_Apotheke\", \"\")).strip()\n",
    "    if apo:\n",
    "        lines.append(f\"üè• {apo}<br>\")\n",
    "\n",
    "    # √Ñrzte im Umkreis (Liste aufl√∂sen)\n",
    "    arzt_list = parse_arzt_list(row.get(\"arzt_keys_100m\", []))\n",
    "\n",
    "    if len(arzt_list) > 0:\n",
    "        lines.append(f\"<b>{len(arzt_list)}</b> Arztpraxen im 100 m Radius:\")\n",
    "\n",
    "        # Fachrichtungen bestimmen\n",
    "        fachrichtungen = []\n",
    "        for name in arzt_list:\n",
    "            fr = arzt_fach_map.get(name)\n",
    "            if fr:\n",
    "                fachrichtungen.append(f\"{name} ‚Äì {fr}\")\n",
    "            else:\n",
    "                fachrichtungen.append(f\"{name} ‚Äì (Fachrichtung unbekannt)\")\n",
    "\n",
    "        # als Liste anzeigen\n",
    "        lines.append(\"<ul>\" + \"\".join([f\"<li>{f}</li>\" for f in fachrichtungen]) + \"</ul>\")\n",
    "\n",
    "    else:\n",
    "        lines.append(\"Keine √Ñrzte im 100 m Radius gefunden.\")\n",
    "\n",
    "    return \"<br>\".join(lines)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3) Icon Auswahl\n",
    "# ------------------------------------------------------\n",
    "def pick_icon(row):\n",
    "    if bool(row[\"is_med_center\"]):\n",
    "        return folium.Icon(color=\"green\", icon=\"plus-sign\", prefix=\"glyphicon\")\n",
    "    else:\n",
    "        return folium.Icon(color=\"gray\", icon=\"staff-snake\", prefix=\"fa\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 4) Karte rendern\n",
    "# ------------------------------------------------------\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=14)\n",
    "cluster = MarkerCluster(name=\"Medizinische Zentren / Apotheken\")\n",
    "cluster.add_to(m)\n",
    "\n",
    "for _, row in df_centers.iterrows():\n",
    "\n",
    "    lat = row.get(\"lat\")\n",
    "    lon = row.get(\"lon\")\n",
    "\n",
    "    if pd.isna(lat) or pd.isna(lon):\n",
    "        continue\n",
    "\n",
    "    popup_html = build_popup(row)\n",
    "    icon = pick_icon(row)\n",
    "\n",
    "    marker = folium.Marker(\n",
    "        location=[lat, lon],\n",
    "        tooltip=row.get(\"Strassenname\", \"MedZentrum\"),\n",
    "        icon=icon,\n",
    "    ).add_to(cluster)\n",
    "    marker.add_child(folium.Popup(popup_html, max_width=450))\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "m\n"
   ],
   "id": "a4533f83433b8618",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Medizinische Felder in gdf √ºbernehmen\n",
    "# 1. Routing-Ergebnis f√ºr medizinische Versorgung laden\n",
    "gdf_med = load_geocsv(\"out/adressen_mit_medzentren_routen.csv\")\n",
    "print(\"gdf_med shape:\", gdf_med.shape)\n",
    "print(\"gdf shape (vor Merge):\", gdf.shape)\n",
    "\n",
    "# 2. Merge-Key bauen (Adresse normalisieren)\n",
    "gdf_med[\"Adresse_merge\"] = gdf_med.apply(make_merge_addr, axis=1)\n",
    "gdf_med = gdf_med.drop_duplicates(\"Adresse_merge\")\n",
    "\n",
    "# 3. Relevante Attributspalten aus der medizinischen Versorgung definieren\n",
    "medzentren_attribute = [\n",
    "    \"medzentren_min_distance_m\",\n",
    "    \"medzentren_route\",\n",
    "    \"medzentren_count_within_500m\",\n",
    "    \"medzentren_count_within_800m\",\n",
    "    \"medzentren_count_within_1000m\",\n",
    "]\n",
    "\n",
    "# 4. Merge in Haupt-GDF\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_med[[\"Adresse_merge\"] + medzentren_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_one\",\n",
    ")\n",
    "\n",
    "print(\"gdf shape (nach Merge):\", gdf.shape)"
   ],
   "id": "2e57b491ca5f7e24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## √ñPNV-Qualit√§t\n",
    "\n",
    "Die Qualit√§t des √ñPNV wird anhand der Fu√ül√§ufigkeit zur n√§chsten Haltestelle. Die H√§ufigkeit von Abfahrten (Headway) wird zwar berechnet, ist aber in der aktuellen Form noch kein verl√§sslicher Indikator. Die Daten stammen vom Verkehrsverbund Berlin-Brandenburg (VBB), Lizenz: CC BY 4.0, [zu den Daten](https://unternehmen.vbb.de/digitale-services/datensaetze) bzw. der Stadt Brandenburg an der Havel (\"2024_Haltestellen.csv\").\n",
    "\n",
    "Vorausgesetzte Datens√§tze:\n",
    "- ```data/GTFS/stops.txt```, der die Haltestellen mit ihren Geokoordinaten enth√§lt.\n",
    "- ```data/adressen_mit_haltestellen_routen.csv```, der die Routen zu den Haltestellen und Anzahl von Haltestellen im Radius 500m und 800m enth√§lt.\n",
    "- ```2024_Haltestellen.csv```, der nur die Haltestellen mit Geokoordinaten enth√§lt.\n",
    "\n",
    "Probleme mit Datenqualit√§t:\n",
    "- In der \"2024_Haltestellen.csv\" fehlen die Haltestellen \"Libellenweg\" und \"Immenweg\" (Linie B). Dadurch werden diese Haltestellen nicht ber√ºcksichtigt und Wege zur n√§chsten Haltestelle werden l√§nger eingesch√§tzt."
   ],
   "id": "97d042d0ef303f6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from shapely.geometry import Point\n",
    "\n",
    "# Load GTFS stops data\n",
    "stops = pd.read_csv(\"data/GTFS/stops.txt\")\n",
    "stops[\"geometry\"] = stops.apply(lambda row: Point(row[\"stop_lon\"], row[\"stop_lat\"]), axis=1)\n",
    "gdf_stops = gpd.GeoDataFrame(stops, geometry=\"geometry\", crs=EPSG_4326)\n",
    "\n",
    "# Convert to UTM for precise metric distance calculations\n",
    "gdf = gdf.to_crs(epsg=32633)\n",
    "gdf_stops = gdf_stops.to_crs(epsg=32633)\n",
    "\n",
    "# Assign nearest stop to each address based on Point(X, Y) geometry\n",
    "gdf[\"nearest_stop_id\"] = gdf.geometry.apply(\n",
    "    lambda pt: gdf_stops.loc[gdf_stops.distance(pt).idxmin(), \"stop_id\"]\n",
    ")\n",
    "\n",
    "# Read routes from adresses to stops and stop count from prepared CSV\n",
    "gdf_haltestellen = load_geocsv(\"out/adressen_mit_haltestellen_routen.csv\")\n",
    "gdf_haltestellen[\"Adresse_merge\"] = gdf_haltestellen.apply(make_merge_addr, axis=1)\n",
    "gdf_haltestellen = gdf_haltestellen.drop_duplicates(\"Adresse_merge\").copy()\n",
    "\n",
    "print(\"gdf_haltestellen shape:\", gdf_haltestellen.shape)\n",
    "print(\"gdf shape (vor Merge):\", gdf.shape)\n",
    "\n",
    "# Merge haltestellen attributes into main GeoDataFrame\n",
    "haltestellen_attribute = [\"haltestellen_route\", \"haltestellen_min_distance\", \"haltestellen_count_within_500m\", \"haltestellen_count_within_800m\"]\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_haltestellen[[\"Adresse_merge\"] + haltestellen_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_one\"\n",
    ")\n",
    "\n",
    "print(\"gdf shape (nach Merge):\", gdf.shape)"
   ],
   "id": "b032c3c18de695a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Berechnung der √ñPNV-Taktung",
   "id": "9b1c9bc9b0c3c80d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. GTFS laden\n",
    "# -------------------------------------------------\n",
    "stops = pd.read_csv(\"data/GTFS/stops.txt\")\n",
    "stop_times = pd.read_csv(\"data/GTFS/stop_times.txt\", low_memory=False)\n",
    "trips = pd.read_csv(\"data/GTFS/trips.txt\")\n",
    "calendar = pd.read_csv(\"data/GTFS/calendar.txt\")\n",
    "# optional:\n",
    "# calendar_dates = pd.read_csv(\"data/GTFS/calendar_dates.txt\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Zeitspalte -> Minuten ab Mitternacht\n",
    "# -------------------------------------------------\n",
    "def parse_time_to_minutes(t):\n",
    "    if pd.isna(t):\n",
    "        return None\n",
    "    parts = str(t).split(\":\")\n",
    "    if len(parts) == 2:\n",
    "        h, m = parts\n",
    "    elif len(parts) == 3:\n",
    "        h, m, _s = parts\n",
    "    else:\n",
    "        return None\n",
    "    try:\n",
    "        h = int(h)\n",
    "        m = int(m)\n",
    "        return h * 60 + m\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "stop_times = stop_times.copy()\n",
    "stop_times[\"minutes\"] = stop_times[\"arrival_time\"].apply(parse_time_to_minutes)\n",
    "stop_times = stop_times.dropna(subset=[\"minutes\"])\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3. Hauptverkehrszeit ausw√§hlen\n",
    "# -------------------------------------------------\n",
    "HVZ_WINDOWS = [\n",
    "    (360, 540),   # 06:00‚Äì09:00\n",
    "    (960, 1140),  # 16:00‚Äì19:00\n",
    "]\n",
    "\n",
    "def in_any_window(mins, windows):\n",
    "    for lo, hi in windows:\n",
    "        if lo <= mins <= hi:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "stop_times_hvz = stop_times[\n",
    "    stop_times[\"minutes\"].apply(lambda mm: in_any_window(mm, HVZ_WINDOWS))\n",
    "].copy()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4. Werkt√§gliche Dienste filtern und Trip-Infos mergen\n",
    "# -------------------------------------------------\n",
    "trips_filtered = trips.merge(calendar, on=\"service_id\")\n",
    "trips_filtered = trips_filtered[trips_filtered[\"monday\"] == 1]\n",
    "\n",
    "stop_times_hvz[\"trip_id\"] = stop_times_hvz[\"trip_id\"].astype(str)\n",
    "trips_filtered[\"trip_id\"] = trips_filtered[\"trip_id\"].astype(str)\n",
    "\n",
    "stopdata = stop_times_hvz.merge(\n",
    "    trips_filtered[[\"trip_id\", \"route_id\", \"service_id\"]],\n",
    "    on=\"trip_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "stopdata[\"stop_id\"] = stopdata[\"stop_id\"].astype(str)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 5. Haltestellengeometrie (f√ºr Karten etc.)\n",
    "# -------------------------------------------------\n",
    "stops = stops.copy()\n",
    "stops[\"stop_id\"] = stops[\"stop_id\"].astype(str)\n",
    "\n",
    "gdf_stops_all = gpd.GeoDataFrame(\n",
    "    stops,\n",
    "    geometry=gpd.points_from_xy(stops[\"stop_lon\"], stops[\"stop_lat\"]),\n",
    "    crs=EPSG_4326\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 6. Headway je Stop-ID berechnen\n",
    "# -------------------------------------------------\n",
    "def compute_headway_for_window(df, lo, hi, group_col=\"stop_id\", time_col=\"minutes\"):\n",
    "    result = {}\n",
    "    for key, group in df.groupby(group_col):\n",
    "        if pd.isna(key):\n",
    "            continue\n",
    "        times = sorted([t for t in group[time_col] if lo <= t <= hi])\n",
    "        if len(times) < 2:\n",
    "            continue\n",
    "        diffs = [b - a for a, b in zip(times[:-1], times[1:])]\n",
    "        result[key] = sum(diffs) / len(diffs)\n",
    "    return result\n",
    "\n",
    "headway_morning = compute_headway_for_window(stopdata, 360, 540, group_col=\"stop_id\")\n",
    "headway_evening = compute_headway_for_window(stopdata, 960, 1140, group_col=\"stop_id\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 7. Headway in gdf mappen (n√§chstgelegene Haltestelle)\n",
    "# -------------------------------------------------\n",
    "gdf[\"nearest_stop_id\"] = gdf[\"nearest_stop_id\"].astype(str)\n",
    "\n",
    "for col in [\n",
    "    \"headway_morning\", \"headway_evening\", \"headway_avg\",\n",
    "    \"headway_morning_score\", \"headway_evening_score\",\n",
    "    \"headway_avg_score\",\n",
    "]:\n",
    "    if col in gdf.columns:\n",
    "        gdf = gdf.drop(columns=[col])\n",
    "\n",
    "gdf[\"headway_morning\"] = gdf[\"nearest_stop_id\"].map(headway_morning)\n",
    "gdf[\"headway_evening\"] = gdf[\"nearest_stop_id\"].map(headway_evening)\n",
    "gdf[\"headway_avg\"] = gdf[[\"headway_morning\", \"headway_evening\"]].mean(axis=1)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 8. Headway-Scores (z.B. 5‚Äì60 Minuten)\n",
    "# -------------------------------------------------\n",
    "fixed_min, fixed_max = 5, 60\n",
    "\n",
    "def scoreify(series):\n",
    "    return 1 - ((series - fixed_min) / (fixed_max - fixed_min)).clip(lower=0, upper=1)\n",
    "\n",
    "gdf[\"headway_morning_score\"] = scoreify(gdf[\"headway_morning\"])\n",
    "gdf[\"headway_evening_score\"] = scoreify(gdf[\"headway_evening\"])\n",
    "gdf[\"headway_avg_score\"]     = scoreify(gdf[\"headway_avg\"])\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 9. Debug: fehlende Headways\n",
    "# -------------------------------------------------\n",
    "no_headway_mask = gdf[\"headway_avg\"].isna()\n",
    "print(\"Adressen ohne Headway_avg:\", int(no_headway_mask.sum()))\n",
    "\n",
    "na_stops = gdf.loc[no_headway_mask, \"nearest_stop_id\"].value_counts()\n",
    "print(\"Anzahl unterschiedlicher problematischer Haltestellen:\", len(na_stops))\n",
    "print(na_stops.head(20))\n",
    "\n",
    "if len(na_stops) > 0:\n",
    "    test_stop = na_stops.index[0]\n",
    "    sample_times = stopdata.loc[stopdata[\"stop_id\"] == test_stop, \"minutes\"]\n",
    "    sample_morning = sorted([t for t in sample_times if 360 <= t <= 540])[:20]\n",
    "    print(\"Beispiel-Haltestelle\", test_stop, \"HVZ-Zeiten morgens:\",\n",
    "          sample_morning)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 10. Cleanup (optional)\n",
    "# -------------------------------------------------\n",
    "# del(stop_times, trips, calendar, trips_filtered, stopdata)\n"
   ],
   "id": "ad2f3fdb3ae58eb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# √ñPNV in gdf mergen\n",
    "headway_attribute = [\"headway_avg\"]"
   ],
   "id": "a1e92bc343809d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -------------------------------------------------\n",
    "# X. Debug: Abfahrts-Statistik pro Haltestelle (HVZ)\n",
    "# -------------------------------------------------\n",
    "def minutes_to_hhmm(mins: int) -> str:\n",
    "    \"\"\"Hilfsfunktion: 0..1440 Minuten -> 'HH:MM'.\"\"\"\n",
    "    h = int(mins) // 60\n",
    "    m = int(mins) % 60\n",
    "    h = h % 24  # falls GTFS > 24h nutzt\n",
    "    return f\"{h:02d}:{m:02d}\"\n",
    "\n",
    "def summarize_stop_times(df_stop: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Erzeugt Debug-Statistik f√ºr eine Haltestelle in der HVZ.\"\"\"\n",
    "    mins = df_stop[\"minutes\"].dropna().astype(int).tolist()\n",
    "    if not mins:\n",
    "        return pd.Series({\n",
    "            \"hvz_dep_total\": 0,\n",
    "            \"hvz_dep_morning\": 0,\n",
    "            \"hvz_dep_evening\": 0,\n",
    "            \"hvz_first\": None,\n",
    "            \"hvz_last\": None,\n",
    "            \"hvz_sample_times\": \"\"\n",
    "        })\n",
    "\n",
    "    mins_sorted = sorted(mins)\n",
    "\n",
    "    # Morning / Evening nach Deinen HVZ_WINDOWS\n",
    "    morning = [t for t in mins_sorted if 360 <= t <= 540]\n",
    "    evening = [t for t in mins_sorted if 960 <= t <= 1140]\n",
    "\n",
    "    def fmt_first(lst):\n",
    "        return minutes_to_hhmm(lst[0]) if lst else None\n",
    "\n",
    "    def fmt_last(lst):\n",
    "        return minutes_to_hhmm(lst[-1]) if lst else None\n",
    "\n",
    "    # ein paar Beispielzeiten (gesamt, egal ob morgens/abends)\n",
    "    sample = \", \".join(minutes_to_hhmm(t) for t in mins_sorted[:10])\n",
    "\n",
    "    return pd.Series({\n",
    "        \"hvz_dep_total\": len(mins_sorted),\n",
    "        \"hvz_dep_morning\": len(morning),\n",
    "        \"hvz_dep_evening\": len(evening),\n",
    "        \"hvz_first\": fmt_first(mins_sorted),\n",
    "        \"hvz_last\": fmt_last(mins_sorted),\n",
    "        \"hvz_sample_times\": sample\n",
    "    })\n",
    "\n",
    "# stopdata enth√§lt alle HVZ-Fahrten mit stop_id und minutes\n",
    "# -> Gruppierung nach stop_id\n",
    "stop_debug = (\n",
    "    stopdata\n",
    "    .groupby(\"stop_id\", as_index=False)\n",
    "    .apply(summarize_stop_times)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Dictionary f√ºr schnellen Zugriff im Mapping\n",
    "stop_debug_dict = (\n",
    "    stop_debug\n",
    "    .set_index(\"stop_id\")\n",
    "    .to_dict(orient=\"index\")\n",
    ")\n"
   ],
   "id": "612b5cbf42ecd82b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualisierung der √ñPNV-Taktung",
   "id": "f3be44369f64d5db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "from branca.colormap import linear, LinearColormap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Convert gdf_stops geometry to WGS84\n",
    "gdf_stops = gdf_stops.to_crs(epsg=4326).copy()\n",
    "\n",
    "# Haltestellen innerhalb Stadt\n",
    "gdf_stops_clip = gdf_stops[gdf_stops.geometry.within(CITY_BOUNDING_BOX)].copy()\n",
    "print(\"Haltestellen im Stadtpolygon:\", len(gdf_stops_clip))\n",
    "\n",
    "#\n",
    "# 2. Farbskala nur aus Adressen-Headway\n",
    "#\n",
    "# headway_avg = durchschnittliche Taktzeit (Minuten) f√ºr diese Adresse\n",
    "# Annahme: kleiner Wert = besser (h√§ufigere Bedienung)\n",
    "addr_headway = pd.to_numeric(gdf[\"headway_avg\"], errors=\"coerce\")\n",
    "\n",
    "hv_valid = addr_headway.dropna()\n",
    "if len(hv_valid) > 0:\n",
    "    vmin, vmax = hv_valid.quantile([0.01, 0.99])\n",
    "    if vmin == vmax:\n",
    "        # falls alles gleich (z. B. nur eine Linie), spreizen f√ºr die Farbskala\n",
    "        vmin = vmin - 0.1\n",
    "        vmax = vmax + 0.1\n",
    "else:\n",
    "    # Fallback, falls ALLE Adressen NaN sind\n",
    "    vmin, vmax = (0, 1)\n",
    "\n",
    "palette_normal = list(linear.RdYlGn_11.colors)\n",
    "palette_inverted = palette_normal[::-1]\n",
    "colormap = LinearColormap(\n",
    "    colors=palette_inverted,\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    ").to_step(n=9)\n",
    "colormap.caption = \"Headway pro Adresse (Minuten, kleiner = besser)\"\n",
    "\n",
    "# 3. Karte initialisieren\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"cartodbpositron\")\n",
    "\n",
    "# 4. Adressen plotten (farbig nach headway_avg)\n",
    "#    - Farbig wenn headway_avg da\n",
    "#    - Hellgrau wenn kein Wert\n",
    "for _, row in gdf.iterrows():\n",
    "    hv_addr = row.get(\"headway_avg\", np.nan)\n",
    "    hv_morning = row.get(\"headway_morning\", np.nan)\n",
    "    hv_evening = row.get(\"headway_evening\", np.nan)\n",
    "\n",
    "    if pd.isna(hv_addr):\n",
    "        # Kein Wert berechnet -> zeichne neutral\n",
    "        color = \"#BBBBBB\"\n",
    "        fill_color = \"#BBBBBB\"\n",
    "        hv_label = \"kein Wert\"\n",
    "    else:\n",
    "        color = colormap(hv_addr)\n",
    "        fill_color = colormap(hv_addr)\n",
    "        hv_label = f\"{hv_addr:.1f} min\"\n",
    "\n",
    "    # Popup mit allen Headways, falls vorhanden\n",
    "    popup_lines = [\n",
    "        f\"{row.get('Stra√üenname', '')} {row.get('Hsnr', '')}\",\n",
    "        f\"<b>Headway (avg):</b> {hv_label}\",\n",
    "    ]\n",
    "    if pd.notna(hv_morning):\n",
    "        popup_lines.append(f\"Fr√ºhspitze: {hv_morning:.1f} min\")\n",
    "    if pd.notna(hv_evening):\n",
    "        popup_lines.append(f\"Abendspitze: {hv_evening:.1f} min\")\n",
    "\n",
    "    popup_html = \"<br>\".join(popup_lines)\n",
    "\n",
    "    folium.CircleMarker(\n",
    "        location=[row.lat, row.lon],\n",
    "        radius=5,\n",
    "        color=color,\n",
    "        fill=True,\n",
    "        fill_color=fill_color,\n",
    "        fill_opacity=0.8,\n",
    "        weight=1,\n",
    "        popup=popup_html,\n",
    "    ).add_to(m)\n",
    "\n",
    "# 5. Haltestellen plotten (schwarz, neutral + Debug-Infos)\n",
    "for _, row in gdf_stops_clip.iterrows():\n",
    "    lat_s = row[\"stop_lat\"]\n",
    "    lon_s = row[\"stop_lon\"]\n",
    "    stop_id = str(row.get(\"stop_id\"))\n",
    "    stop_label = row.get(\"stop_name\", stop_id or \"Haltestelle\")\n",
    "\n",
    "    dbg = stop_debug_dict.get(stop_id, None)\n",
    "\n",
    "    popup_lines = [f\"<b>Haltestelle:</b> {stop_label}\",\n",
    "                   f\"<b>stop_id:</b> {stop_id}\"]\n",
    "\n",
    "    if dbg is not None:\n",
    "        popup_lines.append(f\"<b>HVZ-Abfahrten gesamt:</b> {dbg['hvz_dep_total']}\")\n",
    "        popup_lines.append(f\"&nbsp;&nbsp;Morgens (06‚Äì09): {dbg['hvz_dep_morning']}\")\n",
    "        popup_lines.append(f\"&nbsp;&nbsp;Abends (16‚Äì19): {dbg['hvz_dep_evening']}\")\n",
    "        if dbg[\"hvz_first\"] and dbg[\"hvz_last\"]:\n",
    "            popup_lines.append(\n",
    "                f\"<b>HVZ-Fenster:</b> {dbg['hvz_first']} ‚Äì {dbg['hvz_last']}\"\n",
    "            )\n",
    "        if dbg[\"hvz_sample_times\"]:\n",
    "            popup_lines.append(\n",
    "                f\"<b>Beispiele:</b> {dbg['hvz_sample_times']}\"\n",
    "            )\n",
    "    else:\n",
    "        popup_lines.append(\"<i>Keine HVZ-Abfahrten gefunden.</i>\")\n",
    "\n",
    "    popup_html = \"<br>\".join(popup_lines)\n",
    "\n",
    "    folium.CircleMarker(\n",
    "        location=[lat_s, lon_s],\n",
    "        radius=3,\n",
    "        color=\"black\",\n",
    "        fill=True,\n",
    "        fill_color=\"black\",\n",
    "        fill_opacity=1,\n",
    "        weight=1,\n",
    "        popup=popup_html,\n",
    "    ).add_to(m)\n",
    "\n",
    "# 6. Legende f√ºr die Adressen-Headways\n",
    "colormap.add_to(m)\n",
    "m\n"
   ],
   "id": "24544ac9ee9f7dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Umwelt\n",
    "### Gro√üfl√§chen\n",
    "- Luftlinie in m zum n√§chsten gro√üen Wald oder See\n",
    "- Luftlinie in m zum n√§chsten gro√üen Gewerbe- oder Industriegebiet\n"
   ],
   "id": "51f2302c42d26989"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import geopandas as gpd\n",
    "from shapely.strtree import STRtree\n",
    "from shapely.geometry.base import BaseGeometry\n",
    "import numpy as np\n",
    "\n",
    "# --------------------------------------------\n",
    "# 1) Gro√üe Fl√§chen in metrischem CRS vorbereiten\n",
    "# --------------------------------------------\n",
    "gdf_m = gdf.to_crs(32633)\n",
    "gdf_large_m = gdf_large.to_crs(32633)\n",
    "\n",
    "TARGET_CLASSES = {\n",
    "    \"gewerbe\": \"Gewerbe\",\n",
    "    \"gruen\": \"Gruen\",\n",
    "    \"sonstiges\": \"Sonstiges\"\n",
    "}\n",
    "\n",
    "# --------------------------------------------\n",
    "# 2) Geometrien pro Klasse + STRtree vorbereiten\n",
    "# --------------------------------------------\n",
    "targets = {}\n",
    "\n",
    "for key, cls in TARGET_CLASSES.items():\n",
    "    geoms = list(gdf_large_m[gdf_large_m[\"nutzklasse\"] == cls].geometry)\n",
    "\n",
    "    # Leere Klassen √ºberspringen\n",
    "    if not geoms:\n",
    "        print(f\"Warnung: keine Geometrien f√ºr Klasse {cls} gefunden.\")\n",
    "        continue\n",
    "\n",
    "    tree = STRtree(geoms)\n",
    "    targets[key] = {\n",
    "        \"geoms\": geoms,\n",
    "        \"tree\": tree,\n",
    "    }\n",
    "\n",
    "print(\"STRtrees vorbereitet f√ºr:\", list(targets.keys()))\n",
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "# 3) Distanzfunktion: Punkt ‚Üí n√§chstgelegene Fl√§che\n",
    "# --------------------------------------------\n",
    "def fast_distance_to_area(pt, target):\n",
    "    \"\"\"\n",
    "    pt: shapely Point (im selben CRS wie target-geoms)\n",
    "    target: Dict mit 'geoms' (Liste) und 'tree' (STRtree)\n",
    "    \"\"\"\n",
    "    if pt is None or (hasattr(pt, \"is_empty\") and pt.is_empty):\n",
    "        return np.nan\n",
    "\n",
    "    tree = target[\"tree\"]\n",
    "    geoms = target[\"geoms\"]\n",
    "\n",
    "    # nearest() liefert hier einen INDEX in der Geom-Liste zur√ºck\n",
    "    idx = tree.nearest(pt)\n",
    "\n",
    "    # falls doch mal ein Geometry zur√ºckk√§me: beides abfangen\n",
    "    if isinstance(idx, BaseGeometry):\n",
    "        nearest_geom = idx\n",
    "    else:\n",
    "        nearest_geom = geoms[int(idx)]\n",
    "\n",
    "    try:\n",
    "        return int(pt.distance(nearest_geom))\n",
    "    except TypeError:\n",
    "        # Falls unerwartete Typen auftauchen\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "# 4) Distanzen f√ºr jede Kategorie berechnen\n",
    "# --------------------------------------------\n",
    "for key, target in targets.items():\n",
    "    print(f\"Berechne Distanz f√ºr Kategorie: {key} ...\")\n",
    "    gdf_m[f\"gross_{key}_distance\"] = gdf_m.geometry.apply(\n",
    "        lambda pt, t=target: fast_distance_to_area(pt, t)\n",
    "    )\n",
    "\n",
    "# --------------------------------------------\n",
    "# 5) Ergebnisse zur√ºck nach WGS84\n",
    "# --------------------------------------------\n",
    "gdf_back = gdf_m.to_crs(4326)\n",
    "\n",
    "dist_cols = [f\"gross_{k}_distance\" for k in targets.keys()]\n",
    "gdf[dist_cols] = gdf_back[dist_cols]\n",
    "\n",
    "print(\"Fertig! Neue Distanzfelder berechnet:\", dist_cols)\n"
   ],
   "id": "ed393f2798a56388",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "import geopandas as gpd\n",
    "from shapely.ops import linemerge\n",
    "\n",
    "# ------------------------------\n",
    "# 1) Metrische Projektion\n",
    "# ------------------------------\n",
    "gdf_m = gdf.to_crs(32633)\n",
    "gdf_large_m = gdf_large.to_crs(32633)\n",
    "\n",
    "# Fl√§che in ha berechnen (1 ha = 10.000 m¬≤) und runden\n",
    "gdf_large_m[\"area_ha\"] = (gdf_large_m.area / 10000).round(1)\n",
    "\n",
    "# zur√ºck nach WGS84 f√ºr Darstellung\n",
    "gdf_large_4326 = gdf_large_m.to_crs(4326)\n",
    "\n",
    "# ------------------------------\n",
    "# 2) Fl√§chen nach Kategorien\n",
    "# ------------------------------\n",
    "TARGET_CLASSES = {\n",
    "    \"gewerbe\": \"Gewerbe\",\n",
    "    \"gruen\": \"Gruen\",\n",
    "    \"sonstiges\": \"Sonstiges\"\n",
    "}\n",
    "\n",
    "areas = {\n",
    "    key: gdf_large_4326[gdf_large_4326[\"nutzklasse\"] == cls].copy()\n",
    "    for key, cls in TARGET_CLASSES.items()\n",
    "}\n",
    "\n",
    "colors = {\"gewerbe\": \"red\", \"gruen\": \"green\", \"sonstiges\": \"blue\"}\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 3) Distanzfunktionen\n",
    "# ------------------------------\n",
    "def nearest_boundary_point(pt, polygon):\n",
    "    boundary = polygon.boundary\n",
    "    if boundary.geom_type == \"MultiLineString\":\n",
    "        boundary = linemerge(boundary)\n",
    "    proj = boundary.project(pt)\n",
    "    nearest_pt = boundary.interpolate(proj)\n",
    "    return nearest_pt\n",
    "\n",
    "\n",
    "def compute_nearest_area(pt, df):\n",
    "    \"\"\"\n",
    "    pt: Point (UTM)\n",
    "    df: GeoDataFrame (WGS84!), deshalb f√ºr Distanz kurz in UTM projizieren\n",
    "    \"\"\"\n",
    "    # in metrisches CRS bringen\n",
    "    df_utm = df.to_crs(32633)\n",
    "\n",
    "    best_dist = 1e12\n",
    "    best_point = None\n",
    "\n",
    "    for poly in df_utm.geometry:\n",
    "        nb = nearest_boundary_point(pt, poly)\n",
    "        d = pt.distance(nb)\n",
    "        if d < best_dist:\n",
    "            best_dist = d\n",
    "            best_point = nb\n",
    "\n",
    "    return best_dist, best_point\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 4) Karte aufbauen\n",
    "# ------------------------------\n",
    "def build_map():\n",
    "    # 5 zuf√§llige Adressen\n",
    "    rows = gdf.sample(5, random_state=42)\n",
    "\n",
    "    m = folium.Map(location=CITY_CENTER, zoom_start=12, tiles=\"cartodbpositron\")\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # Fl√§chenlayer (mit Tooltip: bez + area_ha)\n",
    "    # ------------------------------------------\n",
    "    for key, df in areas.items():\n",
    "\n",
    "        layer = folium.FeatureGroup(name=f\"Fl√§chen ‚Äì {key}\", show=True)\n",
    "\n",
    "        df_safe = df[[\"geometry\", \"nutzklasse\", \"bez\", \"area_ha\"]].copy()\n",
    "\n",
    "        folium.GeoJson(\n",
    "            df_safe,\n",
    "            name=key,\n",
    "            style_function=lambda feature, col=colors[key]: {\n",
    "                \"fillColor\": col,\n",
    "                \"color\": col,\n",
    "                \"weight\": 1,\n",
    "                \"fillOpacity\": 0.25,\n",
    "            },\n",
    "            tooltip=folium.features.GeoJsonTooltip(\n",
    "                fields=[\"bez\", \"nutzklasse\", \"area_ha\"],\n",
    "                aliases=[\"Objekt:\", \"Kategorie:\", \"Fl√§che (ha):\"],\n",
    "                localize=True,\n",
    "                sticky=True,\n",
    "            ),\n",
    "        ).add_to(layer)\n",
    "\n",
    "        layer.add_to(m)\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # Adressen + Luftlinien\n",
    "    # ------------------------------------------\n",
    "    for idx, row in rows.iterrows():\n",
    "\n",
    "        # Adresspunkt in UTM\n",
    "        addr_pt_utm = gdf_m.loc[row.name].geometry\n",
    "\n",
    "        # Adresse markieren (WGS84-Koordinaten aus gdf)\n",
    "        folium.CircleMarker(\n",
    "            location=[row.lat, row.lon],\n",
    "            radius=7,\n",
    "            color=\"black\",\n",
    "            fill=True,\n",
    "            fill_opacity=1,\n",
    "            tooltip=row[\"Adresse_merge\"],\n",
    "        ).add_to(m)\n",
    "\n",
    "        # Linien zu Fl√§chenkategorien\n",
    "        for key, df in areas.items():\n",
    "\n",
    "            dist, nearest_pt_utm = compute_nearest_area(addr_pt_utm, df)\n",
    "\n",
    "            # n√§chster Punkt zur√ºck in WGS84\n",
    "            nearest_pt_wgs = (\n",
    "                gpd.GeoSeries([nearest_pt_utm], crs=32633).to_crs(4326).iloc[0]\n",
    "            )\n",
    "\n",
    "            # Linie\n",
    "            folium.PolyLine(\n",
    "                locations=[\n",
    "                    (row.lat, row.lon),\n",
    "                    (nearest_pt_wgs.y, nearest_pt_wgs.x),\n",
    "                ],\n",
    "                color=colors[key],\n",
    "                weight=3,\n",
    "                opacity=0.9,\n",
    "                tooltip=f\"{key}: {int(dist)} m\",\n",
    "            ).add_to(m)\n",
    "\n",
    "            # Zielmarker\n",
    "            folium.CircleMarker(\n",
    "                location=[nearest_pt_wgs.y, nearest_pt_wgs.x],\n",
    "                radius=4,\n",
    "                color=colors[key],\n",
    "                fill=True,\n",
    "                fill_opacity=0.9,\n",
    "                tooltip=f\"Rand {key}: {int(dist)} m\",\n",
    "            ).add_to(m)\n",
    "\n",
    "    folium.LayerControl(collapsed=False).add_to(m)\n",
    "    return m\n",
    "\n",
    "\n",
    "m = build_map()\n",
    "m\n"
   ],
   "id": "dadcf605e73e7658",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Freizeit- und Erholungsfl√§chen\n",
    "\n",
    "- Fu√ül√§ufige Distanz zur n√§chstgelegenen Freizeit- und Erholungsfl√§chen (Spielpl√§tze, Parks, Gr√ºnanlagen, Promenaden)\n",
    "\n",
    "Die Freizeit- und Erholungsfl√§chen laut Auftrag sind:\n",
    "- Marienberg\n",
    "- Humboldthain\n",
    "- Salzhofufer\n",
    "- Wallpromenade\n",
    "- Theaterpark\n",
    "- Grabenpromenade\n",
    "- Schlosspark Plaue\n",
    "- Schlosspark Gollwitz\n",
    "- Krugpark\n",
    "\n",
    "Aus den bereitgestellten Shape-Dateien werden anhand der Objektbezeichnung (Spalte \"objektbeze\") im Routing-Skript ca. 100 zusammenh√§ngende Fl√§chen gebildet, deren R√§nder als Ziele f√ºr die fu√ül√§ufige Distanzberechnung genutzt werden. Dadurch werden mehr als die angegebenen Fl√§chen genutzt."
   ],
   "id": "94649ee801aa7560"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "path = \"data/Gr√ºnfl√§chen_Verkehrszeichen/20251029_Vegetation_KSP_GP_31.shp\"\n",
    "gdf_gruen_shape = gpd.read_file(path)\n",
    "#gdf_gruen"
   ],
   "id": "aa43fe538b4bc67a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=14)\n",
    "\n",
    "def random_color(seed):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    r = rng.integers(80, 200)\n",
    "    g = rng.integers(80, 200)\n",
    "    b = rng.integers(80, 200)\n",
    "    return f\"#{r:02x}{g:02x}{b:02x}\"\n",
    "\n",
    "# Ein Farbschema erzeugen\n",
    "unique_ids = gdf_gruen_shape[\"objektbeze\"].unique()\n",
    "color_map = {uid: random_color(i) for i, uid in enumerate(unique_ids)}\n",
    "\n",
    "# Polygone hinzuf√ºgen\n",
    "folium.GeoJson(\n",
    "    gdf_gruen_shape,\n",
    "    style_function=lambda feature: {\n",
    "        \"color\": \"black\",\n",
    "        \"weight\": 0.5,\n",
    "        \"fillOpacity\": 0.9,\n",
    "        \"fillColor\": color_map[feature[\"properties\"][\"objektbeze\"]]\n",
    "    },\n",
    "    tooltip=folium.GeoJsonTooltip(fields=[\"objektbeze\"])\n",
    ").add_to(m)\n",
    "\n",
    "m"
   ],
   "id": "2ae81272462576a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gdf_gruen_m = gdf_gruen_shape.to_crs(32633)\n",
    "\n",
    "# Gruppieren & union der Fl√§chen\n",
    "gdf_gruen_area = (gdf_gruen_shape.dissolve(by=\"objektbeze\").reset_index())\n",
    "\n",
    "# Fl√§che berechnen (m¬≤)\n",
    "gdf_gruen_area[\"flaeche_m2\"] = gdf_gruen_area.area\n",
    "gdf_gruen_area[\"flaeche_ha\"] = gdf_gruen_area[\"flaeche_m2\"] / 10_000\n",
    "\n",
    "bad = gdf_gruen_area.geometry.apply(lambda g: not g.is_valid)\n",
    "print(\"Ung√ºltige Geometrien:\", bad.sum())\n",
    "\n",
    "bb = gdf_gruen_area.geometry.boundary\n",
    "print(\"Boundary is empty:\", sum(bb.is_empty))\n",
    "\n",
    "del(gdf_gruen_m, gdf_gruen_area)"
   ],
   "id": "70328158908d4bc8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Lade vorberechnete Routen zur n√§chstgelegenen Anlage und Anzahl von Funden im Umkreis\n",
    "gdf_gruen = load_geocsv(\"out/adressen_mit_gruen_routen.csv\")"
   ],
   "id": "aa74c34fdcf6a9a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Merge mit Haupt-GDF\n",
    "gdf_gruen[\"Adresse_merge\"] = gdf_gruen.apply(make_merge_addr, axis=1)\n",
    "gdf_gruen = gdf_gruen.sort_values(\"Adresse_merge\").drop_duplicates(\"Adresse_merge\", keep=\"first\")\n",
    "\n",
    "dups = gdf_gruen[\"Adresse_merge\"].value_counts()\n",
    "print(dups[dups > 1])\n",
    "\n",
    "gruen_attribute = [\"gruen_route\",\"gruen_min_distance\", \"gruen_count_within_500m\", \"gruen_count_within_800m\", \"gruen_count_within_1000m\"]\n",
    "\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_gruen[[\"Adresse_merge\"] + gruen_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "\n",
    "# Plausibili√§tspr√ºfung\n",
    "print(gdf[[\"Adresse_merge\", \"gruen_min_distance\", \"gruen_route\"]].head())\n",
    "print(gdf.shape)"
   ],
   "id": "7390decad77bb1da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "\n",
    "# Alle \"isna\"-Punkte in gdf_gruen auf \"0\" m setzen, weil sie vermutlich direkt an der Fl√§che liegen und daher keine Route berechnet werden konnte\n",
    "gdf_gruen = gdf_gruen.copy()\n",
    "mask_na = gdf_gruen[\"gruen_min_distance\"].isna()\n",
    "gdf_gruen.loc[mask_na, \"gruen_min_distance\"] = 0\n",
    "\n",
    "# Z√§hlen, wie viele Punkte keine Route haben (d.h. direkt an der Fl√§che liegen)\n",
    "mask = (\n",
    "    gdf_gruen[\"gruen_route\"].isna()\n",
    "    | (gdf_gruen[\"gruen_route\"].astype(str).str.strip() == \"\")\n",
    ")\n",
    "gdf_no_route = gdf_gruen[mask].copy()\n",
    "\n",
    "print(f\"Anzahl Punkte ohne gruen_route: {len(gdf_no_route)}\")\n",
    "\n",
    "# 2) Folium-Map erzeugen\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"cartodbpositron\")\n",
    "\n",
    "# 3) Alle Punkte einzeichnen\n",
    "for _, row in gdf_no_route.iterrows():\n",
    "    geom = row.geometry\n",
    "    if geom is None or geom.is_empty:\n",
    "        continue\n",
    "\n",
    "    # Falls es wirkliche Punkte sind:\n",
    "    try:\n",
    "        lat = geom.y\n",
    "        lon = geom.x\n",
    "    except AttributeError:\n",
    "        # Fallback: z.B. bei Polygon ‚Üí Schwerpunkt\n",
    "        geom = geom.centroid\n",
    "        lat = geom.y\n",
    "        lon = geom.x\n",
    "\n",
    "    folium.CircleMarker(\n",
    "        location=(lat, lon),\n",
    "        radius=4,\n",
    "        fill=True,\n",
    "        fill_opacity=0.8,\n",
    "        popup=str(row.get(\"name\", \"\")),      # ggf. an deine Spalte anpassen\n",
    "        tooltip=row.get(\"Adresse\", None),    # oder andere sinnvolle Spalte\n",
    "    ).add_to(m)\n",
    "\n",
    "def random_color(seed):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    r = rng.integers(80, 200)\n",
    "    g = rng.integers(80, 200)\n",
    "    b = rng.integers(80, 200)\n",
    "    return f\"#{r:02x}{g:02x}{b:02x}\"\n",
    "\n",
    "# Ein Farbschema erzeugen\n",
    "unique_ids = gdf_gruen_shape[\"objektbeze\"].unique()\n",
    "color_map = {uid: random_color(i) for i, uid in enumerate(unique_ids)}\n",
    "\n",
    "# Polygone hinzuf√ºgen\n",
    "folium.GeoJson(\n",
    "    gdf_gruen_shape,\n",
    "    style_function=lambda feature: {\n",
    "        \"color\": \"black\",\n",
    "        \"weight\": 0.5,\n",
    "        \"fillOpacity\": 0.9,\n",
    "        \"fillColor\": color_map[feature[\"properties\"][\"objektbeze\"]]\n",
    "    },\n",
    "    tooltip=folium.GeoJsonTooltip(fields=[\"objektbeze\"])\n",
    ").add_to(m)\n",
    "\n",
    "m"
   ],
   "id": "a7b971341bb7929e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# \"Gr√ºn-und-Parkanlagen.gpkg\" einlesen und Layer \"je_eine_Flaeche\" als geometry nutzen\n",
    "path = \"data/Gr√ºn-und-Parkanlagen.gpkg\"\n",
    "gdf_parkanlagen = gpd.read_file(path, layer=\"je_eine_Flaeche\")\n",
    "print(\"Parkanlagen geladen:\", gdf_parkanlagen.shape)"
   ],
   "id": "79faaeb6675e6a34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Auf Folium-Karte anzeigen\n",
    "import folium\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=14)\n",
    "folium.GeoJson(\n",
    "    gdf_parkanlagen,\n",
    "    style_function=lambda feature: {\n",
    "        \"color\": \"darkgreen\",\n",
    "        \"weight\": 1,\n",
    "        \"fillOpacity\": 0.7,\n",
    "        \"fillColor\": \"green\"\n",
    "    },\n",
    "    tooltip=folium.GeoJsonTooltip(fields=[\"objektbeze\"])\n",
    ").add_to(m)\n",
    "m"
   ],
   "id": "b07db3d784271493",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# gdf_parkanlagen in gdf mergen\n",
    "gdf_parkanlagen_m = gdf_parkanlagen.to_crs(32633)\n",
    "gdf_parkanlagen_m[\"area_ha\"] = (gdf_parkanlagen_m.area / 10_000).round(1)\n",
    "gdf_parkanlagen_m = gdf_parkanlagen_m[[\"objektbeze\", \"area_ha\", \"geometry\"]]\n",
    "gdf_parkanlagen_4326 = gdf_parkanlagen_m.to_crs(4326)"
   ],
   "id": "5d073da0da486efa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from shapely.strtree import STRtree\n",
    "# STRtree der Parkanlagen vorbereiten\n",
    "park_tree = STRtree(gdf_parkanlagen_m.geometry.tolist())\n",
    "\n",
    "def distance_to_nearest_park(pt):\n",
    "    if pt is None or (hasattr(pt, \"is_empty\") and pt.is_empty):\n",
    "        return np.nan\n",
    "    idx = park_tree.nearest(pt)\n",
    "    if isinstance(idx, BaseGeometry):\n",
    "        nearest_geom = idx\n",
    "    else:\n",
    "        nearest_geom = gdf_parkanlagen_m.geometry.iloc[int(idx)]\n",
    "    try:\n",
    "        return int(pt.distance(nearest_geom))\n",
    "    except TypeError:\n",
    "        return np.nan\n",
    "\n",
    "# Distanz zur n√§chstgelegenen Parkanlage berechnen\n",
    "gdf_m = gdf.to_crs(32633)\n",
    "gdf_m[\"park_distance\"] = gdf_m.geometry.apply(distance_to_nearest_park)\n",
    "gdf[\"park_distance\"] = gdf_m[\"park_distance\"]\n",
    "print(\"Fertig! park_distance hinzugef√ºgt.\")"
   ],
   "id": "f03206caf3630c73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Begrenzung durch dauerhafte Barrieren\n",
    "Als zus√§tzlicher Indikator wird berechnet, ob eine Adresse durch eine Bahnlinie vom Stadtzentrum getrennt ist. Damit wird abgebildet, ob eine Adresse trotz N√§he zum Zentrum durch eine Barriere erschwerten Zugang hat (z. B., durch Wartezeiten an Bahn√ºberg√§ngen)."
   ],
   "id": "9d1da8cf2f7610c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import osmnx as ox\n",
    "# Schritt 1: Bahnlinien von OSM laden\n",
    "place = \"Brandenburg an der Havel, Germany\"\n",
    "\n",
    "# Eisenbahnlinien holen\n",
    "rails = ox.features_from_place(\n",
    "    place,\n",
    "    tags={\"railway\": True}  # includes rail, light_rail, tram, etc.\n",
    ")\n",
    "\n",
    "# nur Schienenverkehr (keine Haltestellen)\n",
    "rails = rails[rails[\"railway\"].isin([\"rail\"])]"
   ],
   "id": "d902584f88044dd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from shapely.geometry import LineString\n",
    "\n",
    "# Schritt 2: Fu√üƒ∫√§ufige Routen zum Stadtzentrum auf Schnittpunkt mit Bahnlinie pr√ºfen und im Datensatz speichern\n",
    "def route_crosses_rail(route_geojson_str, rail_geom):\n",
    "    if not isinstance(route_geojson_str, str):\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        geo = json.loads(route_geojson_str)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "    if geo.get(\"type\") != \"LineString\":\n",
    "        return False\n",
    "\n",
    "    # Koordinaten (lon, lat) -> Shapely LineString nutzen\n",
    "    coords = geo[\"coordinates\"]\n",
    "    line = LineString(coords)\n",
    "\n",
    "    # Schnitt-Test\n",
    "    return line.intersects(rail_geom)\n",
    "\n",
    "rail_union = rails.union_all()\n",
    "gdf[\"behind_rail_from_center\"] = gdf[\"center_route\"].apply(\n",
    "    lambda r: int(route_crosses_rail(r, rail_union))\n",
    ")\n",
    "\n",
    "print(gdf.shape)"
   ],
   "id": "e81e3b0dad416510",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "import folium\n",
    "\n",
    "# 10 zuf√§llige Adressen ziehen\n",
    "sample_gdf = gdf.sample(10, random_state=42)\n",
    "\n",
    "center_lat, center_lon = CITY_CENTER  # CITY_CENTER ist [lat, lon]\n",
    "center_point = (center_lat, center_lon)\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Zentrum markieren\n",
    "folium.Marker(\n",
    "    location=CITY_CENTER,\n",
    "    tooltip=\"Stadtzentrum\",\n",
    "    icon=folium.Icon(color=\"red\", icon=\"star\")\n",
    ").add_to(m)\n",
    "\n",
    "# Route + Marker je Adresse\n",
    "for idx, row in sample_gdf.iterrows():\n",
    "    if pd.isna(row[\"lat\"]) or pd.isna(row[\"lon\"]):\n",
    "        continue\n",
    "\n",
    "    addr_point = (row[\"lat\"], row[\"lon\"])\n",
    "    behind_flag = row.get(\"behind_rail_from_center\", None)\n",
    "\n",
    "    tooltip = f\"Adresse {idx}<br>behind_rail_from_center: {behind_flag}\"\n",
    "\n",
    "    # Route zum Zentrum (GeoJSON)\n",
    "    route_json = row.get(\"center_route\")\n",
    "\n",
    "    if isinstance(route_json, str):\n",
    "        try:\n",
    "            route_geo = json.loads(route_json)\n",
    "\n",
    "            if route_geo.get(\"type\") == \"LineString\":\n",
    "                # GeoJSON Koordinaten sind (lon, lat)\n",
    "                coords = [(c[1], c[0]) for c in route_geo[\"coordinates\"]]\n",
    "\n",
    "                folium.PolyLine(\n",
    "                    locations=coords,\n",
    "                    color=\"blue\",\n",
    "                    weight=4,\n",
    "                    opacity=0.7,\n",
    "                    tooltip=f\"Route zu Adresse {idx}\"\n",
    "                ).add_to(m)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Zeichnen der Route f√ºr Adresse {idx}: {e}\")\n",
    "\n",
    "    # Adressmarker\n",
    "    folium.CircleMarker(\n",
    "        location=addr_point,\n",
    "        radius=4,\n",
    "        color=\"blue\",\n",
    "        fill=True,\n",
    "        fill_opacity=0.8,\n",
    "        tooltip=folium.Tooltip(tooltip)\n",
    "    ).add_to(m)\n",
    "\n",
    "# Bahnlinien-Layer\n",
    "bahn_layer = folium.FeatureGroup(name=\"Bahnlinien (OSM)\", show=True)\n",
    "\n",
    "for _, row in rails.iterrows():\n",
    "    geom = row.geometry\n",
    "    if geom is None:\n",
    "        continue\n",
    "\n",
    "    if geom.geom_type == \"LineString\":\n",
    "        coords = [(y, x) for x, y in geom.coords]\n",
    "        folium.PolyLine(\n",
    "            locations=coords,\n",
    "            color=\"darkred\",\n",
    "            weight=4,\n",
    "            opacity=0.8\n",
    "        ).add_to(bahn_layer)\n",
    "\n",
    "    elif geom.geom_type == \"MultiLineString\":\n",
    "        for part in geom:\n",
    "            coords = [(y, x) for x, y in part.coords]\n",
    "            folium.PolyLine(\n",
    "                locations=coords,\n",
    "                color=\"darkred\",\n",
    "                weight=4,\n",
    "                opacity=0.8\n",
    "            ).add_to(bahn_layer)\n",
    "\n",
    "bahn_layer.add_to(m)\n",
    "\n",
    "print(gdf.shape)\n",
    "m"
   ],
   "id": "44fcb8f889ac1cf4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Visualisierung aller Indikatoren\n",
    "Alle Einflussfaktoren (Superm√§rkte, √Ñrzte, Schulen etc.) werden zur Plausibilit√§tspr√ºfung auf einer Karte visualisiert."
   ],
   "id": "1a1d9689bda3a442"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "import branca.colormap as cm\n",
    "from helper import add_markers_from_csv, STRASSENNAME, HAUSNUMMER, HAUSNUMMERZUSATZ\n",
    "import ast\n",
    "\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"cartodbpositron\")\n",
    "\n",
    "# √Ñrzte laden\n",
    "df_aerzte = pd.read_csv(\"out/aerzte_geocoded.csv\")\n",
    "# Lookup Dictionary: Name_Arzt -> Fachrichtung\n",
    "fach_lookup = dict(zip(df_aerzte[\"Name_Arzt\"], df_aerzte[\"Fachrichtung\"]))\n",
    "\n",
    "def add_medcenter_markers(map_obj, csv_path, color=\"red\", icon=\"staff-snake\", layer_name=\"Medizinische Zentren\"):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    layer = folium.FeatureGroup(name=layer_name)\n",
    "    layer.add_to(map_obj)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        lat, lon = row[\"lat\"], row[\"lon\"]\n",
    "        if pd.isna(lat) or pd.isna(lon):\n",
    "            continue\n",
    "\n",
    "        # Arztliste parsen\n",
    "        arzt_keys = row.get(\"arzt_keys_100m\", \"[]\")\n",
    "        if isinstance(arzt_keys, str):\n",
    "            arzt_keys = ast.literal_eval(arzt_keys)\n",
    "\n",
    "        # Popup zusammenbauen\n",
    "        lines = []\n",
    "\n",
    "        if bool(row.get(\"is_med_center\", False)):\n",
    "            lines.append(f\"<b>Medizinisches Zentrum<br>{row.get('Strassenname','')}</b><br>\")\n",
    "\n",
    "        # Apotheke\n",
    "        name_ap = str(row.get(\"Name_Apotheke\", \"\")).strip()\n",
    "        if name_ap:\n",
    "            lines.append(f\"üè• {name_ap}<br>\")\n",
    "\n",
    "        # Anzahl √Ñrzte\n",
    "        if len(arzt_keys) > 0:\n",
    "            lines.append(f\"<br><b>{len(arzt_keys)} Arztpraxen im 100 m Radius:</b><br>\")\n",
    "\n",
    "        # √Ñrzte + Fachrichtung\n",
    "        for arzt in arzt_keys:\n",
    "            fach = fach_lookup.get(arzt, \"(Fachrichtung unbekannt)\")\n",
    "            lines.append(f\"{arzt} ‚Äì {fach}<br>\")\n",
    "\n",
    "        popup_html = \"\".join(lines)\n",
    "\n",
    "        # Icon w√§hlen\n",
    "        ico = folium.Icon(color=color, icon=icon, prefix=\"fa\")\n",
    "\n",
    "        marker = folium.Marker(\n",
    "            location=[lat, lon],\n",
    "            tooltip=row.get(\"Strassenname\", \"MedZentrum\"),\n",
    "            icon=ico\n",
    "        ).add_to(layer)\n",
    "\n",
    "        # Popup breiter machen\n",
    "        marker.add_child(folium.Popup(popup_html, max_width=450))\n",
    "\n",
    "# Add layer markers\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/einzelhandel_geocoded.csv\", color=\"blue\", icon=\"shopping-cart\", layer_name=\"Einzelhandel\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/grundschulen_geocoded.csv\", color=\"green\", icon=\"graduation-cap\", layer_name=\"Grundschulen\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/kitas_geocoded.csv\", color=\"beige\", icon=\"child\", layer_name=\"Kitas\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/haltestellen_geocoded.csv\", color=\"lightgray\", icon=\"bus\", layer_name=\"Haltestellen\")\n",
    "add_medcenter_markers(map_obj=m, csv_path=\"out/medzentren_geocoded.csv\")\n",
    "\n",
    "# L√§rmindex aus dem Geopackage\n",
    "gdf_laerm_karte = gpd.read_file(\"data/laerm.gpkg\", layer=\"laerm\")\n",
    "gdf_laerm_karte = gdf_laerm_karte.clip(CITY_BOUNDING_BOX)\n",
    "value_column = \"isov1\"\n",
    "min_val = gdf_laerm_karte[value_column].min()\n",
    "max_val = gdf_laerm_karte[value_column].max()\n",
    "colormap = cm.LinearColormap(colors=[\"green\", \"yellow\", \"red\"], vmin=min_val, vmax=max_val)\n",
    "colormap.caption = \"L√§rmpegel (LDEN in dB)\"\n",
    "\n",
    "# √Ñrzte\n",
    "df_aerzte = pd.read_csv(\"out/aerzte_geocoded.csv\")\n",
    "fach_lookup = dict(zip(df_aerzte[\"Name_Arzt\"], df_aerzte[\"Fachrichtung\"]))\n",
    "\n",
    "# Alle Adressen als Punkte\n",
    "adress_layer = folium.FeatureGroup(name=\"Wohnadressen\", show=False)\n",
    "for _, row in gdf.iterrows():\n",
    "    if pd.notna(row[\"lat\"]) and pd.notna(row[\"lon\"]):\n",
    "        strasse = s(row.get(STRASSENNAME))\n",
    "        hsnr = s(row.get(HAUSNUMMER))\n",
    "        hsnrzus = s(row.get(HAUSNUMMERZUSATZ))\n",
    "\n",
    "        tooltip = strasse + \" \" + hsnr\n",
    "\n",
    "        adressen_map = folium.CircleMarker(\n",
    "            location=[row[\"lat\"], row[\"lon\"]],\n",
    "            radius=3,\n",
    "            color=\"violet\",\n",
    "            fill=True,\n",
    "            fill_opacity=0.6,\n",
    "            tooltip=tooltip\n",
    "        ).add_to(adress_layer)\n",
    "adress_layer.add_to(m)\n",
    "\n",
    "def style_function(feature):\n",
    "    value = feature[\"properties\"][value_column]\n",
    "    return {\n",
    "        \"fillColor\": colormap(value),\n",
    "        \"color\": \"black\",\n",
    "        \"weight\": 0.3,\n",
    "        \"fillOpacity\": 0.2\n",
    "    }\n",
    "\n",
    "laerm_layer = folium.FeatureGroup(name=\"L√§rmkarte (LDEN 2022)\")\n",
    "folium.GeoJson(\n",
    "    gdf_laerm_karte,\n",
    "    style_function=style_function,\n",
    ").add_to(laerm_layer)\n",
    "laerm_layer.add_to(m)\n",
    "colormap.add_to(m)\n",
    "\n",
    "# Parks hinzuf√ºgen\n",
    "park_layer = folium.FeatureGroup(name=\"Parks\")\n",
    "folium.GeoJson(\n",
    "    gdf_parkanlagen,\n",
    "    style_function=lambda feature: {\n",
    "        \"color\": \"black\",\n",
    "        \"weight\": 0.2,\n",
    "        \"fillOpacity\": 0.9,\n",
    "        \"fillColor\": \"green\"\n",
    "    }\n",
    ").add_to(park_layer)\n",
    "park_layer.add_to(m)\n",
    "\n",
    "# Gr√ºnfl√§chen hinzuf√ºgen\n",
    "gruen_layer = folium.FeatureGroup(name=\"Freizeit- und Erholungsfl√§chen\")\n",
    "folium.GeoJson(\n",
    "    gdf_gruen_shape,\n",
    "    style_function=lambda feature: {\n",
    "        \"color\": \"black\",\n",
    "        \"weight\": 0.2,\n",
    "        \"fillOpacity\": 0.9,\n",
    "        \"fillColor\": \"green\"\n",
    "    }\n",
    ").add_to(gruen_layer)\n",
    "gruen_layer.add_to(m)\n",
    "\n",
    "# Bahnlinien layer hinzuf√ºgen\n",
    "bahn_layer = folium.FeatureGroup(name=\"Bahnlinien\", show=True)\n",
    "\n",
    "for _, row in rails.iterrows():\n",
    "    geom = row.geometry\n",
    "    if geom is None:\n",
    "        continue\n",
    "\n",
    "    if geom.geom_type == \"LineString\":\n",
    "        coords = [(y, x) for x, y in geom.coords]\n",
    "        folium.PolyLine(\n",
    "            locations=coords,\n",
    "            color=\"darkred\",\n",
    "            weight=4,\n",
    "            opacity=0.8\n",
    "        ).add_to(bahn_layer)\n",
    "\n",
    "    elif geom.geom_type == \"MultiLineString\":\n",
    "        for part in geom:\n",
    "            coords = [(y, x) for x, y in part.coords]\n",
    "            folium.PolyLine(\n",
    "                locations=coords,\n",
    "                color=\"darkred\",\n",
    "                weight=4,\n",
    "                opacity=0.8\n",
    "            ).add_to(bahn_layer)\n",
    "\n",
    "bahn_layer.add_to(m)\n",
    "\n",
    "# Wohnadressen nach \"cluster\" farb-codiert oben drauf\n",
    "\n",
    "\n",
    "# Schaltbare Layer\n",
    "folium.LayerControl(collapsed=False).add_to(m)\n",
    "del gdf_laerm_karte  # Speicher freigeben\n",
    "print(gdf.shape)\n",
    "m"
   ],
   "id": "779464ac37bb84c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Scoring / Punktesystem\n",
    "Hier werden z-Werte zu alle **Einflussfaktoren** gebildet, um die Abweichung einer Auspr√§gung vom Standard (im betrachteten Gebiet) zu erfassen. Weiterhin werden die **Gewichte** festgelegt, mit denen die Faktoren in die Wohnlagenbewertung eingehen."
   ],
   "id": "92944c1fbc1d51d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# ---------------------------------------\n",
    "# 1) Numerische & bin√§re Features\n",
    "# ---------------------------------------\n",
    "numeric_features = (\n",
    "        [\"center_distance\"] +\n",
    "        haltestellen_attribute +\n",
    "        headway_attribute +\n",
    "        einzelhandel_attribute +\n",
    "        laerm_attribute +\n",
    "        kitas_attribute +\n",
    "        grundschulen_attribute +\n",
    "        medzentren_attribute +\n",
    "        gruen_attribute\n",
    ")\n",
    "\n",
    "binary_features = [\"behind_rail_from_center\"]\n",
    "\n",
    "score_vars = numeric_features + binary_features\n",
    "\n",
    "# Masken nur auf numerische Daten!\n",
    "mask_all = gdf[numeric_features].notna().all(axis=1)\n",
    "\n",
    "# ---------------------------------------\n",
    "# 2) Z-Scores f√ºr numerische Variablen\n",
    "#    (immer: hoch = gut!)\n",
    "# ---------------------------------------\n",
    "\n",
    "# Zentralit√§t\n",
    "gdf.loc[mask_all, \"z_centrality\"] = -zscore(gdf.loc[mask_all, \"center_distance\"])\n",
    "\n",
    "# Einzelhandel\n",
    "gdf.loc[mask_all, \"z_einzelhandel_distance\"]    = -zscore(gdf.loc[mask_all, \"einzelhandel_min_distance\"])\n",
    "gdf.loc[mask_all, \"z_einzelhandel_near_500\"]    =  zscore(gdf.loc[mask_all, \"einzelhandel_500m_count\"])\n",
    "gdf.loc[mask_all, \"z_einzelhandel_near_800\"]    =  zscore(gdf.loc[mask_all, \"einzelhandel_800m_count\"])\n",
    "gdf.loc[mask_all, \"z_einzelhandel_near_1000\"]   =  zscore(gdf.loc[mask_all, \"einzelhandel_1000m_count\"])\n",
    "\n",
    "# L√§rm\n",
    "gdf.loc[mask_all, \"z_laerm_index_tag\"]          = -zscore(gdf.loc[mask_all, \"laerm_index_tag\"])\n",
    "\n",
    "# Kitas\n",
    "gdf.loc[mask_all, \"z_kita_distance\"]            = -zscore(gdf.loc[mask_all, \"kitas_min_distance\"])\n",
    "gdf.loc[mask_all, \"z_kita_near_500\"]            =  zscore(gdf.loc[mask_all, \"kitas_count_within_500m\"])\n",
    "gdf.loc[mask_all, \"z_kita_near_800\"]            =  zscore(gdf.loc[mask_all, \"kitas_count_within_800m\"])\n",
    "gdf.loc[mask_all, \"z_kita_near_1000\"]           =  zscore(gdf.loc[mask_all, \"kitas_count_within_1000m\"])\n",
    "\n",
    "# Grundschulen\n",
    "gdf.loc[mask_all, \"z_grundschulen_distance\"]    = -zscore(gdf.loc[mask_all, \"grundschulen_min_distance_m\"])\n",
    "gdf.loc[mask_all, \"z_grundschulen_near_500\"]    =  zscore(gdf.loc[mask_all, \"grundschulen_count_within_500m\"])\n",
    "gdf.loc[mask_all, \"z_grundschulen_near_800\"]    =  zscore(gdf.loc[mask_all, \"grundschulen_count_within_800m\"])\n",
    "gdf.loc[mask_all, \"z_grundschulen_near_1000\"]   =  zscore(gdf.loc[mask_all, \"grundschulen_count_within_1000m\"])\n",
    "\n",
    "# Mobilit√§t\n",
    "gdf.loc[mask_all, \"z_haltestelle_distance\"]     = -zscore(gdf.loc[mask_all, \"haltestellen_min_distance\"])\n",
    "gdf.loc[mask_all, \"z_haltestellen_count_within_500m\"] =  zscore(gdf.loc[mask_all, \"haltestellen_count_within_500m\"])\n",
    "gdf.loc[mask_all, \"z_haltestellen_count_within_800m\"] =  zscore(gdf.loc[mask_all, \"haltestellen_count_within_800m\"])\n",
    "#gdf.loc[mask_all, \"z_headway_score\"]            = -zscore(gdf.loc[mask_all, \"headway_avg\"]) # vorl√§ufig nicht in der Bewertung\n",
    "\n",
    "# Medizinische Versorgung\n",
    "gdf.loc[mask_all, \"z_medzentrum_distance\"]      = -zscore(gdf.loc[mask_all, \"medzentren_min_distance_m\"])\n",
    "gdf.loc[mask_all, \"z_medzentrum_near_500\"]      =  zscore(gdf.loc[mask_all, \"medzentren_count_within_500m\"])\n",
    "gdf.loc[mask_all, \"z_medzentrum_near_800\"]      =  zscore(gdf.loc[mask_all, \"medzentren_count_within_800m\"])\n",
    "gdf.loc[mask_all, \"z_medzentrum_near_1000\"]     =  zscore(gdf.loc[mask_all, \"medzentren_count_within_1000m\"])\n",
    "\n",
    "# Gr√ºnfl√§chen\n",
    "gdf.loc[mask_all, \"z_gruen_distance\"]           = -zscore(gdf.loc[mask_all, \"gruen_min_distance\"])\n",
    "gdf.loc[mask_all, \"z_gruen_near_500\"]           =  zscore(gdf.loc[mask_all, \"gruen_count_within_500m\"])\n",
    "gdf.loc[mask_all, \"z_gruen_near_800\"]           =  zscore(gdf.loc[mask_all, \"gruen_count_within_800m\"])\n",
    "gdf.loc[mask_all, \"z_gruen_near_1000\"]          =  zscore(gdf.loc[mask_all, \"gruen_count_within_1000m\"])\n",
    "\n",
    "def safe_z(x):\n",
    "    z = zscore(x)\n",
    "    # Falls Varianz = 0 oder einzelne Werte fehlen:\n",
    "    return np.where(np.isfinite(z), z, 0)\n",
    "\n",
    "# ---------------------------------------\n",
    "# Gro√üfl√§chen\n",
    "# Gewerbe (Industrie) -> weiter weg = gut\n",
    "mask_mm_gewerbe = gdf[\"gross_gewerbe_distance\"].notna()\n",
    "gdf.loc[mask_mm_gewerbe, \"z_gross_gewerbe_distance\"] = zscore(gdf.loc[mask_mm_gewerbe, \"gross_gewerbe_distance\"])\n",
    "\n",
    "# Gruen -> n√§her = gut\n",
    "mask_mm_gruen = gdf[\"gross_gruen_distance\"].notna()\n",
    "gdf.loc[mask_mm_gruen, \"z_gross_gruen_distance\"]    = -zscore(gdf.loc[mask_mm_gruen, \"gross_gruen_distance\"])\n",
    "\n",
    "# Sonstiges (Wasser) -> n√§her = gut\n",
    "mask_mm_sonst = gdf[\"gross_sonstiges_distance\"].notna()\n",
    "gdf.loc[mask_mm_sonst, \"z_gross_sonstiges_distance\"] = -zscore(gdf.loc[mask_mm_sonst, \"gross_sonstiges_distance\"])\n",
    "# ---------------------------------------\n",
    "\n",
    "# ---------------------------------------\n",
    "# 3) Score-Dimensionen (alle Summen = 1.0)\n",
    "# ---------------------------------------\n",
    "### 3.1 Zentralit√§t (1 Dimension, Summe = 1.0)\n",
    "mask_mm_central = gdf[\"center_distance\"].notna()\n",
    "gdf.loc[mask_mm_central, \"score_zentralitaet\"] = gdf.loc[mask_mm_central, \"z_centrality\"]\n",
    "\n",
    "\n",
    "### 3.2 Versorgung (Summe = 1.0)\n",
    "mask_mm_versorgung = gdf[[\n",
    "    \"einzelhandel_min_distance\",\n",
    "    \"einzelhandel_500m_count\",\n",
    "    \"einzelhandel_800m_count\",\n",
    "    \"einzelhandel_1000m_count\",\n",
    "    \"medzentren_min_distance_m\",\n",
    "    \"medzentren_count_within_500m\",\n",
    "    \"medzentren_count_within_800m\",\n",
    "    \"medzentren_count_within_1000m\"\n",
    "]].notna().all(axis=1)\n",
    "\n",
    "gdf.loc[mask_mm_versorgung, \"score_versorgung\"] = (\n",
    "      0.20 * gdf.loc[mask_mm_versorgung, \"z_einzelhandel_distance\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_versorgung, \"z_einzelhandel_near_500\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_versorgung, \"z_einzelhandel_near_800\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_versorgung, \"z_einzelhandel_near_1000\"]\n",
    "    + 0.20 * gdf.loc[mask_mm_versorgung, \"z_medzentrum_distance\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_versorgung, \"z_medzentrum_near_500\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_versorgung, \"z_medzentrum_near_800\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_versorgung, \"z_medzentrum_near_1000\"]\n",
    ")\n",
    "\n",
    "\n",
    "### 3.3 Mobilit√§t (Summe = 1.0)\n",
    "mask_mm_mobilitaet = gdf[[\n",
    "    \"haltestellen_min_distance\",\n",
    "    \"haltestellen_count_within_500m\",\n",
    "    \"haltestellen_count_within_800m\"\n",
    "]].notna().all(axis=1)\n",
    "\n",
    "gdf.loc[mask_mm_mobilitaet, \"score_mobilitaet\"] = (\n",
    "      0.80 * gdf.loc[mask_mm_mobilitaet, \"z_haltestelle_distance\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_mobilitaet, \"z_haltestellen_count_within_500m\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_mobilitaet, \"z_haltestellen_count_within_800m\"]\n",
    ")\n",
    "\n",
    "\n",
    "### 3.4 Bildung (Summe = 1.0)\n",
    "mask_mm_bildung = gdf[[\n",
    "    \"kitas_min_distance\",\n",
    "    \"kitas_count_within_500m\",\n",
    "    \"kitas_count_within_800m\",\n",
    "    \"kitas_count_within_1000m\",\n",
    "    \"grundschulen_min_distance_m\",\n",
    "    \"grundschulen_count_within_500m\",\n",
    "    \"grundschulen_count_within_800m\",\n",
    "    \"grundschulen_count_within_1000m\"\n",
    "]].notna().all(axis=1)\n",
    "\n",
    "gdf.loc[mask_mm_bildung, \"score_bildung\"] = (\n",
    "      0.15 * gdf.loc[mask_mm_bildung, \"z_kita_distance\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_bildung, \"z_kita_near_500\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_bildung, \"z_kita_near_800\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_bildung, \"z_kita_near_1000\"]\n",
    "    + 0.15 * gdf.loc[mask_mm_bildung, \"z_grundschulen_distance\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_bildung, \"z_grundschulen_near_500\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_bildung, \"z_grundschulen_near_800\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_bildung, \"z_grundschulen_near_1000\"]\n",
    ")\n",
    "\n",
    "\n",
    "### 3.5 Umwelt (Summe = 1.0)\n",
    "# Umwelt (Summe = 1.0)\n",
    "mask_mm_umwelt = gdf[[\n",
    "    \"gruen_min_distance\",\n",
    "    \"gruen_count_within_500m\",\n",
    "    \"gruen_count_within_800m\",\n",
    "    \"gruen_count_within_1000m\",\n",
    "    \"laerm_index_tag\",\n",
    "    \"z_gross_gewerbe_distance\",\n",
    "    \"z_gross_gruen_distance\",\n",
    "    \"z_gross_sonstiges_distance\"\n",
    "]].notna().all(axis=1)\n",
    "print(gdf[[\n",
    "    \"gruen_min_distance\",\n",
    "    \"gruen_count_within_500m\",\n",
    "    \"gruen_count_within_800m\",\n",
    "    \"gruen_count_within_1000m\",\n",
    "    \"laerm_index_tag\",\n",
    "    \"z_gross_gewerbe_distance\",\n",
    "    \"z_gross_gruen_distance\",\n",
    "    \"z_gross_sonstiges_distance\"\n",
    "]].notna())\n",
    "\n",
    "gdf.loc[mask_mm_umwelt, \"score_umwelt\"] = (\n",
    "      0.30 * gdf.loc[mask_mm_umwelt, \"z_gruen_distance\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_umwelt, \"z_gruen_near_500\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_umwelt, \"z_gruen_near_800\"]\n",
    "    + 0.05 * gdf.loc[mask_mm_umwelt, \"z_gruen_near_1000\"]\n",
    "    + 0.15 * gdf.loc[mask_mm_umwelt, \"z_laerm_index_tag\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_umwelt, \"z_gross_gewerbe_distance\"]     # Industrie\n",
    "    + 0.10 * gdf.loc[mask_mm_umwelt, \"z_gross_gruen_distance\"]       # Gr√ºn\n",
    "    + 0.10 * gdf.loc[mask_mm_umwelt, \"z_gross_sonstiges_distance\"]   # Wasser\n",
    ")\n",
    "\n",
    "# ---------------------------------------\n",
    "# 4) Gesamt-Score (alle Dimensionen verf√ºgbar)\n",
    "# ---------------------------------------\n",
    "score_all_vars = [\n",
    "    \"score_zentralitaet\",\n",
    "    \"score_bildung\",\n",
    "    \"score_versorgung\",\n",
    "    \"score_umwelt\",\n",
    "    \"score_mobilitaet\"\n",
    "]\n",
    "\n",
    "mask_all_scores = gdf[score_all_vars].notna().all(axis=1)\n",
    "\n",
    "gdf.loc[mask_all_scores, \"score_total\"] = (\n",
    "      0.20 * gdf.loc[mask_all_scores, \"score_zentralitaet\"]\n",
    "    + 0.20 * gdf.loc[mask_all_scores, \"score_bildung\"]\n",
    "    + 0.20 * gdf.loc[mask_all_scores, \"score_versorgung\"]\n",
    "    + 0.20 * gdf.loc[mask_all_scores, \"score_umwelt\"]\n",
    "    + 0.20 * gdf.loc[mask_all_scores, \"score_mobilitaet\"]\n",
    ")\n",
    "\n",
    "print(\"Anzahl g√ºltiger Gesamt-Scores:\", gdf[\"score_total\"].notna().sum())\n"
   ],
   "id": "36111c65c1e0e5b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Validierung\n",
    "\n",
    "Im Folgenden werden die Z-Variablen genutzt, um mittels K-Means-Clustering Wohnlagen zu identifizieren. Zun√§chst wird die optimale Clusteranzahl mittels Elbow-Methode und Silhouetten-Analyse bestimmt. Danach wird das finale K-Means-Modell mit der gew√§hlten Clusteranzahl trainiert und die Wohnlagen den Adressen zugewiesen."
   ],
   "id": "38efad5274a30e01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------\n",
    "# Z-Variablen aus allen Kategorien\n",
    "# ---------------------------------------\n",
    "z_vars = [\n",
    "    # Zentralit√§t\n",
    "    \"z_centrality\",\n",
    "\n",
    "    # Einzelhandel\n",
    "    \"z_einzelhandel_distance\",\n",
    "    \"z_einzelhandel_near_500\",\n",
    "    \"z_einzelhandel_near_800\",\n",
    "    \"z_einzelhandel_near_1000\",\n",
    "\n",
    "    # L√§rm\n",
    "    \"z_laerm_index_tag\",\n",
    "\n",
    "    # Kitas\n",
    "    \"z_kita_distance\",\n",
    "    \"z_kita_near_500\",\n",
    "    \"z_kita_near_800\",\n",
    "    \"z_kita_near_1000\",\n",
    "\n",
    "    # Grundschulen\n",
    "    \"z_grundschulen_distance\",\n",
    "    \"z_grundschulen_near_500\",\n",
    "    \"z_grundschulen_near_800\",\n",
    "    \"z_grundschulen_near_1000\",\n",
    "\n",
    "    # Haltestellen / Headway\n",
    "    \"z_haltestelle_distance\",\n",
    "    \"z_haltestellen_count_within_500m\",\n",
    "    \"z_haltestellen_count_within_800m\",\n",
    "    #\"z_headway_score\",\n",
    "\n",
    "    # MedZentren\n",
    "    \"z_medzentrum_distance\",\n",
    "    \"z_medzentrum_near_500\",\n",
    "    \"z_medzentrum_near_800\",\n",
    "    \"z_medzentrum_near_1000\",\n",
    "\n",
    "    # Gr√ºnfl√§chen\n",
    "    \"z_gruen_distance\",\n",
    "    \"z_gruen_near_500\",\n",
    "    \"z_gruen_near_800\",\n",
    "    \"z_gruen_near_1000\",\n",
    "\n",
    "    # Distanzen zu Gro√üfl√§chen\n",
    "    \"z_gross_gewerbe_distance\",\n",
    "    \"z_gross_gruen_distance\",\n",
    "    \"z_gross_sonstiges_distance\",\n",
    "]\n",
    "\n",
    "# ---------------------------------------\n",
    "# Validierung\n",
    "# ---------------------------------------\n",
    "missing = [c for c in z_vars if c not in gdf.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Diese Z-Variablen fehlen im gdf: {missing}\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# Datenmatrix: nur vollst√§ndige Zeilen\n",
    "# ---------------------------------------\n",
    "X = gdf[z_vars].dropna().values\n",
    "\n",
    "# ---------------------------------------\n",
    "# Elbow-Methode\n",
    "# ---------------------------------------\n",
    "inertia = []\n",
    "cluster_range = range(2, 20)\n",
    "\n",
    "for k in cluster_range:\n",
    "    model = KMeans(n_clusters=k, random_state=42)\n",
    "    model.fit(X)\n",
    "    inertia.append(model.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(cluster_range, inertia, marker='o')\n",
    "plt.title(\"Elbow-Methode: KMeans-Inertia vs. Clusteranzahl\")\n",
    "plt.xlabel(\"Anzahl Cluster (k)\")\n",
    "plt.ylabel(\"Inertia (Distanz innerhalb der Cluster)\")\n",
    "plt.xticks(cluster_range)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "a25fef9d8bf060c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Silhouetten-Analyse\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouettes = []\n",
    "\n",
    "for k in cluster_range:\n",
    "    model = KMeans(n_clusters=k, random_state=42)\n",
    "    labels = model.fit_predict(X)\n",
    "    score = silhouette_score(X, labels, random_state=42)\n",
    "    silhouettes.append(score)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(cluster_range, silhouettes, marker='o', color=\"green\")\n",
    "plt.title(\"Silhouetten-Score pro Clusteranzahl\")\n",
    "plt.xlabel(\"Anzahl Cluster (k)\")\n",
    "plt.ylabel(\"Durchschn. Silhouetten-Koeffizient\")\n",
    "plt.xticks(cluster_range)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "dd61e3f41e78504d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "NUMBER_OF_CLUSTERS = 8",
   "id": "123efa33a967ed0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "k = NUMBER_OF_CLUSTERS\n",
    "seeds = [0, 1, 2, 3, 4, 5, 42, 123]\n",
    "\n",
    "results = []\n",
    "\n",
    "for seed in seeds:\n",
    "    km = KMeans(\n",
    "        n_clusters=k,\n",
    "        init=\"k-means++\",\n",
    "        random_state=seed,\n",
    "        n_init=\"auto\",\n",
    "        max_iter=300,\n",
    "    ).fit(X)\n",
    "    labels = km.labels_\n",
    "    inertia = km.inertia_\n",
    "    sil = silhouette_score(X, labels)\n",
    "    results.append((seed, inertia, sil))\n",
    "\n",
    "for seed, inertia, sil in results:\n",
    "    print(f\"seed={seed}, inertia={inertia:.0f}, silhouette={sil:.3f}\")"
   ],
   "id": "a2986114291d30e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------\n",
    "# 1) KMeans\n",
    "# ----------------------------\n",
    "X = gdf[z_vars].dropna().values  # vollst√§ndige Zeilen\n",
    "model = KMeans(n_clusters=NUMBER_OF_CLUSTERS, random_state=4).fit(X)\n",
    "\n",
    "mask_complete = gdf[z_vars].notna().all(axis=1)\n",
    "gdf.loc[mask_complete, \"cluster\"] = model.labels_\n",
    "\n",
    "cluster_centers = pd.DataFrame(model.cluster_centers_, columns=z_vars)\n",
    "cluster_centers.index.name = \"Cluster\"\n",
    "print(cluster_centers.round(2))\n",
    "\n",
    "# ----------------------------\n",
    "# 2) PCA (3 Komponenten)\n",
    "# ----------------------------\n",
    "pca3 = PCA(n_components=3, random_state=42)\n",
    "\n",
    "X_pca3 = pca3.fit_transform(X)\n",
    "centers_pca3 = pca3.transform(cluster_centers.to_numpy())\n",
    "print(\"Explained variance ratio (3 PCs):\", pca3.explained_variance_ratio_)\n",
    "\n",
    "# Datenframe f√ºr Punkte\n",
    "df_pca = pd.DataFrame({\n",
    "    \"PC1\": X_pca3[:, 0],\n",
    "    \"PC2\": X_pca3[:, 1],\n",
    "    \"PC3\": X_pca3[:, 2],\n",
    "    \"cluster\": model.labels_\n",
    "})\n",
    "\n",
    "# Datenframe f√ºr Cluster-Zentren\n",
    "df_centers = pd.DataFrame({\n",
    "    \"PC1\": centers_pca3[:, 0],\n",
    "    \"PC2\": centers_pca3[:, 1],\n",
    "    \"PC3\": centers_pca3[:, 2],\n",
    "    \"cluster\": range(NUMBER_OF_CLUSTERS)\n",
    "})\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Interaktive 3D-Plotly-Grafik\n",
    "# ----------------------------\n",
    "colors = px.colors.qualitative.Dark24  # 24 Farben ‚Üí genug Reserve\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Clusterpunkte einzeichnen\n",
    "for cl in sorted(df_pca[\"cluster\"].unique()):\n",
    "    sub = df_pca[df_pca.cluster == cl]\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=sub[\"PC1\"],\n",
    "        y=sub[\"PC2\"],\n",
    "        z=sub[\"PC3\"],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(\n",
    "            size=3.5,\n",
    "            color=colors[cl % len(colors)],\n",
    "            opacity=0.65\n",
    "        ),\n",
    "        name=f\"Cluster {cl}\"\n",
    "    ))\n",
    "\n",
    "# Clusterzentren\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=df_centers[\"PC1\"],\n",
    "    y=df_centers[\"PC2\"],\n",
    "    z=df_centers[\"PC3\"],\n",
    "    mode=\"markers\",\n",
    "    marker=dict(\n",
    "        size=6,\n",
    "        color=\"black\",\n",
    "        symbol=\"x\",\n",
    "        opacity=0.9\n",
    "    ),\n",
    "    name=\"Cluster-Zentren\"\n",
    "))\n",
    "\n",
    "# Layout\n",
    "fig.update_layout(\n",
    "    title=\"Hauptkomponentenprojektion (PCA) ‚Äì KMeans-Cluster\",\n",
    "    scene=dict(\n",
    "        xaxis_title=\"PC1\",\n",
    "        yaxis_title=\"PC2\",\n",
    "        zaxis_title=\"PC3\"\n",
    "    ),\n",
    "    height=750,\n",
    "    legend=dict(itemsizing=\"constant\")\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ],
   "id": "2a3ba24b6de7a923",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "\n",
    "mask = gdf[\"lat\"].notna() & gdf[\"lon\"].notna() & gdf[\"cluster\"].notna()\n",
    "gdf = gdf.loc[mask].copy()\n",
    "gdf[\"cluster\"] = gdf[\"cluster\"].astype(int)\n",
    "\n",
    "def get_cluster_colors(n_clusters):\n",
    "    cmap = plt.get_cmap(\"tab20\")   # 20 unterscheidbare Farben\n",
    "    colors = {\n",
    "        i: mcolors.to_hex(cmap(i % 20))\n",
    "        for i in range(n_clusters)\n",
    "    }\n",
    "    return colors\n",
    "\n",
    "cluster_colors = get_cluster_colors(NUMBER_OF_CLUSTERS)\n",
    "\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Add layer markers\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/einzelhandel_geocoded.csv\", color=\"blue\", icon=\"shopping-cart\", layer_name=\"Einzelhandel\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/grundschulen_geocoded.csv\", color=\"green\", icon=\"graduation-cap\", layer_name=\"Grundschulen\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/kitas_geocoded.csv\", color=\"beige\", icon=\"child\", layer_name=\"Kitas\")\n",
    "add_markers_from_csv(map_obj=m,csv_path=\"out/haltestellen_geocoded.csv\",color=\"lightgray\", icon=\"bus\", layer_name=\"Haltestellen\")\n",
    "add_medcenter_markers(map_obj=m, csv_path=\"out/medzentren_geocoded.csv\")\n",
    "\n",
    "valid_kita_json = gdf[\"kitas_route\"].apply(lambda x: isinstance(x, str))\n",
    "print(\"G√ºltige JSON-Eintr√§ge:\", valid_kita_json.sum(), \"/\", len(gdf))\n",
    "\n",
    "for _, r in gdf.iterrows():\n",
    "    c = cluster_colors.get(r.cluster, \"#666666\")\n",
    "    folium.CircleMarker(\n",
    "        location=[r.lat, r.lon],\n",
    "        radius=3,\n",
    "        color=c,\n",
    "        fill=True,\n",
    "        fill_color=c,\n",
    "        fill_opacity=0.85,\n",
    "        tooltip=f\"{r.Stra√üenname} {r.Hsnr} ‚Äì Cluster {r.cluster}\"\n",
    "    ).add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "m"
   ],
   "id": "19db7c7c67edc72a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Nur Spalten verwenden, die im gdf enthalten sind\n",
    "cols = [col for col in z_vars if col in gdf.columns]\n",
    "\n",
    "# Korrelationsmatrix berechnen\n",
    "corr = gdf[cols].corr()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(corr, annot=True, cmap=\"vlag\", center=0)\n",
    "plt.title(\"Korrelationsmatrix der Z-Scores\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "3884a510fe473e01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Die Korrelationsanalyse zeigt, dass einige Variablen stark korreliert sind, z. B. die verschiedenen Distanzen zu Einzelhandelsstandorten und die Anzahl der Standorte in der N√§he. Dies ist zu erwarten, da Adressen, die n√§her an Einzelhandelsstandorten liegen, tendenziell auch mehr Standorte in ihrer Umgebung haben. Gleichzeitig ist die Zentralit√§t erwartungskonform leicht mit der Verf√ºgbarkeit von Nahversorgung (Einkaufsm√∂glichkeiten, medizinische Versorgung, Kitas) korreliert. Diese Erkenntnisse sind Hinweise auf die Plausibilit√§t des Modells, wobei gleichzeitg keine perfekten Korrelationen vorliegen, die auf Redundanzen hindeuten w√ºrden. Alle bisher betrachteten Kriterien scheinen relevante und unterschiedliche Aspekte der Wohnlage zu erfassen.",
   "id": "93a582f2058f2e79"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Interaktive Karte zur Bewertung einzelner Adressen",
   "id": "1495801883de52ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "# Widget f√ºr Adresseingabe\n",
    "text_input = widgets.Text(\n",
    "    value='Kurstra√üe 15',\n",
    "    placeholder='Stra√üenname Hausnummer',\n",
    "    description='Adresse:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "button = widgets.Button(description=\"Zeige Routen\")\n",
    "output = widgets.Output()\n",
    "\n",
    "# Hilfsfunktion\n",
    "def load_geojson(geo):\n",
    "    \"\"\"Konvertiert GeoJSON-Felder sicher in ein Python-Dict.\"\"\"\n",
    "    if geo is None:\n",
    "        return None\n",
    "    if isinstance(geo, float):  # NaN\n",
    "        return None\n",
    "    if isinstance(geo, dict):   # bereits dict\n",
    "        return geo\n",
    "    if isinstance(geo, str) and geo.strip() == \"\":\n",
    "        return None\n",
    "    if isinstance(geo, str):\n",
    "        try:\n",
    "            return json.loads(geo)\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def scale_score(z):\n",
    "    \"\"\"Skaliert Z-Score linear auf 0 - 10 f√ºr B√ºrgerverst√§ndlichkeit.\"\"\"\n",
    "    if pd.isna(z):\n",
    "        return None\n",
    "    score = (z + 3) / 6 * 10\n",
    "    return max(0, min(10, round(score, 1)))\n",
    "\n",
    "gdf[\"score_total_scaled\"]        = gdf[\"score_total\"].apply(scale_score)\n",
    "gdf[\"score_zentralitaet_scaled\"] = gdf[\"score_zentralitaet\"].apply(scale_score)\n",
    "gdf[\"score_versorgung_scaled\"]   = gdf[\"score_versorgung\"].apply(scale_score)\n",
    "gdf[\"score_bildung_scaled\"]      = gdf[\"score_bildung\"].apply(scale_score)\n",
    "gdf[\"score_mobilitaet_scaled\"]   = gdf[\"score_mobilitaet\"].apply(scale_score)\n",
    "gdf[\"score_umwelt_scaled\"]       = gdf[\"score_umwelt\"].apply(scale_score)\n",
    "\n",
    "def score_color(value):\n",
    "    if value is None:\n",
    "        return \"gray\"\n",
    "    if value >= 8:\n",
    "        return \"#2ecc71\"   # gr√ºn\n",
    "    if value >= 5:\n",
    "        return \"#f1c40f\"   # gelb\n",
    "    return \"#e74c3c\"        # rot\n",
    "\n",
    "# Funktion zum Einf√ºgen einer Route + Zielmarker\n",
    "def add_route(m, geojson_raw, color, label, icon, distance=None):\n",
    "    geo = load_geojson(geojson_raw)\n",
    "    if not geo:\n",
    "        return  # keine Route vorhanden\n",
    "\n",
    "    if geo.get(\"type\") == \"LineString\":\n",
    "        try:\n",
    "            coords = [(y, x) for x, y in geo[\"coordinates\"]]\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Lesen der Koordinaten f√ºr {label}: {e}\")\n",
    "            return\n",
    "\n",
    "        distance_text = f\" ‚Äì {int(distance)} m\" if distance else \"\"\n",
    "        tooltip_text = f\"{label}{distance_text}\"\n",
    "\n",
    "        folium.PolyLine(\n",
    "            locations=coords,\n",
    "            color=color,\n",
    "            weight=4,\n",
    "            opacity=0.9,\n",
    "            tooltip=tooltip_text\n",
    "        ).add_to(m)\n",
    "\n",
    "        # Zielpunkt markieren\n",
    "        end = coords[-1]\n",
    "        folium.Marker(\n",
    "            location=end,\n",
    "            icon=folium.Icon(color=color, icon=icon, prefix=\"fa\"),\n",
    "            tooltip=f\"Ziel: {label}{distance_text}\"\n",
    "        ).add_to(m)\n",
    "\n",
    "# Funktion zum Anzeigen der Karte\n",
    "def show_routes(_=None):\n",
    "    output.clear_output(wait=True)\n",
    "    with output:\n",
    "        addr = text_input.value.strip().lower()\n",
    "\n",
    "        filtered = gdf[gdf[\"Adresse_merge\"].str.lower().str.contains(addr)].copy()\n",
    "        if filtered.empty:\n",
    "            print(\"Keine passende Adresse gefunden.\")\n",
    "            return\n",
    "\n",
    "        row = filtered.iloc[0]\n",
    "\n",
    "        m = folium.Map(\n",
    "            tiles=\"cartodbpositron\",\n",
    "            location=CITY_CENTER,\n",
    "            zoom_start=12,\n",
    "        )\n",
    "\n",
    "        # Farbige Score-Badges\n",
    "        def badge(label, val):\n",
    "            col = score_color(val)\n",
    "            return f\"<div style='padding:4px 8px;margin:2px;background:{col};color:white;border-radius:4px;display:inline-block;'>{label}: {val}</div>\"\n",
    "\n",
    "        popup_html = f\"\"\"\n",
    "        <div style=\"width:420px;font-family:Arial, sans-serif;\">\n",
    "          <h2>{row['Stra√üenname']} {row['Hsnr']}</h2>\n",
    "\n",
    "          <h3>Gesamtbewertung</h3>\n",
    "          {badge(\"Gesamt\", row.get('score_total_scaled'))}\n",
    "\n",
    "          <h3>Teilbereiche</h3>\n",
    "          {badge(\"Zentralit√§t\", row.get('score_zentralitaet_scaled'))}\n",
    "          {badge(\"Versorgung\", row.get('score_versorgung_scaled'))}\n",
    "          {badge(\"Bildung\", row.get('score_bildung_scaled'))}\n",
    "          {badge(\"Mobilit√§t\", row.get('score_mobilitaet_scaled'))}\n",
    "          {badge(\"Umwelt\", row.get('score_umwelt_scaled'))}\n",
    "\n",
    "\n",
    "          <h3 style=\"margin-top:15px;\">Fu√ül√§ufige Entfernungen</h3>\n",
    "          <ul>\n",
    "            <li><b>Entfernung Zentrum:</b> {int(row.get(\"center_distance\",0))} m</li>\n",
    "            <li><b>N√§chste Haltestelle:</b> {int(row.get(\"haltestellen_min_distance\",0))} m</li>\n",
    "            <li><b>N√§chster Einzelhandel:</b> {int(row.get(\"einzelhandel_min_distance\",0))} m</li>\n",
    "            <li><b>N√§chste Kita:</b> {int(row.get(\"kitas_min_distance\",0))} m</li>\n",
    "            <li><b>N√§chste Grundschule:</b> {int(row.get(\"grundschulen_min_distance_m\",0))} m</li>\n",
    "            <li><b>Med. Zentrum:</b> {int(row.get(\"medzentren_min_distance_m\",0))} m</li>\n",
    "            <li><b>Gr√ºnfl√§che:</b> {int(row.get(\"gruen_min_distance\",0))} m</li>\n",
    "          </ul>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "        popup = folium.Popup(popup_html, max_width=450)\n",
    "\n",
    "        marker = folium.Marker(\n",
    "            location=[row.lat, row.lon],\n",
    "            popup=popup,\n",
    "            icon=folium.Icon(color=\"blue\", icon=\"info-sign\")\n",
    "        ).add_to(m)\n",
    "\n",
    "        # Popup automatisch √∂ffnen\n",
    "        marker.add_child(folium.Popup(popup_html, max_width=450))\n",
    "        marker.add_child(folium.map.Tooltip(\"\"))  # kein Tooltip\n",
    "\n",
    "        # Popup sofort anzeigen\n",
    "        marker._popup = popup\n",
    "\n",
    "        # Startmarker\n",
    "        folium.Marker(\n",
    "            location=[row.lat, row.lon],\n",
    "            popup=popup_html,\n",
    "        ).add_to(m)\n",
    "\n",
    "        # ‚ñ∏ Routen einf√ºgen\n",
    "        add_route(m, row.get(\"center_route\"), \"lightgray\", \"Weg zum Zentrum\", \"arrows-to-circle\", row.get(\"center_distance\"))\n",
    "        add_route(m, row.get(\"kitas_route\"), \"cadetblue\", \"N√§chste Kita\", \"child\", row.get(\"kitas_min_distance\"))\n",
    "        add_route(m, row.get(\"grundschulen_route\"), \"cadetblue\", \"N√§chste Grundschule\", \"graduation-cap\", row.get(\"grundschulen_min_distance_m\"))\n",
    "        add_route(m, row.get(\"haltestellen_route\"), \"beige\", \"N√§chste Haltestelle\", \"bus\", row.get(\"haltestellen_min_distance\"))\n",
    "        add_route(m, row.get(\"medzentren_route\"), \"red\", \"N√§chstes Medizinisches Zentrum\", \"staff-snake\", row.get(\"medzentren_min_distance_m\"))\n",
    "        add_route(m, row.get(\"einzelhandel_route\"), \"purple\", \"N√§chster Einzelhandel\", \"shop\", row.get(\"einzelhandel_min_distance\"))\n",
    "        add_route(m, row.get(\"gruen_route\"), \"darkgreen\", \"N√§chste Freizeit- und Erholungsfl√§che\", \"tree\", row.get(\"gruen_min_distance\"))\n",
    "\n",
    "        display(m)\n",
    "\n",
    "# Button-Event\n",
    "button.on_click(show_routes)\n",
    "\n",
    "# UI anzeigen\n",
    "display(text_input, button, output)"
   ],
   "id": "1505678dc5e76d43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# R√§umliches Clustering\n",
    "Ein Ziel der Analyse ist die Entwicklung zusammenh√§ngender Gebiete, die einer gemeinsamen Wohnlage zugeordnet werden k√∂nnen. Damit sollen \"Insellagen\", also mehrere abgeschnittene Bereiche mit derselben Wohnlage vermieden werden. Daf√ºr wenden wir im Folgenden eine Gl√§ttung mit dem SKATER-Ansatz an (vgl. [Assun√ß√£o et al. 2006](https://www.tandfonline.com/doi/abs/10.1080/13658810600665111]))."
   ],
   "id": "e06cb92a06290d6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from libpysal import weights\n",
    "from libpysal.weights import KNN\n",
    "from spopt.region import Skater\n",
    "from libpysal.weights import DistanceBand\n",
    "\n",
    "# Metrische Projektion f√ºr korrekte Berechnung\n",
    "gdf = gdf.to_crs(epsg=32633)\n",
    "\n",
    "# Index zur√ºcksetzen\n",
    "gdf.reset_index(drop=True)\n",
    "\n",
    "z_vars = [\n",
    "    'z_centrality',\n",
    "    'z_einzelhandel_distance',\n",
    "    'z_laerm_index_tag',\n",
    "    'z_kita_distance',\n",
    "    'z_grundschulen_distance',\n",
    "    'z_haltestelle_distance',\n",
    "    'z_medzentrum_distance',\n",
    "    'z_gruen_distance',\n",
    "    #'z_headway_score',\n",
    "    #'z_gross_gewerbe_distance',\n",
    "    #'z_gross_sonstiges_distance',\n",
    "    #'z_gross_gruen_distance'\n",
    "]\n",
    "\n",
    "# Erzeuge Gewichtsmatrix\n",
    "W = weights.contiguity.Queen.from_dataframe(gdf, use_index=True)\n",
    "\n",
    "print(f\"n_components: {W.n_components}\")\n",
    "print(f\"W.component_labels: {W.component_labels}\")\n",
    "print(f\"Inseln in W: {W.islands}\")\n",
    "\n",
    "sk = Skater(\n",
    "    gdf, W, z_vars,\n",
    "    n_clusters=NUMBER_OF_CLUSTERS,\n",
    "    islands = \"ignore\"\n",
    ")\n",
    "sk.solve()\n",
    "\n",
    "gdf[\"cluster_skater\"] = sk.labels_"
   ],
   "id": "99063ccb0de835ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot histogram of form [(np.int64(0), np.int64(3)), (np.int64(1), np.int64(4)), (np.int64(2), np.int64...\n",
    "import matplotlib.pyplot as plt\n",
    "cluster_counts = gdf[\"cluster_skater\"].value_counts().sort_index()\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(cluster_counts.index.astype(str), cluster_counts.values, color='skyblue')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Anzahl Adressen')\n",
    "plt.title('Anzahl der Adressen pro Cluster (SKATER)')\n",
    "plt.xticks(cluster_counts.index.astype(str))\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ],
   "id": "108046004e72b76b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Cluster-Karte",
   "id": "faebb2e1aabc7784"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# Daten laden & CRS vereinheitlichen\n",
    "gdf_quartiere = gpd.read_file(\"data/Quartiere/2024_Quartiere.gpkg\")\n",
    "gdf_ortsteile = gpd.read_file(\"data/ortsteile_brandenburg.json\", bbox=CITY_BOUNDING_BOX)\n",
    "gdf_quartiere = gdf_quartiere.to_crs(4326)\n",
    "gdf_ortsteile.drop(columns=[\"otl_aktualitaet\"], inplace=True, errors=\"ignore\") # Karte will keine Timestamps!\n",
    "gdf = gdf.to_crs(4326)\n",
    "\n",
    "assert gdf.crs.to_epsg() == 4326\n",
    "assert gdf_quartiere.crs.to_epsg() == 4326\n",
    "assert gdf_ortsteile.crs.to_epsg() == 4326\n",
    "\n",
    "# Spatial Join: Adressen -> Quartiere\n",
    "# alte Spalten sicher entfernen\n",
    "gdf = gdf.drop(columns=[\"index_right\", \"mietkatego\", \"mietkategorie\", \"bezeichnun\", \"quartier\"], errors=\"ignore\")\n",
    "cols_to_drop = [col for col in gdf.columns if col.endswith(\"_quartier\")]\n",
    "\n",
    "gdf = gdf.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "gdf = gpd.sjoin(\n",
    "    gdf,\n",
    "    gdf_quartiere[[\"bezeichnun\", \"mietkatego\", \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    predicate=\"within\",\n",
    ")\n",
    "\n",
    "# Spatial Join: Adressen -> Ortsteile\n",
    "# alte Spalten sicher entfernen\n",
    "gdf = gdf.drop(columns=[\"index_right\", \"otl_name\", \"index_left\", \"otl_name_left\", \"otl_name_right\"], errors=\"ignore\")\n",
    "gdf = gpd.sjoin(\n",
    "    gdf,\n",
    "    gdf_ortsteile[[\"otl_name\", \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    predicate=\"within\",\n",
    ")\n",
    "\n",
    "gdf = gdf.drop(columns=[\"index_right\"])\n",
    "\n",
    "gdf = gdf.rename(columns={\n",
    "    \"otl_name\": \"ortsteil\",\n",
    "    \"bezeichnun\": \"quartier\",\n",
    "    \"mietkatego\": \"mietkategorie\"\n",
    "})\n",
    "\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Ortsteile layer\n",
    "folium.GeoJson(\n",
    "    gdf_ortsteile,\n",
    "    name=\"Ortsteile\",\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': '#1f78b4',\n",
    "        'color': '#1f78b4',\n",
    "        'weight': 1,\n",
    "        'fillOpacity': 0.10,\n",
    "    },\n",
    "    tooltip=folium.GeoJsonTooltip(\n",
    "        fields=[\"otl_name\"],\n",
    "        aliases=[\"Ortsteil\"],\n",
    "        localize=True,\n",
    "        sticky=True\n",
    "    )\n",
    ").add_to(m)\n",
    "\n",
    "#  Quartiere layer\n",
    "folium.GeoJson(\n",
    "    gdf_quartiere,\n",
    "    name=\"Quartiere\",\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': 'orange',\n",
    "        'color': 'orange',\n",
    "        'weight': 1,\n",
    "        'fillOpacity': 0.20,\n",
    "    },\n",
    "    tooltip=folium.GeoJsonTooltip(\n",
    "        fields=[\"bezeichnun\", \"mietkatego\"],\n",
    "        aliases=[\"Quartier\", \"Mietkategorie\"],\n",
    "        localize=True,\n",
    "        sticky=True\n",
    "    )\n",
    ").add_to(m)\n",
    "\n",
    "# KMeans-Cluster einf√ºgen (zum Vergleich mit spatial-Ergebnis)\n",
    "cluster_kmeans_layer = folium.FeatureGroup(name=\"Cluster (kMeans)\", show=True)\n",
    "for _, r in gdf.iterrows():\n",
    "    c = cluster_colors.get(r.cluster, \"#666666\")\n",
    "    folium.CircleMarker(\n",
    "        location=[r.lat, r.lon],\n",
    "        radius=3,\n",
    "        color=c,\n",
    "        fill=True,\n",
    "        fill_color=c,\n",
    "        fill_opacity=0.85,\n",
    "        tooltip=f\"{r.Stra√üenname} {r.Hsnr} ‚Äì Cluster {r.cluster}\"\n",
    "    ).add_to(cluster_kmeans_layer)\n",
    "cluster_kmeans_layer.add_to(m)\n",
    "\n",
    "# Clusterpunkte layer\n",
    "cluster_skater_layer = folium.FeatureGroup(name=\"Cluster (SKATER)\", show=True)\n",
    "for _, r in gdf.iterrows():\n",
    "    c = cluster_colors.get(r.cluster_skater, \"#666666\")\n",
    "    folium.CircleMarker(\n",
    "        location=[r.lat, r.lon],\n",
    "        radius=3,\n",
    "        color=c,\n",
    "        fill=True,\n",
    "        fill_color=c,\n",
    "        fill_opacity=0.85,\n",
    "        tooltip=f\"{r.Stra√üenname} {r.Hsnr} ‚Äì Cluster {r.cluster_skater}\"\n",
    "    ).add_to(cluster_skater_layer)\n",
    "\n",
    "cluster_skater_layer.add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "m"
   ],
   "id": "37bb9529b5b0103a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Abgleich mit Ortsteilen, Quartieren und Mietkategorien\n",
    "Zum Abgleich der ermittelten Wohnlagen mit bestehenden Strukturen werden die Cluster mit den Quartieren und Ortsteilen der Adressen sowie den Mietkategorien (sofern vorhanden) verglichen. In der Kreuztabelle k√∂nnen die Verteilungen der Cluster √ºber die verschiedenen r√§umlichen Einheiten analysiert werden."
   ],
   "id": "b6194bac21991433"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Kreuztabelle zu Quartieren\n",
    "ct = pd.crosstab(gdf[\"quartier\"], gdf[\"cluster_skater\"], normalize=\"index\")\n",
    "plt.figure(figsize=(14,10))\n",
    "sns.heatmap(ct, cmap=\"viridis\", annot=False)\n",
    "plt.title(\"Quartier vs. SKATER-Cluster (Zeilen normalize: Anteil pro Quartier)\")\n",
    "plt.xlabel(\"SKATER-Cluster\")\n",
    "plt.ylabel(\"Quartier\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "c1c20c5935a39a9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Die Darstellung zeigt, wie sich die automatisch gebildeten SKATER-Cluster auf die bestehenden Wohnquartiere verteilen. Deutlich wird, dass mehrere Quartiere eine klare Dominanz einzelner Cluster aufweisen (z. B. Zentrum, Nord, G√∂rden oder Hohenst√ºcken), was auf eine vergleichsweise homogene interne Struktur schlie√üen l√§sst. Andere Quartiere, insbesondere jene mit gemischten Nutzungen oder gro√üen r√§umlichen Ausdehnungen, verteilen sich st√§rker auf mehrere Cluster. Diese Heterogenit√§t ist erwartbar und spiegelt eher die interne Vielfalt der Quartiere wider als Schw√§chen im Clustering. Insgesamt zeigt die Heatmap, dass die Clusterbildung bestehende r√§umliche Zusammenh√§nge gut trifft.",
   "id": "c598f2340d709d0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Kreuztabelle zu Ortsteilen\n",
    "ct = pd.crosstab(gdf[\"ortsteil\"], gdf[\"cluster_skater\"], normalize=\"index\")\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(ct, cmap=\"magma\", annot=False)\n",
    "plt.title(\"Ortsteil vs. SKATER-Cluster\")\n",
    "plt.xlabel(\"SKATER-Cluster\")\n",
    "plt.ylabel(\"Ortsteil\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "4a6e1ed31d9df962",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Die Zuordnung der SKATER-Cluster zu den Ortsteilen zeigt √ºberwiegend klare Muster. Viele Ortsteile werden √ºberwiegend einem oder zwei Clustern zugeordnet, was auf eine konsistente und funktional nachvollziehbare Lagecharakteristik schlie√üen l√§sst. Dies ist besonders bei peripheren oder d√∂rflichen Ortsteilen sichtbar, die sich typischerweise durch √§hnliche Infrastrukturausstattung und Distanzlagen auszeichnen. Gleichzeitig treten - abh√§ngig von Gr√∂√üe und Struktur des Ortsteils ‚Äì einzelne Streuungen auf, die auf interne Unterschiede oder √úbergangsbereiche hindeuten k√∂nnen. Insgesamt best√§tigt die Darstellung, dass die Cluster auch au√üerhalb des Kernstadtgebiets sinnvolle, zusammenh√§ngende Lagemuster abbilden.",
   "id": "1e25aeb4bf491452"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ct = pd.crosstab(gdf[\"mietkategorie\"], gdf[\"cluster_skater\"], normalize=\"columns\")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(ct, cmap=\"coolwarm\", annot=True, fmt=\".2f\")\n",
    "plt.title(\"Mietkategorie vs. SKATER-Cluster (Spalten normalize)\")\n",
    "plt.xlabel(\"SKATER-Cluster\")\n",
    "plt.ylabel(\"Mietkategorie\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "895529dbe50c2b6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Die Kreuztabelle zwischen Mietkategorien und SKATER-Clustern dient der √∂konomischen Validierung des Modells. Hier zeigt sich, dass bestimmte Cluster deutlich mit niedrigeren, mittleren oder h√∂heren Mietkategorien assoziiert sind. Mehrere Cluster weisen eine hohe √úbereinstimmung mit spezifischen Mietniveaus auf, was darauf hinweist, dass die algorithmisch erkannten Lagegruppen auch sozio√∂konomische Unterschiede in der Wohnlagequalit√§t widerspiegeln. Streuungen in einzelnen Kategorien sind zu erwarten und spiegeln nat√ºrliche √úberg√§nge oder heterogene Stra√üenz√ºge wider. Insgesamt deutet die Struktur jedoch auf eine plausibel differenzierende Wirkung der Cluster hin.",
   "id": "2f060d1b7ee1eac5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Alle relevanten Z-Variablen f√ºr die Clusterinterpretation\n",
    "z_vars = [col for col in gdf.columns if col.startswith(\"z_\")]\n",
    "\n",
    "cluster_profile = gdf.groupby(\"cluster_skater\")[z_vars].mean()\n",
    "\n",
    "plt.figure(figsize=(18,10))\n",
    "sns.heatmap(cluster_profile, cmap=\"coolwarm\", center=0, annot=False)\n",
    "plt.title(\"Feature-Profil der SKATER-Cluster (alle Z-Scores)\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Cluster\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "afa697c7c36a17d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Export-Pipeline",
   "id": "d630ac1d11f4b4f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save GeoDataFrame with scores and clusters as CSV\n",
    "import os\n",
    "\n",
    "# -------------------------------------------\n",
    "# 0) EXPORT-PFAD\n",
    "# -------------------------------------------\n",
    "EXPORT_PATH = \"out\"\n",
    "EXPORT_FILE = os.path.join(EXPORT_PATH, \"wohnlagen_brb.gpkg\")\n",
    "\n",
    "# Ordner anlegen\n",
    "os.makedirs(EXPORT_PATH, exist_ok=True)\n",
    "\n",
    "# Falls alte Datei existiert: l√∂schen (sonst doppelte Layer)\n",
    "if os.path.exists(EXPORT_FILE):\n",
    "    os.remove(EXPORT_FILE)\n",
    "    print(f\"Alte Datei gel√∂scht: {EXPORT_FILE}\")\n",
    "\n",
    "# -------------------------------------------\n",
    "# 1) HILFSFUNKTION: Sicheres Schreiben\n",
    "# -------------------------------------------\n",
    "\n",
    "def write_layer(gdf, layer_name, crs=EPSG_4326):\n",
    "    \"\"\"\n",
    "    Schreibt einen GeoDataFrame als Layer in die GeoPackage-Datei.\n",
    "    Stellt sicher, dass das CRS korrekt ist.\n",
    "    \"\"\"\n",
    "    if gdf is None or len(gdf) == 0:\n",
    "        print(f\"‚ö† Layer '{layer_name}' √ºbersprungen: leer oder None\")\n",
    "        return\n",
    "\n",
    "    # CRS pr√ºfen\n",
    "    if gdf.crs is None:\n",
    "        print(f\"‚ö† GDF '{layer_name}' hat kein CRS ‚Äì setze auf {crs}\")\n",
    "        gdf = gdf.set_crs(crs)\n",
    "    elif gdf.crs.to_string() != crs:\n",
    "        print(f\"üîÑ Reprojiziere '{layer_name}' nach {crs}\")\n",
    "        gdf = gdf.to_crs(crs)\n",
    "\n",
    "    # Schreiben\n",
    "    gdf.to_file(EXPORT_FILE, layer=layer_name, driver=\"GPKG\")\n",
    "    print(f\"‚úî Exportiert: {layer_name}  ‚Üí  {EXPORT_FILE}\")\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# 2) LAYER DEFINIEREN\n",
    "# -------------------------------------------\n",
    "layers = {\n",
    "    \"wohnadressen\": gdf,\n",
    "    \"wohnlagen_score\": gdf[[col for col in gdf.columns if col.startswith(\"score_\") or col in [\"geometry\"]]],\n",
    "    \"cluster_skater\": gdf[[\"cluster_skater\", \"geometry\"]] if \"cluster_skater\" in gdf.columns else None,\n",
    "    \"cluster_kmeans\": gdf[[\"cluster\", \"geometry\"]] if \"cluster\" in gdf.columns else None,\n",
    "    \"lageklassen\": gdf[[\"lageklasse\", \"score_total\", \"geometry\"]] if \"lageklasse\" in gdf.columns else None,\n",
    "\n",
    "    # Infrastruktur-Daten\n",
    "    \"bahnlinien\": rails,\n",
    "    \"gruenflaechen\": gdf_gruen_shape,\n",
    "    #\"laerm_lden\": gdf_laerm,                      # falls du gdf_laerm hei√üt\n",
    "    \"haltestellen\": gdf_haltestellen if 'gdf_haltestellen' in globals() else None,\n",
    "    #\"medzentren\": gdf_medzentren if 'gdf_medzentren' in globals() else None,\n",
    "    \"kitas\": gdf_kitas if 'gdf_kitas' in globals() else None,\n",
    "    \"grundschulen\": gdf_grundschulen if 'gdf_grundschulen' in globals() else None,\n",
    "    #\"einzelhandel\": gdf_einzelhandel if 'gdf_einzelhandel' in globals() else None,\n",
    "\n",
    "    # Debug-Daten\n",
    "    \"bahnschnitt_debug\": gdf[[\"behind_rail_from_center\", \"center_route\", \"geometry\"]] if \"behind_rail_from_center\" in gdf.columns else None,\n",
    "}\n",
    "\n",
    "# -------------------------------------------\n",
    "# 3) EXPORT AUSF√úHREN\n",
    "# -------------------------------------------\n",
    "\n",
    "print(\"üîÅ Exportiere alle Layer ‚Ä¶\\n\")\n",
    "\n",
    "for layer_name, layer_gdf in layers.items():\n",
    "    write_layer(layer_gdf, layer_name)\n",
    "\n",
    "print(\"\\nüéâ Fertig! Die GeoPackage-Datei liegt hier:\")\n",
    "print(f\"üì¶ {EXPORT_FILE}\")\n"
   ],
   "id": "4856ef3797db369e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WohnlagenBRB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

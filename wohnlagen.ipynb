{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e58eeaf9ab328ebb",
   "metadata": {},
   "source": [
    "# Datenvorbereitung\n",
    "Zunächst werden für alle gewünschten Einflussfaktoren die Daten beschafft und in ein CSV-Format mit lat/lon oder GeoJSON-Geoemtry gebracht, sodass zu allen Adressen die gewünschten Eigenschaften vorliegen."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from shapely.geometry import box\n",
    "\n",
    "from helper import load_geocsv, s\n",
    "\n",
    "EPSG_4326 = \"EPSG:4326\"\n",
    "\n",
    "# BBOX für Brandenburg an der Havel\n",
    "CITY_BOUNDING_BOX = box(12.3120236786, 52.2938432979, 12.7562682548, 52.5594777244)\n",
    "\n",
    "#  Stadtzentrum für Brandenburg an der Havel\n",
    "CITY_CENTER = (52.4116351153561, 12.556331280534392)"
   ],
   "id": "c50d60922d6f74cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Adressen einlesen\n",
    "Alle Adressen des Zielgebiets als CSV in einen GeoDataFrame einlesen."
   ],
   "id": "5112fadb5098e98"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "gdf = load_geocsv(\"out/adressen_mit_zentrum_routen.csv\")",
   "id": "ef79a64303652c4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Ortsteile der Stadt visualisieren und im Datensatz ergänzen",
   "id": "1a4012c65bb00510"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "\n",
    "# Datei laden\n",
    "with open(\"data/ortsteile_brandenburg.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "# FeatureCollection extrahieren\n",
    "features = raw[\"features\"]\n",
    "gdf_ortsteile = gpd.GeoDataFrame.from_features(features)\n",
    "gdf_ortsteile.set_crs(EPSG_4326, inplace=True)\n",
    "gdf_ortsteile = gdf_ortsteile.clip(CITY_BOUNDING_BOX)\n",
    "\n",
    "# Karte zentrieren\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=12, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Tooltip konfigurieren\n",
    "tooltip_fields = [\"otl_name\"]\n",
    "tooltip = folium.GeoJsonTooltip(\n",
    "    fields=tooltip_fields,\n",
    "    aliases=[\"Ortsteil\"],\n",
    "    localize=True,\n",
    "    sticky=True\n",
    ")\n",
    "\n",
    "# GeoJSON mit Tooltip zur Karte hinzufügen\n",
    "folium.GeoJson(\n",
    "    gdf_ortsteile,\n",
    "    name=\"Ortsteile\",\n",
    "    tooltip=tooltip\n",
    ").add_to(m)\n",
    "\n",
    "assert gdf.crs.to_epsg() == 4326\n",
    "assert gdf_ortsteile.crs.to_epsg() == 4326\n",
    "\n",
    "gdf = gpd.sjoin(gdf, gdf_ortsteile[[\"geometry\", \"otl_name\"]], how=\"left\", predicate=\"within\")\n",
    "gdf = gdf.rename(columns={\"otl_name\": \"ortsteil\"})\n",
    "gdf = gdf.drop(columns=[\"index_right\"], errors=\"ignore\")\n",
    "\n",
    "# Drop rows with NaN lat/lon\n",
    "gdf = gdf.dropna(subset=[\"lat\"])\n",
    "\n",
    "# Mögliche Erweiterung: Ergänzung einer Spalte \"stadtteil\" für spätere Validierung und auch Visualisierung\n",
    "# Adressen im Zentrum haben korrekterweise keinen Ortsteil\n",
    "\n",
    "# Karte anzeigen\n",
    "m\n"
   ],
   "id": "92288a7317c72d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Explorative Datenanalyse",
   "id": "d082da0d61c0f1d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns           # nur für schönere Plots\n",
    "from helper import load_geocsv, make_merge_addr\n",
    "\n",
    "# Eindeutigen Merge-baren String aus Adresse erzeugen\n",
    "gdf[\"Adresse_merge\"] = gdf.apply(make_merge_addr, axis=1)\n",
    "\n",
    "gdf = gdf.rename(columns={\"geojson\": \"center_route\",\n",
    "                                    \"distance_m\" : \"center_distance_m\"})\n",
    "\n",
    "# Relevante Spalten auswählen\n",
    "gdf = gdf[[\"Straßenname\", \"Hsnr\", \"HsnrZus\",\n",
    "         \"center_distance_m\", \"lat\", \"lon\", \"geometry\", \"Adresse_merge\", \"ortsteil\", \"center_route\"]]\n",
    "\n",
    "# Histogramm der Distanzen zum Zentrum\n",
    "plt.figure(figsize=(6,3))\n",
    "sns.histplot(gdf[\"center_distance_m\"], bins=60, kde=False)\n",
    "plt.title(\"Verteilung der Fußentfernung zum Zentrum\")\n",
    "plt.xlabel(\"Distanz (Meter)\")\n",
    "plt.ylabel(\"Häufigkeit\")\n",
    "plt.show()\n",
    "print(gdf.shape)\n",
    "print(gdf.columns)"
   ],
   "id": "de62fa81b281925b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Daten bereinigen",
   "id": "f14dc6214657a08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(gdf.shape)\n",
    "# Dubletten aus Adressen entfernen\n",
    "dups = gdf[\"Adresse_merge\"].value_counts()\n",
    "dups = dups[dups > 1]\n",
    "print(f\"{len(dups)} doppelte Adressen gefunden\")\n",
    "print(dups.head())\n",
    "\n",
    "# Ersten Treffer behalten\n",
    "gdf = gdf.sort_values(\"Adresse_merge\").drop_duplicates(\"Adresse_merge\", keep=\"first\")\n",
    "print(gdf.shape)\n"
   ],
   "id": "af2201946c11980d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Einzelhandel\n",
    "Separates Skript ```einzelhandel-adressen.py``` ausfühen, um Datei \"adressen_mit_einzelhandel.csv\" zu erzeugen.\n",
    "Durch fußläufiges Routing berechnete Faktoren:\n",
    "- Anzahl von Einkaufsmöglichkeiten im Umkreis von 500 m\n",
    "- Anzahl von Einkaufsmöglichkeiten im Umkreis von 800 m\n",
    "- Geringste Distanz zum nächsten Einzelhandel"
   ],
   "id": "fb6d05a628d926b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns, matplotlib.pyplot as plt\n",
    "\n",
    "# Lade vorberechnete Einzelhandel-Faktoren\n",
    "gdf_retail = load_geocsv(\"out/adressen_mit_einzelhandel_routen.csv\")\n",
    "\n",
    "# Merge mit Haupt-GDF\n",
    "gdf_retail[\"Adresse_merge\"] = gdf_retail.apply(make_merge_addr, axis=1)\n",
    "gdf_retail = gdf_retail.sort_values(\"Adresse_merge\").drop_duplicates(\"Adresse_merge\", keep=\"first\")\n",
    "\n",
    "dups = gdf_retail[\"Adresse_merge\"].value_counts()\n",
    "print(dups[dups > 1])\n",
    "\n",
    "einzelhandel_attribute = [\"einzelhandel_route\",\"einzelhandel_min_distance_m\", \"einzelhandel_500m_count\", \"einzelhandel_800m_count\", \"einzelhandel_1000m_count\"]\n",
    "\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_retail[[\"Adresse_merge\"] + einzelhandel_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "print(gdf.shape)\n",
    "print(gdf[[\"Adresse_merge\", \"einzelhandel_min_distance_m\"]].head())\n",
    "\n",
    "print(gdf.shape)\n",
    "\n",
    "# Speicher freigeben\n",
    "del(gdf_retail)"
   ],
   "id": "14c882fa9c070677",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Verteilung Distanz zum nächsten Markt\n",
    "print(gdf.columns)\n",
    "sns.histplot(gdf[\"einzelhandel_min_distance_m\"].dropna(), bins=40, kde=False)\n",
    "plt.title(\"Distanz zum nächsten Lebensmittel­markt\")\n",
    "plt.xlabel(\"Meter Fußweg\"); plt.ylabel(\"Adressen\")\n",
    "plt.show()\n",
    "\n",
    "# Scatter Zentralität vs. Nahversorgung\n",
    "sns.scatterplot(x=\"center_distance_m\", y=\"einzelhandel_min_distance_m\", data=gdf, alpha=.3)\n",
    "plt.xlabel(\"Distanz Zentrum (m)\"); plt.ylabel(\"Distanz nächster Markt (m)\")\n",
    "plt.show()"
   ],
   "id": "2425ee38a7ebf529",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Lärmbelastung\n",
    "Siehe ```laerm.ipynb``` zur Erzeugung, ansonsten einfach ```data/adressen_mit_laerm.csv``` verwenden und per Spalte 'geometry' verschneiden.\n",
    "\n",
    "Definition Lärm-Index:\n",
    "- NaN / leer: kein gemessener Straßenlärm\n",
    "- 0: 55 - 59 dB\n",
    "- 1: 60 - 64 dB\n",
    "- 2: 65 - 69 dB\n",
    "- 3: 70 - 74 dB\n",
    "- 4: >= 75 db"
   ],
   "id": "d0c2655c478327a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gdf_laerm_karte = load_geocsv(\"out/adressen_mit_laerm.csv\")\n",
    "print(gdf_laerm_karte.shape)\n",
    "print(gdf.shape)\n",
    "\n",
    "# Merge des Lärmindex mit Haupt-GDF\n",
    "gdf_laerm_karte[\"Adresse_merge\"] = gdf_laerm_karte.apply(make_merge_addr, axis=1)\n",
    "gdf_laerm_karte[\"laerm_index_tag\"] = gdf_laerm_karte[\"Laerm_index_tag\"].fillna(-0.1) # lowercase\n",
    "\n",
    "# Deduplicate, im Zweifel nimm den lautesten Wert\n",
    "gdf_laerm_karte = (\n",
    "    gdf_laerm_karte\n",
    "    .sort_values(\"laerm_index_tag\", ascending=False)\n",
    "    .drop_duplicates(\"Adresse_merge\", keep=\"first\")\n",
    ")\n",
    "\n",
    "laerm_attribute = [\"laerm_index_tag\"]\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_laerm_karte[[\"Adresse_merge\"] + laerm_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "\n",
    "#print(gdf.columns)\n",
    "print(gdf.shape)"
   ],
   "id": "f991ebcdf50656b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Bildung\n",
    "Weitere Faktoren\n",
    "- Fußläufige Entfernung zur nächstgelegenen Kita\n",
    "- Fußläufige Entfernung zur nächstgelegenen Schule\n",
    "- Anzahl Kitas im Umkreis von 500, 800 und 1000 Metern\n",
    "- Anzahl Schulen im Umkreis von 500, 800 und 1000 Metern"
   ],
   "id": "87cef8c157d06d58"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Daten als GeoDataFrame einlesen\n",
    "gdf_kitas = load_geocsv(\"out/adressen_mit_kitas_routen.csv\")\n",
    "gdf_grundschulen = load_geocsv(\"out/adressen_mit_grundschulen_routen.csv\")\n",
    "print(gdf_kitas.shape)\n",
    "print(gdf_grundschulen.shape)\n",
    "print(gdf.shape)\n",
    "\n",
    "# Eindeutige Adresse für den Merge generieren\n",
    "gdf_kitas[\"Adresse_merge\"] = gdf_kitas.apply(make_merge_addr, axis=1)\n",
    "gdf_kitas = gdf_kitas.drop_duplicates(\"Adresse_merge\")\n",
    "gdf_grundschulen[\"Adresse_merge\"] = gdf_grundschulen.apply(make_merge_addr, axis=1)\n",
    "gdf_grundschulen = gdf_grundschulen.drop_duplicates(\"Adresse_merge\")\n",
    "\n",
    "# Rename kitas_geometry column to kitas_route in gfd_kitas\n",
    "\n",
    "\n",
    "# Merge into main gdf\n",
    "kitas_attribute = [\"kitas_min_distance_m\", \"kitas_route\", \"kitas_count_within_500m\", \"kitas_count_within_800m\", \"kitas_count_within_1000m\"]\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_kitas[[\"Adresse_merge\"] + kitas_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "\n",
    "grundschulen_attribute = [\"grundschulen_min_distance_m\", \"grundschulen_route\", \"grundschulen_count_within_500m\", \"grundschulen_count_within_800m\", \"grundschulen_count_within_1000m\"]\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_grundschulen[[\"Adresse_merge\"] + grundschulen_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "del(gdf_kitas, gdf_grundschulen)  # Speicher freigeben\n",
    "\n",
    "print(gdf.columns)\n",
    "print(gdf.shape)"
   ],
   "id": "f3a118199fb1be23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Medizinische Versorgung\n",
    "Ein \"medizinisches Zentrum\" wurde definiert als eine Apotheke mit zwei Ärzten im Umkreis von 100 Metern. Diese Zentren werden separat in ```medizinische-zentren.py``` berechnet. Dazu wird die euklidische Distanz (\"Luftlinie\") zwischen Apotheken und umgebenden Ärzten berechnet.\n",
    "Dadurch entstehen für den Datensatz folgende neue Attribute:\n",
    "- Anzahl von medizinischen Zentren im Umkreis von 500 m\n",
    "- Anzahl von medizinischen Zentren im Umkreis von 800 m\n",
    "- Anzahl von medizinischen Zentren im Umkreis von 1000 m\n",
    "- Fußläufige Distanz zum nächsten medizinischen Zentrum\n",
    "\n",
    "Die vollständige Erklärung der Felder findet sich im Anhang.\n",
    "\n",
    "Die fußläufige Distanz zum nächstgelegenen medizinischen Zentrum wird per ```routing.py``` für jede Adresse einzeln ermittelt und als Weg gespeichert (```adressen_mit_medzentren_routen```)."
   ],
   "id": "a8b3a7b9ddd38f8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "# Zentren / Apothekenstandorte mit Klassifikation\n",
    "df_centers = pd.read_csv(\"out/medzentren_geocoded.csv\")\n",
    "\n",
    "# Normiere Bool-Spalte\n",
    "df_centers[\"is_med_center\"] = (df_centers[\"is_med_center\"].astype(str).str.lower().isin([\"true\", \"1\", \"yes\", \"y\"]))\n",
    "\n",
    "# Einzel-Apotheken ausblenden?\n",
    "# df_centers = df_centers[df_centers[\"is_med_center\"] == True].copy()\n",
    "\n",
    "def build_popup(row):\n",
    "    lines = []\n",
    "\n",
    "    if bool(row[\"is_med_center\"]):\n",
    "        lines.append(f\"<b>Medizinisches Zentrum \\\"{str(row['Strassenname'])}\\\"</b><br>\")\n",
    "\n",
    "    # Name\n",
    "    if pd.notna(row.get(\"Name_Apotheke\")) and str(row[\"Name_Apotheke\"]).strip() != \"\":\n",
    "        lines.append(str(row[\"Name_Apotheke\"]))\n",
    "\n",
    "    # Ärztedichte im 100m Radius\n",
    "    if \"arzt_count_100m\" in row:\n",
    "        lines.append(f\"<br><b>{int(row['arzt_count_100m'])}</b> Arzt-Praxen\")\n",
    "\n",
    "    return \"<br>\".join(lines)\n",
    "\n",
    "def pick_icon(row):\n",
    "    if bool(row[\"is_med_center\"]):\n",
    "        return folium.Icon(color=\"green\", icon=\"plus-sign\", prefix=\"glyphicon\")\n",
    "    else:\n",
    "        return folium.Icon(color=\"gray\", icon=\"staff-snake\", prefix=\"fa\")\n",
    "\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=14)\n",
    "cluster = MarkerCluster(name=\"Medizinische Zentren / Apotheken\")\n",
    "cluster.add_to(m)\n",
    "\n",
    "# Marker setzen\n",
    "for _, row in df_centers.iterrows():\n",
    "    lat = row[\"lat\"]\n",
    "    lon = row[\"lon\"]\n",
    "\n",
    "    if pd.isna(lat) or pd.isna(lon):\n",
    "        continue\n",
    "\n",
    "    popup_html = build_popup(row)\n",
    "    icon = pick_icon(row)\n",
    "\n",
    "    folium.Marker(\n",
    "        location=[lat, lon],\n",
    "        popup=popup_html,\n",
    "        tooltip=row.get(\"Strassenname\", \"Apotheke\"),\n",
    "        icon=icon,\n",
    "    ).add_to(cluster)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "m"
   ],
   "id": "a4533f83433b8618",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Medizinische Felder in gdf übernehmen\n",
    "# 1. Routing-Ergebnis für medizinische Versorgung laden\n",
    "gdf_med = load_geocsv(\"out/adressen_mit_medzentren_routen.csv\")\n",
    "print(\"gdf_med shape:\", gdf_med.shape)\n",
    "print(\"gdf shape (vor Merge):\", gdf.shape)\n",
    "\n",
    "# 2. Merge-Key bauen (Adresse normalisieren)\n",
    "gdf_med[\"Adresse_merge\"] = gdf_med.apply(make_merge_addr, axis=1)\n",
    "gdf_med = gdf_med.drop_duplicates(\"Adresse_merge\")\n",
    "\n",
    "# 3. Relevante Attributspalten aus der medizinischen Versorgung definieren\n",
    "medzentren_attribute = [\n",
    "    \"medzentren_min_distance_m\",\n",
    "    \"medzentren_route\",\n",
    "    \"medzentren_count_within_500m\",\n",
    "    \"medzentren_count_within_800m\",\n",
    "    \"medzentren_count_within_1000m\",\n",
    "]\n",
    "\n",
    "# 4. Merge in Haupt-GDF\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_med[[\"Adresse_merge\"] + medzentren_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_one\",\n",
    ")\n",
    "\n",
    "print(\"gdf shape (nach Merge):\", gdf.shape)"
   ],
   "id": "2e57b491ca5f7e24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ÖPNV-Qualität\n",
    "\n",
    "Die Qualität des ÖPNV wird anhand der Fußläufigkeit zur nächsten Haltestelle und der Häufigkeit von Abfahrten (Headway) bewertet. Die Daten stammen vom Verkehrsverbund Berlin-Brandenburg (VBB), Lizenz: CC BY 4.0, [zu den Daten](https://unternehmen.vbb.de/digitale-services/datensaetze).\n",
    "\n",
    "Vorausgesetzte Datensätze:\n",
    "- ```data/GTFS/stops.txt```, der die Haltestellen mit ihren Geokoordinaten enthält.\n",
    "- ```data/adressen_mit_haltestellen_routen.csv```, der die Routen zu den Haltestellen und Anzahl von Haltestellen im Radius 500m und 800m enthält.\n",
    "\n",
    "Probleme mit Datenqualität:\n",
    "- In der \"2024_Haltestellen.csv\" fehlen die Haltestellen \"Libellenweg\" und \"Immenweg\" (Linie B). Dadurch werden diese Haltestellen nicht berücksichtigt und Wege zur nächsten Haltestelle werden länger eingeschätzt."
   ],
   "id": "97d042d0ef303f6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from shapely.geometry import Point      # this is needed!\n",
    "\n",
    "# Load GTFS stops data\n",
    "stops = pd.read_csv(\"data/GTFS/stops.txt\")\n",
    "stops[\"geometry\"] = stops.apply(lambda row: Point(row[\"stop_lon\"], row[\"stop_lat\"]), axis=1)\n",
    "gdf_stops = gpd.GeoDataFrame(stops, geometry=\"geometry\", crs=EPSG_4326)\n",
    "\n",
    "# Convert to UTM for precise metric distance calculations\n",
    "gdf = gdf.to_crs(epsg=32633)\n",
    "gdf_stops = gdf_stops.to_crs(epsg=32633)\n",
    "\n",
    "# Assign nearest stop to each address based on Point(X, Y) geometry\n",
    "gdf[\"nearest_stop_id\"] = gdf.geometry.apply(\n",
    "    lambda pt: gdf_stops.loc[gdf_stops.distance(pt).idxmin(), \"stop_id\"]\n",
    ")\n",
    "\n",
    "# Read routes from adresses to stops and stop count from prepared CSV\n",
    "gdf_haltestellen = load_geocsv(\"out/adressen_mit_haltestellen_routen.csv\")\n",
    "gdf_haltestellen[\"Adresse_merge\"] = gdf_haltestellen.apply(make_merge_addr, axis=1)\n",
    "gdf_haltestellen = gdf_haltestellen.drop_duplicates(\"Adresse_merge\").copy()\n",
    "\n",
    "print(\"gdf_haltestellen shape:\", gdf_haltestellen.shape)\n",
    "print(\"gdf shape (vor Merge):\", gdf.shape)\n",
    "\n",
    "# Merge haltestellen attributes into main GeoDataFrame\n",
    "haltestellen_attribute = [\"haltestellen_route\", \"haltestellen_min_distance_m\", \"haltestellen_count_within_500m\", \"haltestellen_count_within_800m\"]\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_haltestellen[[\"Adresse_merge\"] + haltestellen_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_one\"\n",
    ")\n",
    "\n",
    "print(\"gdf shape (nach Merge):\", gdf.shape)\n",
    "\n",
    "# Speicher freigeben\n",
    "del gdf_haltestellen"
   ],
   "id": "b032c3c18de695a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Berechnung der ÖPNV-Taktung",
   "id": "9b1c9bc9b0c3c80d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. GTFS laden\n",
    "# -------------------------------------------------\n",
    "stops = pd.read_csv(\"data/GTFS/stops.txt\")\n",
    "stop_times = pd.read_csv(\"data/GTFS/stop_times.txt\", low_memory=False)\n",
    "trips = pd.read_csv(\"data/GTFS/trips.txt\")\n",
    "calendar = pd.read_csv(\"data/GTFS/calendar.txt\")  # behalten wir für evtl. spätere Filter\n",
    "# optional:\n",
    "# calendar_dates = pd.read_csv(\"data/GTFS/calendar_dates.txt\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Zeitspalte -> Minuten ab Mitternacht\n",
    "# -------------------------------------------------\n",
    "def parse_time_to_minutes(t):\n",
    "    if pd.isna(t):\n",
    "        return None\n",
    "    parts = str(t).split(\":\")\n",
    "    if len(parts) == 2:\n",
    "        h, m = parts\n",
    "    elif len(parts) == 3:\n",
    "        h, m, _s = parts\n",
    "    else:\n",
    "        return None\n",
    "    try:\n",
    "        h = int(h)\n",
    "        m = int(m)\n",
    "        return h * 60 + m\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "stop_times = stop_times.copy()\n",
    "stop_times[\"minutes\"] = stop_times[\"arrival_time\"].apply(parse_time_to_minutes)\n",
    "stop_times = stop_times.dropna(subset=[\"minutes\"])\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3. Wir interessieren uns für HVZ-Fenster\n",
    "#    Wir extrahieren NUR Stop-Zeiten, die überhaupt in diesen Fenstern liegen.\n",
    "#    Damit behalten wir reale Pendlerfahrten selbst dann,\n",
    "#    wenn calendar.monday == 0 gesagt hätte.\n",
    "# -------------------------------------------------\n",
    "\n",
    "HVZ_WINDOWS = [\n",
    "    (360, 540),   # 06:00–09:00\n",
    "    (960, 1140),  # 16:00–19:00\n",
    "]\n",
    "\n",
    "def in_any_window(mins, windows):\n",
    "    for lo, hi in windows:\n",
    "        if lo <= mins <= hi:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "stop_times_hvz = stop_times[stop_times[\"minutes\"].apply(lambda mm: in_any_window(mm, HVZ_WINDOWS))].copy()\n",
    "\n",
    "# 3. Filter nur auf werktägliche Dienste\n",
    "trips_filtered = trips.merge(calendar, on=\"service_id\")\n",
    "trips_filtered = trips_filtered[trips_filtered[\"monday\"] == 1]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4. stop_times_hvz ↔ trips (route_id etc.)\n",
    "# -------------------------------------------------\n",
    "trips[\"trip_id\"] = trips[\"trip_id\"].astype(str)\n",
    "\n",
    "stop_times_hvz[\"trip_id\"] = stop_times_hvz[\"trip_id\"].astype(str)\n",
    "\n",
    "stopdata = stop_times_hvz.merge(\n",
    "    trips[[\"trip_id\", \"route_id\", \"service_id\"]],\n",
    "    on=\"trip_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 5. Haltestellengeometrie + Clusterbildung (DBSCAN)\n",
    "# -------------------------------------------------\n",
    "stops = stops.copy()\n",
    "stops[\"stop_id\"] = stops[\"stop_id\"].astype(str)\n",
    "\n",
    "gdf_stops_all = gpd.GeoDataFrame(\n",
    "    stops,\n",
    "    geometry=gpd.points_from_xy(stops[\"stop_lon\"], stops[\"stop_lat\"]),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "gdf_stops_metric = gdf_stops_all.to_crs(epsg=25833).copy()\n",
    "coords = np.vstack([\n",
    "    gdf_stops_metric.geometry.x.values,\n",
    "    gdf_stops_metric.geometry.y.values\n",
    "]).T\n",
    "\n",
    "db = DBSCAN(eps=100, min_samples=1).fit(coords)\n",
    "gdf_stops_all[\"pt_cluster_id\"] = db.labels_.astype(int)\n",
    "\n",
    "stop_to_cluster = dict(zip(gdf_stops_all[\"stop_id\"], gdf_stops_all[\"pt_cluster_id\"]))\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 6. Cluster-ID an stopdata hängen\n",
    "# -------------------------------------------------\n",
    "stopdata[\"stop_id\"] = stopdata[\"stop_id\"].astype(str)\n",
    "stopdata[\"pt_cluster_id\"] = stopdata[\"stop_id\"].map(stop_to_cluster)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 7. Headway je Cluster berechnen\n",
    "#    jetzt auf Basis ALLER HVZ-Fahrten, die tatsächlich vorkommen,\n",
    "#    statt nur calendar.monday==1\n",
    "# -------------------------------------------------\n",
    "def compute_headway_for_window(df, lo, hi, group_col=\"pt_cluster_id\", time_col=\"minutes\"):\n",
    "    result = {}\n",
    "    for clus, group in df.groupby(group_col):\n",
    "        if pd.isna(clus):\n",
    "            continue\n",
    "        # nur Zeiten im Fenster\n",
    "        times = sorted([t for t in group[time_col] if lo <= t <= hi])\n",
    "        if len(times) < 2:\n",
    "            continue\n",
    "        diffs = [b - a for a, b in zip(times, times[1:])]\n",
    "        result[clus] = sum(diffs) / len(diffs)\n",
    "    return result\n",
    "\n",
    "headway_morning = compute_headway_for_window(stopdata, 360, 540)\n",
    "headway_evening = compute_headway_for_window(stopdata, 960, 1140)\n",
    "\n",
    "df_hm = (\n",
    "    pd.DataFrame.from_dict(headway_morning, orient=\"index\", columns=[\"headway_morning\"])\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"pt_cluster_id\"})\n",
    ")\n",
    "df_he = (\n",
    "    pd.DataFrame.from_dict(headway_evening, orient=\"index\", columns=[\"headway_evening\"])\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"pt_cluster_id\"})\n",
    ")\n",
    "\n",
    "df_headways = df_hm.merge(df_he, on=\"pt_cluster_id\", how=\"outer\", validate=\"one_to_one\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 8. Merge in gdf\n",
    "# -------------------------------------------------\n",
    "gdf[\"nearest_stop_id\"] = gdf[\"nearest_stop_id\"].astype(str)\n",
    "gdf[\"pt_cluster_id\"] = gdf[\"nearest_stop_id\"].map(stop_to_cluster)\n",
    "\n",
    "# weg mit alten Spalten falls rerun\n",
    "for col in [\n",
    "    \"headway_morning\", \"headway_evening\", \"headway_avg\",\n",
    "    \"headway_morning_score_fixed\", \"headway_evening_score_fixed\",\n",
    "    \"headway_avg_score_fixed\",\n",
    "]:\n",
    "    if col in gdf.columns:\n",
    "        gdf = gdf.drop(columns=[col])\n",
    "\n",
    "gdf = gdf.merge(\n",
    "    df_headways,\n",
    "    on=\"pt_cluster_id\",\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 9. Kennzahlen\n",
    "# -------------------------------------------------\n",
    "for col in [\"headway_morning\", \"headway_evening\"]:\n",
    "    gdf[col] = pd.to_numeric(gdf[col], errors=\"coerce\")\n",
    "\n",
    "gdf[\"headway_avg\"] = gdf[[\"headway_morning\", \"headway_evening\"]].mean(axis=1)\n",
    "\n",
    "fixed_min, fixed_max = 5, 60\n",
    "def scoreify(series):\n",
    "    return 1 - ((series - fixed_min) / (fixed_max - fixed_min)).clip(lower=0, upper=1)\n",
    "\n",
    "gdf[\"headway_morning_score_fixed\"] = scoreify(gdf[\"headway_morning\"])\n",
    "gdf[\"headway_evening_score_fixed\"] = scoreify(gdf[\"headway_evening\"])\n",
    "gdf[\"headway_avg_score_fixed\"]     = scoreify(gdf[\"headway_avg\"])\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 10. Debug neu\n",
    "# -------------------------------------------------\n",
    "no_headway_mask = gdf[\"headway_avg\"].isna()\n",
    "\n",
    "print(\"Adressen ohne Headway_avg:\", int(no_headway_mask.sum()))\n",
    "\n",
    "na_clusters = (\n",
    "    gdf.loc[no_headway_mask, \"pt_cluster_id\"]\n",
    "    .value_counts()\n",
    ")\n",
    "print(\"Problem-Cluster:\", len(na_clusters))\n",
    "print(na_clusters.head(20))\n",
    "\n",
    "# sicherstellen, dass wir wirklich noch Stops ohne Window-Fahrten haben\n",
    "clusters_with_headway = set(df_headways[\"pt_cluster_id\"].tolist())\n",
    "clusters_without = [cid for cid in gdf[\"pt_cluster_id\"].dropna().unique()\n",
    "                    if cid not in clusters_with_headway]\n",
    "print(\"Cluster ohne Eintrag in df_headways:\", len(clusters_without))\n",
    "print(clusters_without[:20])\n",
    "\n",
    "# Spot-check: nimm den größten Problem-Cluster\n",
    "if len(clusters_without) > 0:\n",
    "    test_cluster = clusters_without[0]\n",
    "    sample_times = stopdata.loc[stopdata[\"pt_cluster_id\"] == test_cluster, \"minutes\"]\n",
    "    print(\"Beispiel-Cluster\", test_cluster, \"HVZ Zeiten:\",\n",
    "          sorted([t for t in sample_times if 360 <= t <= 540])[:20])\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 11. Debug: Wo fehlen noch Headways?\n",
    "# -------------------------------------------------\n",
    "no_headway_mask = gdf[\"headway_avg\"].isna()\n",
    "\n",
    "print(\"Adressen ohne Headway_avg:\", int(no_headway_mask.sum()))\n",
    "\n",
    "# Welche Stop-IDs sind schuld, nach nearest_stop_id\n",
    "na_stops = (\n",
    "    gdf.loc[no_headway_mask, \"nearest_stop_id\"]\n",
    "    .value_counts()\n",
    ")\n",
    "print(\"Anzahl unterschiedlicher problematischer Haltestellen (Steig-Ebene):\", len(na_stops))\n",
    "print(na_stops.head(20))\n",
    "\n",
    "# Welche Cluster sind schuld\n",
    "na_clusters = (\n",
    "    gdf.loc[no_headway_mask, \"pt_cluster_id\"]\n",
    "    .value_counts()\n",
    ")\n",
    "print(\"Anzahl problematischer Cluster:\", len(na_clusters))\n",
    "print(na_clusters.head(20))\n",
    "\n",
    "# Prüfen, ob diese Cluster überhaupt Headways in df_headways haben\n",
    "clusters_with_headway = set(df_headways[\"pt_cluster_id\"].astype(int).tolist())\n",
    "clusters_without = [cid for cid in na_clusters.index if cid not in clusters_with_headway]\n",
    "print(\"Cluster ohne Eintrag in df_headways:\", len(clusters_without))\n",
    "print(clusters_without[:20])\n",
    "\n",
    "# Sanity check: für einen der Top-Cluster, zeig alle Abfahrtszeiten morgens\n",
    "if len(clusters_without) > 0:\n",
    "    test_cluster = clusters_without[0]\n",
    "    sample_times = stopdata.loc[stopdata[\"pt_cluster_id\"] == test_cluster, \"minutes\"]\n",
    "    print(\"Beispiel-Cluster\", test_cluster, \"hat morgens Zeiten in 6-9?:\",\n",
    "          sample_times[(sample_times>=360)&(sample_times<=540)].sort_values().head(20).tolist())\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 12. Cleanup (optional)\n",
    "# -------------------------------------------------\n",
    "#del(stop_times, trips, calendar, trips_filtered,\n",
    "#    stopdata, df_hm, df_he, df_headways,\n",
    "#    gdf_stops_metric, coords, db)\n"
   ],
   "id": "ad2f3fdb3ae58eb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ÖPMV in gdf mergen\n",
    "headway_attribute = [\"headway_avg\"]"
   ],
   "id": "a1e92bc343809d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualisierung der ÖPNV-Taktung",
   "id": "f3be44369f64d5db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "from branca.colormap import linear, LinearColormap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Convert gdf_stops geometry to WGS84\n",
    "gdf_stops = gdf_stops.to_crs(epsg=4326).copy()\n",
    "\n",
    "# Haltestellen innerhalb Stadt\n",
    "gdf_stops_clip = gdf_stops[gdf_stops.geometry.within(CITY_BOUNDING_BOX)].copy()\n",
    "print(\"Haltestellen im Stadtpolygon:\", len(gdf_stops_clip))\n",
    "\n",
    "#\n",
    "# 2. Farbskala nur aus Adressen-Headway\n",
    "#\n",
    "# headway_avg = durchschnittliche Taktzeit (Minuten) für diese Adresse\n",
    "# Annahme: kleiner Wert = besser (häufigere Bedienung)\n",
    "addr_headway = pd.to_numeric(gdf[\"headway_avg\"], errors=\"coerce\")\n",
    "\n",
    "hv_valid = addr_headway.dropna()\n",
    "if len(hv_valid) > 0:\n",
    "    vmin, vmax = hv_valid.quantile([0.01, 0.99])\n",
    "    if vmin == vmax:\n",
    "        # falls alles gleich (z. B. nur eine Linie), spreizen für die Farbskala\n",
    "        vmin = vmin - 0.1\n",
    "        vmax = vmax + 0.1\n",
    "else:\n",
    "    # Fallback, falls ALLE Adressen NaN sind\n",
    "    vmin, vmax = (0, 1)\n",
    "\n",
    "palette_normal = list(linear.RdYlGn_11.colors)\n",
    "palette_inverted = palette_normal[::-1]\n",
    "colormap = LinearColormap(\n",
    "    colors=palette_inverted,\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    ").to_step(n=9)\n",
    "colormap.caption = \"Headway pro Adresse (Minuten, kleiner = besser)\"\n",
    "\n",
    "# 3. Karte initialisieren\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"cartodbpositron\")\n",
    "\n",
    "# 4. Adressen plotten (farbig nach headway_avg)\n",
    "#    - Farbig wenn headway_avg da\n",
    "#    - Hellgrau wenn kein Wert\n",
    "for _, row in gdf.iterrows():\n",
    "    hv_addr = row.get(\"headway_avg\", np.nan)\n",
    "    hv_morning = row.get(\"headway_morning\", np.nan)\n",
    "    hv_evening = row.get(\"headway_evening\", np.nan)\n",
    "\n",
    "    if pd.isna(hv_addr):\n",
    "        # Kein Wert berechnet -> zeichne neutral\n",
    "        color = \"#BBBBBB\"\n",
    "        fill_color = \"#BBBBBB\"\n",
    "        hv_label = \"kein Wert\"\n",
    "    else:\n",
    "        color = colormap(hv_addr)\n",
    "        fill_color = colormap(hv_addr)\n",
    "        hv_label = f\"{hv_addr:.1f} min\"\n",
    "\n",
    "    # Popup mit allen Headways, falls vorhanden\n",
    "    popup_lines = [\n",
    "        f\"{row.get('Straßenname', '')} {row.get('Hsnr', '')}\",\n",
    "        f\"<b>Headway (avg):</b> {hv_label}\",\n",
    "    ]\n",
    "    if pd.notna(hv_morning):\n",
    "        popup_lines.append(f\"Frühspitze: {hv_morning:.1f} min\")\n",
    "    if pd.notna(hv_evening):\n",
    "        popup_lines.append(f\"Abendspitze: {hv_evening:.1f} min\")\n",
    "\n",
    "    popup_html = \"<br>\".join(popup_lines)\n",
    "\n",
    "    folium.CircleMarker(\n",
    "        location=[row.lat, row.lon],\n",
    "        radius=5,\n",
    "        color=color,\n",
    "        fill=True,\n",
    "        fill_color=fill_color,\n",
    "        fill_opacity=0.8,\n",
    "        weight=1,\n",
    "        popup=popup_html,\n",
    "    ).add_to(m)\n",
    "\n",
    "# 5. Haltestellen plotten (schwarz, neutral)\n",
    "#    Du zeigst hier die Infrastrukturpunkte, ohne Qualitätsfarbe.\n",
    "for _, row in gdf_stops_clip.iterrows():\n",
    "    lat_s = row[\"stop_lat\"]\n",
    "    lon_s = row[\"stop_lon\"]\n",
    "\n",
    "    # Popup Haltestellenname\n",
    "    stop_label = row.get(\"stop_name\", row.get(\"stop_id\", \"Haltestelle\"))\n",
    "\n",
    "    folium.CircleMarker(\n",
    "        location=[lat_s, lon_s],\n",
    "        radius=3,\n",
    "        color=\"black\",\n",
    "        fill=True,\n",
    "        fill_color=\"black\",\n",
    "        fill_opacity=1,\n",
    "        weight=1,\n",
    "        popup=f\"<b>Haltestelle:</b> {stop_label}<br>\",\n",
    "    ).add_to(m)\n",
    "\n",
    "# 6. Legende für die Adressen-Headways\n",
    "colormap.add_to(m)\n",
    "m\n"
   ],
   "id": "24544ac9ee9f7dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Freizeit- und Erholungsflächen\n",
    "\n",
    "- Fußläufige Distanz zur nächstgelegenen Freizeit- und Erholungsflächen (Parks, Grünanlagen)\n",
    "\n",
    "Die Freizeit- und Erholungsflächen laut Auftrag sind:\n",
    "- Marienberg\n",
    "- Humboldthain\n",
    "- Salzhofufer\n",
    "- Wallpromenade\n",
    "- Theaterpark\n",
    "- Grabenpromenade\n",
    "- Schlosspark Plaue\n",
    "- Schlosspark Gollwitz\n",
    "- Krugpark\n",
    "\n",
    "Aus den bereitgestellten Shape-Dateien werden anhand der Objektbezeichnung (Spalte \"objektbeze\") im Routing-Skript ca. 100 zusammenhängende Flächen gebildet, deren Ränder als Ziele für die fußläufige Distanzberechnung genutzt werden. Dadurch werden mehr als die angegebenen Flächen genutzt.\n",
    "\n",
    "Einschränkung der Validität: Durch die Beschränkung auf diese Flächenarten erhalten zentrumsferne Adressen trotz der Lage z. B. an Wäldern schlechtere Bewertungen."
   ],
   "id": "94649ee801aa7560"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "path = \"data/Grünflächen_Verkehrszeichen/20251029_Vegetation_KSP_GP_31.shp\"\n",
    "gdf_gruen_shape = gpd.read_file(path)\n",
    "#gdf_gruen"
   ],
   "id": "aa43fe538b4bc67a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=14)\n",
    "\n",
    "def random_color(seed):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    r = rng.integers(80, 200)\n",
    "    g = rng.integers(80, 200)\n",
    "    b = rng.integers(80, 200)\n",
    "    return f\"#{r:02x}{g:02x}{b:02x}\"\n",
    "\n",
    "# Ein Farbschema erzeugen\n",
    "unique_ids = gdf_gruen_shape[\"objektbeze\"].unique()\n",
    "color_map = {uid: random_color(i) for i, uid in enumerate(unique_ids)}\n",
    "\n",
    "# Polygone hinzufügen\n",
    "folium.GeoJson(\n",
    "    gdf_gruen_shape,\n",
    "    style_function=lambda feature: {\n",
    "        \"color\": \"black\",\n",
    "        \"weight\": 0.5,\n",
    "        \"fillOpacity\": 0.9,\n",
    "        \"fillColor\": color_map[feature[\"properties\"][\"objektbeze\"]]\n",
    "    },\n",
    "    tooltip=folium.GeoJsonTooltip(fields=[\"objektbeze\"])\n",
    ").add_to(m)\n",
    "\n",
    "m"
   ],
   "id": "2ae81272462576a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gdf_gruen_m = gdf_gruen_shape.to_crs(32633)\n",
    "\n",
    "# Gruppieren & union der Flächen\n",
    "gdf_gruen_area = (gdf_gruen_shape.dissolve(by=\"objektbeze\").reset_index())\n",
    "\n",
    "# Fläche berechnen (m²)\n",
    "gdf_gruen_area[\"flaeche_m2\"] = gdf_gruen_area.area\n",
    "gdf_gruen_area[\"flaeche_ha\"] = gdf_gruen_area[\"flaeche_m2\"] / 10_000\n",
    "\n",
    "bad = gdf_gruen_area.geometry.apply(lambda g: not g.is_valid)\n",
    "print(\"Ungültige Geometrien:\", bad.sum())\n",
    "\n",
    "bb = gdf_gruen_area.geometry.boundary\n",
    "print(\"Boundary is empty:\", sum(bb.is_empty))\n",
    "\n",
    "# Optional: Die Fläche der nächstgelegenen Anlage könnte noch als Qualitätskriterium hinzugefügt werden. Vorerst nutzen wir nur die Entfernung zu den Anlagen.\n",
    "\n",
    "del(gdf_gruen_m, gdf_gruen_area)"
   ],
   "id": "70328158908d4bc8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Lade vorberechnete Routen zur nächstgelegenen Anlage und Anzahl von Funden im Umkreis\n",
    "gdf_gruen = load_geocsv(\"out/adressen_mit_gruen_routen.csv\")\n",
    "gdf_gruen"
   ],
   "id": "aa74c34fdcf6a9a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Merge mit Haupt-GDF\n",
    "gdf_gruen[\"Adresse_merge\"] = gdf_gruen.apply(make_merge_addr, axis=1)\n",
    "gdf_gruen = gdf_gruen.sort_values(\"Adresse_merge\").drop_duplicates(\"Adresse_merge\", keep=\"first\")\n",
    "\n",
    "dups = gdf_gruen[\"Adresse_merge\"].value_counts()\n",
    "print(dups[dups > 1])\n",
    "\n",
    "gruen_attribute = [\"gruen_route\",\"gruen_min_distance_m\", \"gruen_count_within_500m\", \"gruen_count_within_800m\", \"gruen_count_within_1000m\"]\n",
    "\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_gruen[[\"Adresse_merge\"] + gruen_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "\n",
    "# Plausibiliätsprüfung\n",
    "print(gdf[[\"Adresse_merge\", \"gruen_min_distance_m\", \"gruen_route\"]].head())\n",
    "print(gdf.shape)"
   ],
   "id": "7390decad77bb1da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Begenzung durch dauerhafte Bahnlininen / Schranken\n",
    "Als zusätzlicher Indikator wird berechnet, ob eine Adresse durch eine Bahnlinie oder eine stark befahrene Straße (Autobahn, Bundesstraße) vom Stadtzentrum getrennt ist. Damit wird abgebildet, ob eine Adresse trotz Nähe zum Zentrum durch eine Barriere erschwerten Zugang hat (z. B., durch Wartezeiten an Bahnübergängen)."
   ],
   "id": "9d1da8cf2f7610c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import osmnx as ox\n",
    "\n",
    "place = \"Brandenburg an der Havel, Germany\"\n",
    "\n",
    "# Eisenbahnlinien holen\n",
    "rails = ox.geometries_from_place(\n",
    "    place,\n",
    "    tags={\"railway\": True}  # includes rail, light_rail, tram, etc.\n",
    ")\n",
    "\n",
    "# nur Schienenverkehr (keine Haltestellen)\n",
    "rails = rails[rails[\"railway\"].isin([\"rail\", \"light_rail\", \"subway\", \"tram\"])]\n",
    "rails = rails.to_crs(gdf.crs)  # CRS angleichen"
   ],
   "id": "d902584f88044dd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Visualisierung aller Indikatoren\n",
    "Alle Einflussfaktoren (Supermärkte, Ärzte, Schulen etc.) werden zur Plausibilitätsprüfung auf einer Karte visualisiert."
   ],
   "id": "1a1d9689bda3a442"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "import branca.colormap as cm\n",
    "from helper import add_markers_from_csv, STRASSENNAME, HAUSNUMMER, HAUSNUMMERZUSATZ\n",
    "\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Add layer markers\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/einzelhandel_geocoded.csv\", color=\"blue\", icon=\"shopping-cart\", layer_name=\"Einzelhandel\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/grundschulen_geocoded.csv\", color=\"green\", icon=\"graduation-cap\", layer_name=\"Grundschulen\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/kitas_geocoded.csv\", color=\"beige\", icon=\"child\", layer_name=\"Kitas\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/haltestellen_geocoded.csv\", color=\"lightgray\", icon=\"bus\", layer_name=\"Haltestellen\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/medzentren_geocoded.csv\", color=\"red\", icon=\"staff-snake\", layer_name=\"Medizinische Zentren\")\n",
    "\n",
    "# Lärmindex aus dem Geopackage\n",
    "gdf_laerm_karte = gpd.read_file(\"data/laerm.gpkg\", layer=\"laerm\")\n",
    "gdf_laerm_karte = gdf_laerm_karte.clip(CITY_BOUNDING_BOX)\n",
    "value_column = \"isov1\"\n",
    "min_val = gdf_laerm_karte[value_column].min()\n",
    "max_val = gdf_laerm_karte[value_column].max()\n",
    "colormap = cm.LinearColormap(colors=[\"green\", \"yellow\", \"red\"], vmin=min_val, vmax=max_val)\n",
    "colormap.caption = \"Lärmpegel (LDEN in dB)\"\n",
    "\n",
    "# Alle Adressen als Punkte\n",
    "adress_layer = folium.FeatureGroup(name=\"Wohnadressen\", show=False)\n",
    "for _, row in gdf.iterrows():\n",
    "    if pd.notna(row[\"lat\"]) and pd.notna(row[\"lon\"]):\n",
    "        strasse = s(row.get(STRASSENNAME))\n",
    "        hsnr = s(row.get(HAUSNUMMER))\n",
    "        hsnrzus = s(row.get(HAUSNUMMERZUSATZ))\n",
    "\n",
    "        tooltip = strasse + \" \" + hsnr\n",
    "\n",
    "        adressen_map = folium.CircleMarker(\n",
    "            location=[row[\"lat\"], row[\"lon\"]],\n",
    "            radius=3,\n",
    "            color=\"lightgray\",\n",
    "            fill=True,\n",
    "            fill_opacity=0.6,\n",
    "            tooltip=tooltip\n",
    "        ).add_to(adress_layer)\n",
    "adress_layer.add_to(m)\n",
    "\n",
    "def style_function(feature):\n",
    "    value = feature[\"properties\"][value_column]\n",
    "    return {\n",
    "        \"fillColor\": colormap(value),\n",
    "        \"color\": \"black\",\n",
    "        \"weight\": 0.3,\n",
    "        \"fillOpacity\": 0.2\n",
    "    }\n",
    "\n",
    "laerm_layer = folium.FeatureGroup(name=\"Lärmkarte (LDEN 2022)\")\n",
    "folium.GeoJson(\n",
    "    gdf_laerm_karte,\n",
    "    style_function=style_function,\n",
    ").add_to(laerm_layer)\n",
    "laerm_layer.add_to(m)\n",
    "colormap.add_to(m)\n",
    "\n",
    "# Grünflächen hinzufügen\n",
    "gruen_layer = folium.FeatureGroup(name=\"Freizeit- und Erholungsflächen\")\n",
    "folium.GeoJson(\n",
    "    gdf_gruen_shape,\n",
    "    style_function=lambda feature: {\n",
    "        \"color\": \"black\",\n",
    "        \"weight\": 0.2,\n",
    "        \"fillOpacity\": 0.9,\n",
    "        \"fillColor\": \"green\"\n",
    "    }\n",
    ").add_to(gruen_layer)\n",
    "gruen_layer.add_to(m)\n",
    "\n",
    "# Schaltbare Layer\n",
    "folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "del gdf_laerm_karte  # Speicher freigeben\n",
    "\n",
    "m\n"
   ],
   "id": "779464ac37bb84c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Scoring / Punktesystem\n",
    "Hier werden z-Werte zu alle **Einflussfaktoren** gebildet, um die Abweichung einer Ausprägung vom Standard (im betrachteten Gebiet) zu erfassen. Weiterhin werden die **Gewichte** festgelegt, mit denen die Faktoren in die Wohnlagenbewertung eingehen."
   ],
   "id": "92944c1fbc1d51d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "score_vars = ([\"center_distance_m\"] +\n",
    "              haltestellen_attribute +\n",
    "              headway_attribute +\n",
    "              einzelhandel_attribute +\n",
    "              laerm_attribute +\n",
    "              kitas_attribute +\n",
    "              grundschulen_attribute +\n",
    "              medzentren_attribute +\n",
    "              gruen_attribute\n",
    "              )\n",
    "# Nur Zeilen mit vollständigen Daten verwenden\n",
    "mask_all = gdf[score_vars].notna().all(axis=1)\n",
    "\n",
    "# Z‑Scores, fehlende Werte bleiben NaN, bei negativem Einfluss \"-\" (Minus) angeben!\n",
    "gdf.loc[mask_all, \"z_centrality\"]    = -zscore(gdf.loc[mask_all, \"center_distance_m\"])\n",
    "gdf.loc[mask_all, \"z_einzelhandel_distance\"] = -zscore(gdf.loc[mask_all, \"einzelhandel_min_distance_m\"])\n",
    "gdf.loc[mask_all, \"z_einzelhandel_near_500\"] =  zscore(gdf.loc[mask_all, \"einzelhandel_500m_count\"])\n",
    "gdf.loc[mask_all, \"z_einzelhandel_near_800\"] =  zscore(gdf.loc[mask_all, \"einzelhandel_800m_count\"])\n",
    "gdf.loc[mask_all, \"z_einzelhandel_near_1000\"] =  zscore(gdf.loc[mask_all, \"einzelhandel_1000m_count\"])\n",
    "gdf.loc[mask_all, \"z_laerm_index_tag\"] = -zscore(gdf.loc[mask_all, \"laerm_index_tag\"])\n",
    "gdf.loc[mask_all, \"z_kita_distance\"] = -zscore(gdf.loc[mask_all, \"kitas_min_distance_m\"])\n",
    "gdf.loc[mask_all, \"z_kita_near_500\"] =  zscore(gdf.loc[mask_all, \"kitas_count_within_500m\"])\n",
    "gdf.loc[mask_all, \"z_kita_near_800\"] =  zscore(gdf.loc[mask_all, \"kitas_count_within_800m\"])\n",
    "gdf.loc[mask_all, \"z_kita_near_1000\"] =  zscore(gdf.loc[mask_all, \"kitas_count_within_1000m\"])\n",
    "gdf.loc[mask_all, \"z_grundschulen_distance\"] = -zscore(gdf.loc[mask_all, \"grundschulen_min_distance_m\"])\n",
    "gdf.loc[mask_all, \"z_grundschulen_near_500\"] =  zscore(gdf.loc[mask_all, \"grundschulen_count_within_500m\"])\n",
    "gdf.loc[mask_all, \"z_grundschulen_near_800\"] =  zscore(gdf.loc[mask_all, \"grundschulen_count_within_800m\"])\n",
    "gdf.loc[mask_all, \"z_grundschulen_near_1000\"] =  zscore(gdf.loc[mask_all, \"grundschulen_count_within_1000m\"])\n",
    "gdf.loc[mask_all, \"z_haltestelle_distance\"] = -zscore(gdf.loc[mask_all, \"haltestellen_min_distance_m\"])\n",
    "gdf.loc[mask_all, \"z_headway_score\"] = -zscore(gdf.loc[mask_all, \"headway_avg\"])\n",
    "gdf.loc[mask_all, \"z_medzentrum_distance\"] = -zscore(gdf.loc[mask_all, \"medzentren_min_distance_m\"])\n",
    "gdf.loc[mask_all, \"z_medzentrum_near_500\"] =  zscore(gdf.loc[mask_all, \"medzentren_count_within_500m\"])\n",
    "gdf.loc[mask_all, \"z_medzentrum_near_800\"] =  zscore(gdf.loc[mask_all, \"medzentren_count_within_800m\"])\n",
    "gdf.loc[mask_all, \"z_medzentrum_near_1000\"] =  zscore(gdf.loc[mask_all, \"medzentren_count_within_1000m\"])\n",
    "gdf.loc[mask_all, \"z_gruen_distance\"] = -zscore(gdf.loc[mask_all, \"gruen_min_distance_m\"])\n",
    "gdf.loc[mask_all, \"z_gruen_near_500\"] =  zscore(gdf.loc[mask_all, \"gruen_count_within_500m\"])\n",
    "gdf.loc[mask_all, \"z_gruen_near_800\"] =  zscore(gdf.loc[mask_all, \"gruen_count_within_800m\"])\n",
    "gdf.loc[mask_all, \"z_gruen_near_1000\"] =  zscore(gdf.loc[mask_all, \"gruen_count_within_1000m\"])\n",
    "\n",
    "# ------------------------------\n",
    "# Zentralität (Zentrumsnähe)\n",
    "# ------------------------------\n",
    "mm_central_score_vars = [\"center_distance_m\"]\n",
    "# Score-Zusammenfassung nur bei vollständigen Daten\n",
    "mask_mm_central = gdf[mm_central_score_vars].notna().all(axis=1)\n",
    "gdf.loc[mask_mm_central, \"score_zentralitaet\"] = (\n",
    "    1 * gdf.loc[mask_mm_central, \"center_distance_m\"]\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# Versorgung (Ärzte, Apotheken, Einzelhandel)\n",
    "# ------------------------------\n",
    "mm_versorgung_score_vars = [\n",
    "    \"einzelhandel_min_distance_m\",\n",
    "    \"einzelhandel_500m_count\",\n",
    "    \"einzelhandel_800m_count\",\n",
    "    \"einzelhandel_1000m_count\",\n",
    "    \"medzentren_min_distance_m\",\n",
    "    \"medzentren_count_within_500m\",\n",
    "    \"medzentren_count_within_800m\",\n",
    "    \"medzentren_count_within_1000m\"\n",
    "]\n",
    "mask_mm_versorgung = gdf[mm_versorgung_score_vars].notna().all(axis=1)\n",
    "gdf.loc[mask_mm_versorgung, \"score_versorgung\"] = (\n",
    "    0.1 * gdf.loc[mask_mm_central, \"einzelhandel_min_distance_m\"] +\n",
    "    0.1 * gdf.loc[mask_mm_central, \"einzelhandel_500m_count\"] +\n",
    "    0.1 * gdf.loc[mask_mm_central, \"einzelhandel_800m_count\"] +\n",
    "    0.1 * gdf.loc[mask_mm_central, \"einzelhandel_1000m_count\"] +\n",
    "    0.1 * gdf.loc[mask_mm_central, \"medzentren_min_distance_m\"] +\n",
    "    0.1 * gdf.loc[mask_mm_central, \"medzentren_count_within_500m\"] +\n",
    "    0.1 * gdf.loc[mask_mm_central, \"medzentren_count_within_800m\"] +\n",
    "    0.1 * gdf.loc[mask_mm_central, \"medzentren_count_within_1000m\"]\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# Mobilität\n",
    "# ------------------------------\n",
    "mm_mobilitaet_score_vars = [\n",
    "    \"headway_avg\",\n",
    "    \"haltestellen_min_distance_m\",\n",
    "    \"haltestellen_count_within_500m\",\n",
    "    \"haltestellen_count_within_800m\"\n",
    "]\n",
    "mask_mm_mobilitaet = gdf[mm_mobilitaet_score_vars].notna().all(axis=1)\n",
    "# TODO Multiplikatoren überall auf 100 % angleichen und für interaktive Karte aufbereiten!\n",
    "gdf.loc[mask_mm_mobilitaet, \"score_mobilitaet\"] = (\n",
    "        0.4 * gdf.loc[mask_mm_mobilitaet, \"headway_avg\"] +\n",
    "        0.4 * gdf.loc[mask_mm_mobilitaet, \"haltestellen_min_distance_m\"] +\n",
    "        0.1 * gdf.loc[mask_mm_mobilitaet, \"haltestellen_count_within_500m\"] +\n",
    "        0.1 * gdf.loc[mask_mm_mobilitaet, \"haltestellen_count_within_800m\"]\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# Bildung (Kitas und Grundschulen)\n",
    "# ------------------------------\n",
    "mm_bildung_score_vars = [\n",
    "    \"kitas_min_distance_m\",\n",
    "    \"kitas_count_within_500m\",\n",
    "    \"kitas_count_within_800m\",\n",
    "    \"kitas_count_within_1000m\",\n",
    "    \"grundschulen_min_distance_m\",\n",
    "    \"grundschulen_count_within_500m\",\n",
    "    \"grundschulen_count_within_800m\",\n",
    "    \"grundschulen_count_within_1000m\"\n",
    "]\n",
    "mask_mm_kita = gdf[mm_bildung_score_vars].notna().all(axis=1)\n",
    "gdf.loc[mask_mm_kita, \"score_bildung\"] = (\n",
    "    0.1 * gdf.loc[mask_mm_kita, \"kitas_min_distance_m\"] +\n",
    "    0.1 * gdf.loc[mask_mm_kita, \"kitas_count_within_500m\"] +\n",
    "    0.1 * gdf.loc[mask_mm_kita, \"kitas_count_within_800m\"] +\n",
    "    0.1 * gdf.loc[mask_mm_kita, \"kitas_count_within_1000m\"] +\n",
    "    0.1 * gdf.loc[mask_mm_kita, \"grundschulen_min_distance_m\"] +\n",
    "    0.1 * gdf.loc[mask_mm_kita, \"grundschulen_count_within_500m\"] +\n",
    "    0.1 * gdf.loc[mask_mm_kita, \"grundschulen_count_within_800m\"] +\n",
    "    0.1 * gdf.loc[mask_mm_kita, \"grundschulen_count_within_1000m\"]\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# Umwelt (Lärm und Freizeitflächen)\n",
    "# ------------------------------\n",
    "mm_umwelt_score_vars = [\n",
    "    \"gruen_min_distance_m\",\n",
    "    \"gruen_count_within_500m\",\n",
    "    \"gruen_count_within_800m\",\n",
    "    \"gruen_count_within_1000m\",\n",
    "    \"laerm_index_tag\"\n",
    "]\n",
    "mask_mm_umwelt = gdf[mm_umwelt_score_vars].notna().all(axis=1)\n",
    "gdf.loc[mask_mm_umwelt, \"score_umwelt\"] = (\n",
    "    0.3 * gdf.loc[mask_mm_umwelt, \"gruen_min_distance_m\"] +\n",
    "    0.1 * gdf.loc[mask_mm_umwelt, \"gruen_count_within_500m\"] +\n",
    "    0.1 * gdf.loc[mask_mm_umwelt, \"gruen_count_within_800m\"] +\n",
    "    0.05 * gdf.loc[mask_mm_umwelt, \"gruen_count_within_1000m\"] +\n",
    "    0.2 * gdf.loc[mask_mm_umwelt, \"laerm_index_tag\"]\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# Gesamt-Score (falls alle Teil-Scores vorhanden)\n",
    "# ------------------------------\n",
    "score_all_vars = [\n",
    "    \"score_zentralitaet\",\n",
    "    \"score_bildung\",\n",
    "    \"score_versorgung\",\n",
    "    \"score_umwelt\",\n",
    "    \"score_mobilitaet\"\n",
    "]\n",
    "mask_all_scores = gdf[score_all_vars].notna().all(axis=1)\n",
    "\n",
    "# Skalierte Kombination\n",
    "gdf.loc[mask_all_scores, \"score_total\"] = (\n",
    "    0.2 * gdf.loc[mask_all_scores, \"score_zentralitaet\"] +\n",
    "    0.2 * gdf.loc[mask_all_scores, \"score_bildung\"] +\n",
    "    0.2 * gdf.loc[mask_all_scores, \"score_versorgung\"] +\n",
    "    0.2 * gdf.loc[mask_all_scores, \"score_umwelt\"] +\n",
    "    0.2 * gdf.loc[mask_all_scores, \"score_mobilitaet\"]\n",
    ")\n",
    "\n",
    "# Zwischenauswertung\n",
    "print(\"Anzahl gültiger Gesamt-Scores:\", gdf[\"score_total\"].notna().sum())\n",
    "print(gdf[score_all_vars].notna().sum().sort_values())\n",
    "\n",
    "all_input_vars = (mm_central_score_vars +\n",
    "                  mm_bildung_score_vars +\n",
    "                  mm_versorgung_score_vars +\n",
    "                  mm_umwelt_score_vars +\n",
    "                  mm_mobilitaet_score_vars\n",
    "                  )\n",
    "missing_counts = gdf[all_input_vars].isna().sum().sort_values(ascending=False)\n",
    "print(\"\")\n",
    "print(missing_counts)"
   ],
   "id": "36111c65c1e0e5b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Validierung\n",
    "\n",
    "Im Folgenden werden die Z-Variablen genutzt, um mittels K-Means-Clustering Wohnlagen zu identifizieren. Zunächst wird die optimale Clusteranzahl mittels Elbow-Methode und Silhouetten-Analyse bestimmt. Danach wird das finale K-Means-Modell mit der gewählten Clusteranzahl trainiert und die Wohnlagen den Adressen zugewiesen."
   ],
   "id": "38efad5274a30e01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------\n",
    "# Z-Variablen aus allen Kategorien\n",
    "# ---------------------------------------\n",
    "z_vars = [\n",
    "    # Zentralität\n",
    "    \"z_centrality\",\n",
    "\n",
    "    # Einzelhandel\n",
    "    \"z_einzelhandel_distance\",\n",
    "    \"z_einzelhandel_near_500\",\n",
    "    \"z_einzelhandel_near_800\",\n",
    "    \"z_einzelhandel_near_1000\",\n",
    "\n",
    "    # Lärm\n",
    "    \"z_laerm_index_tag\",\n",
    "\n",
    "    # Kitas\n",
    "    \"z_kita_distance\",\n",
    "    \"z_kita_near_500\",\n",
    "    \"z_kita_near_800\",\n",
    "    \"z_kita_near_1000\",\n",
    "\n",
    "    # Grundschulen\n",
    "    \"z_grundschulen_distance\",\n",
    "    \"z_grundschulen_near_500\",\n",
    "    \"z_grundschulen_near_800\",\n",
    "    \"z_grundschulen_near_1000\",\n",
    "\n",
    "    # Haltestellen / Headway\n",
    "    \"z_haltestelle_distance\",\n",
    "    \"z_headway_score\",\n",
    "\n",
    "    # MedZentren\n",
    "    \"z_medzentrum_distance\",\n",
    "    \"z_medzentrum_near_500\",\n",
    "    \"z_medzentrum_near_800\",\n",
    "    \"z_medzentrum_near_1000\",\n",
    "\n",
    "    # Grünflächen\n",
    "    \"z_gruen_distance\",\n",
    "    \"z_gruen_near_500\",\n",
    "    \"z_gruen_near_800\",\n",
    "    \"z_gruen_near_1000\",\n",
    "]\n",
    "\n",
    "# ---------------------------------------\n",
    "# Validierung\n",
    "# ---------------------------------------\n",
    "missing = [c for c in z_vars if c not in gdf.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Diese Z-Variablen fehlen im gdf: {missing}\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# Datenmatrix: nur vollständige Zeilen\n",
    "# ---------------------------------------\n",
    "X = gdf[z_vars].dropna().values\n",
    "\n",
    "# ---------------------------------------\n",
    "# Elbow-Methode\n",
    "# ---------------------------------------\n",
    "inertia = []\n",
    "cluster_range = range(2, 20)\n",
    "\n",
    "for k in cluster_range:\n",
    "    model = KMeans(n_clusters=k, random_state=42)\n",
    "    model.fit(X)\n",
    "    inertia.append(model.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(cluster_range, inertia, marker='o')\n",
    "plt.title(\"Elbow-Methode: KMeans-Inertia vs. Clusteranzahl\")\n",
    "plt.xlabel(\"Anzahl Cluster (k)\")\n",
    "plt.ylabel(\"Inertia (Distanz innerhalb der Cluster)\")\n",
    "plt.xticks(cluster_range)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "a25fef9d8bf060c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Silhouetten-Analyse\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouettes = []\n",
    "\n",
    "for k in cluster_range:\n",
    "    model = KMeans(n_clusters=k, random_state=42)\n",
    "    labels = model.fit_predict(X)\n",
    "    score = silhouette_score(X, labels, random_state=42)\n",
    "    silhouettes.append(score)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(cluster_range, silhouettes, marker='o', color=\"green\")\n",
    "plt.title(\"Silhouetten-Score pro Clusteranzahl\")\n",
    "plt.xlabel(\"Anzahl Cluster (k)\")\n",
    "plt.ylabel(\"Durchschn. Silhouetten-Koeffizient\")\n",
    "plt.xticks(cluster_range)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "dd61e3f41e78504d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X = gdf[z_vars].dropna().values  # Nur vollständige Zeilen\n",
    "\n",
    "# Die Anzahl der Cluster (Wohnlagen) sollte nach der Bewertung der Scores oben gesetzt werden\n",
    "NUMBER_OF_CLUSTERS = 17\n",
    "\n",
    "model = KMeans(n_clusters=NUMBER_OF_CLUSTERS, random_state=42).fit(X)\n",
    "\n",
    "mask_complete = gdf[z_vars].notna().all(axis=1)\n",
    "gdf.loc[mask_complete, \"cluster\"] = model.labels_\n",
    "\n",
    "cluster_centers = pd.DataFrame(model.cluster_centers_, columns=z_vars)\n",
    "cluster_centers.index.name = \"Cluster\"\n",
    "print(cluster_centers.round(2))\n",
    "\n",
    "# Visualisierung mit Dimension Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "X_scaled = X  # bereits Z-Scores → keine erneute Skalierung nötig\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "cmap = plt.get_cmap(\"tab10\")\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=model.labels_, cmap=cmap, alpha=0.6)\n",
    "plt.title(\"KMeans-Cluster (PCA 2D-Projektion)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ],
   "id": "2a3ba24b6de7a923",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd, folium\n",
    "\n",
    "gdf = gdf[gdf[\"lat\"].notna() & gdf[\"lon\"].notna() & gdf[\"cluster\"].notna()]\n",
    "gdf[\"cluster\"] = gdf[\"cluster\"].astype(int)\n",
    "\n",
    "# Farbpalette für Cluster\n",
    "cluster_colors = {\n",
    "    0: \"#e41a1c\",   # Cluster 0 - rot\n",
    "    1: \"#377eb8\",   # Cluster 1 - blau\n",
    "    2: \"#4daf4a\",   # Cluster 2 - grün\n",
    "    3: \"#984ea3\",   # Cluster 3 - lila\n",
    "    4: \"#ff7f00\",   # Cluster 4 - orange\n",
    "    5: \"#666666\",   # Cluster 5...\n",
    "    6: \"#a65628\",\n",
    "    7: \"#66cd2c\",\n",
    "}\n",
    "\n",
    "# Farben für Wohnlagen (grün - gelb)\n",
    "color_map = {\n",
    "    \"1 Top\":      \"#fee08b\",\n",
    "    \"2\":          \"#d9ef8b\",\n",
    "    \"3\":          \"#a6d96a\",\n",
    "    \"4\":          \"#66bd63\",\n",
    "    \"5 schwach\":  \"#1a9850\",\n",
    "}\n",
    "\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Add layer markers\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/einzelhandel_geocoded.csv\", color=\"blue\", icon=\"shopping-cart\", layer_name=\"Einzelhandel\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/grundschulen_geocoded.csv\", color=\"green\", icon=\"graduation-cap\", layer_name=\"Grundschulen\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/kitas_geocoded.csv\", color=\"beige\", icon=\"child\", layer_name=\"Kitas\")\n",
    "#add_markers_from_csv(map_obj=m,csv_path=\"data/haltestellen_geocoded.csv\",color=\"lightgray\", icon=\"bus\", layer_name=\"Haltestellen\")\n",
    "\n",
    "valid_kita_json = gdf[\"kitas_route\"].apply(lambda x: isinstance(x, str))\n",
    "print(\"Gültige JSON-Einträge:\", valid_kita_json.sum(), \"/\", len(gdf))\n",
    "\n",
    "for _, r in gdf.iterrows():\n",
    "    c = cluster_colors.get(r.cluster, \"#666666\")\n",
    "    folium.CircleMarker(\n",
    "        location=[r.lat, r.lon],\n",
    "        radius=3,\n",
    "        color=c,\n",
    "        fill=True,\n",
    "        fill_color=c,\n",
    "        fill_opacity=0.85,\n",
    "        tooltip=f\"{r.Straßenname} {r.Hsnr} – Cluster {r.cluster}\"\n",
    "    ).add_to(m)\n",
    "\n",
    "# Optional: Layer Control\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "print(gdf.shape)\n",
    "\n",
    "#m.save(\"wohnlagen_clusterkarte.html\")\n",
    "m"
   ],
   "id": "19db7c7c67edc72a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Nur Spalten verwenden, die im gdf enthalten sind\n",
    "cols = [col for col in z_vars if col in gdf.columns]\n",
    "\n",
    "# Korrelationsmatrix berechnen\n",
    "corr = gdf[cols].corr()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(corr, annot=True, cmap=\"vlag\", center=0)\n",
    "plt.title(\"Korrelationsmatrix der Z-Scores\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "3884a510fe473e01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Die Korrelationsanalyse zeigt, dass einige Variablen stark korreliert sind, z. B. die verschiedenen Distanzen zu Einzelhandelsstandorten und die Anzahl der Standorte in der Nähe. Dies ist zu erwarten, da Adressen, die näher an Einzelhandelsstandorten liegen, tendenziell auch mehr Standorte in ihrer Umgebung haben. Gleichzeitig ist die Zentralität erwartungskonform leicht mit der Verfügbarkeit von Nahversorgung (Einkaufsmöglichkeiten, medizinische Versorgung, Kitas) korreliert. Diese Erkenntnisse sind Hinweise auf die Plausibilität des Modells, wobei gleichzeitg keine perfekten Korrelationen vorliegen, die auf Redundanzen hindeuten würden. Alle bisher betrachteten Kriterien scheinen relevante und unterschiedliche Aspekte der Wohnlage zu erfassen.",
   "id": "93a582f2058f2e79"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Interaktive Karte für Bewertung einzelner Adressen",
   "id": "1495801883de52ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Widget für Adresseingabe\n",
    "text_input = widgets.Text(\n",
    "    value='Immenweg 56',\n",
    "    placeholder='Straßenname Hausnummer',\n",
    "    description='Adresse:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Button\n",
    "button = widgets.Button(description=\"Zeige Routen\")\n",
    "\n",
    "# Ausgabe-Bereich für die Karte\n",
    "output = widgets.Output()\n",
    "\n",
    "# Funktion zum Einfügen einer Route + Zielmarker\n",
    "def add_route(m, geojson_str, color, label, icon, distance=None):\n",
    "    if isinstance(geojson_str, str):\n",
    "        try:\n",
    "            geo = json.loads(geojson_str)\n",
    "            if geo.get(\"type\") == \"LineString\":\n",
    "                coords = [(y, x) for x, y in geo[\"coordinates\"]]\n",
    "                distance_text = f\" – {int(distance)} m\" if distance else \"\"\n",
    "                tooltip_text = f\"{label}{distance_text}\"\n",
    "\n",
    "                folium.PolyLine(\n",
    "                    locations=coords,\n",
    "                    color=color,\n",
    "                    weight=4,\n",
    "                    opacity=0.9,\n",
    "                    tooltip=tooltip_text\n",
    "                ).add_to(m)\n",
    "\n",
    "                end = coords[-1]\n",
    "                folium.Marker(\n",
    "                    location=end,\n",
    "                    icon=folium.Icon(color=color, icon=icon, prefix=\"fa\"),\n",
    "                    tooltip=f\"Ziel: {label}{distance_text}\"\n",
    "                ).add_to(m)\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler bei {label}: {e}\")\n",
    "\n",
    "# Funktion zum Anzeigen der Karte\n",
    "def show_routes():\n",
    "    with output:\n",
    "        clear_output()\n",
    "        addr = text_input.value.strip().lower()\n",
    "\n",
    "        filtered = gdf[gdf[\"Adresse_merge\"].str.lower().str.contains(addr)]\n",
    "        if filtered.empty:\n",
    "            print(\"Keine Adresse gefunden.\")\n",
    "            return\n",
    "\n",
    "        row = filtered.iloc[0]\n",
    "        m = folium.Map(location=[row.lat, row.lon], zoom_start=15, tiles=\"cartodbpositron\")\n",
    "        folium.Marker(location=[row.lat, row.lon], tooltip=\"Adresse\").add_to(m)\n",
    "\n",
    "        # ▸ Routen einfügen\n",
    "        add_route(m, row.get(\"center_route\"), \"lightgray\", \"Weg zum Zentrum\", \"arrows-to-circle\", row.get(\"center_distance_m\"))\n",
    "        add_route(m, row.get(\"kitas_route\"), \"orange\", \"Nächste Kita\", \"child\", row.get(\"kitas_min_distance_m\"))\n",
    "        add_route(m, row.get(\"grundschulen_route\"), \"green\", \"Nächste Grundschule\", \"graduation-cap\", row.get(\"grundschulen_min_distance_m\"))\n",
    "        add_route(m, row.get(\"haltestellen_route\"), \"gray\", \"Nächste Haltestelle\", \"bus\", row.get(\"haltestellen_min_distance_m\"))\n",
    "        add_route(m, row.get(\"medzentren_route\"), \"red\", \"Nächstes Medizinisches Zentrum\", \"staff-snake\", row.get(\"medzentren_min_distance_m\"))\n",
    "        add_route(m, row.get(\"einzelhandel_route\"), \"blue\", \"Nächster Einzelhandel\", \"shop\", row.get(\"einzelhandel_min_distance_m\"))\n",
    "        #add_route(m, row.get(\"gruen_route\"), \"green\", \"Nächste Freizeit- und Erholungsfläche\", \"tree\", row.get(\"gruen_min_distance_m\"))\n",
    "        display(m)\n",
    "\n",
    "# Button-Event\n",
    "button.on_click(show_routes)\n",
    "\n",
    "# UI anzeigen\n",
    "display(text_input, button, output)\n",
    "\n",
    "m"
   ],
   "id": "1505678dc5e76d43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Glättung zur Vermeidung von \"Insellagen\"\n",
    "Ein Ziel der Analyse ist die Entwicklung zusammenhängender Gebiete, die einer gemeinsamen Wohnlage zugeordnet werden können. Damit sollen \"Insellagen\", also mehrere abgeschnittene Bereiche mit derselben Wohnlage vermieden werden. Dafür wenden wir im Folgenden eine Glättung an."
   ],
   "id": "e06cb92a06290d6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from libpysal import weights\n",
    "from spopt.region import Skater\n",
    "\n",
    "W = weights.contiguity.Queen.from_dataframe(gdf, use_index=True)\n",
    "attrs = all_input_vars\n",
    "\n",
    "sk = Skater(gdf, W, attrs, n_clusters=NUMBER_OF_CLUSTERS)\n",
    "sk.solve()\n",
    "\n",
    "gdf[\"skater_cluster\"] = sk.labels_"
   ],
   "id": "f484c57f5d6ff67e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd, folium\n",
    "\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"cartodbpositron\")\n",
    "cluster_colors = {\n",
    "    0:  \"#e41a1c\",  # kräftiges Rot\n",
    "    1:  \"#377eb8\",  # kräftiges Blau\n",
    "    2:  \"#4daf4a\",  # kräftiges Grün\n",
    "    3:  \"#984ea3\",  # kräftiges Lila\n",
    "    4:  \"#ff7f00\",  # Orange\n",
    "    5:  \"#ffff33\",  # Gelb (klar sichtbar)\n",
    "    6:  \"#a65628\",  # Braun\n",
    "    7:  \"#f781bf\",  # Pink\n",
    "    8:  \"#999999\",  # Mittelgrau\n",
    "    9:  \"#1b9e77\",  # türkis-grün (klar unterscheidbar von grün)\n",
    "    10: \"#d95f02\",  # warmes Orange (andere Familie als #ff7f00)\n",
    "    11: \"#7570b3\",  # Blau-Lila (gut unterscheidbar von 1 & 3)\n",
    "    12: \"#e7298a\",  # Magenta\n",
    "    13: \"#66a61e\",  # Olivgrün (Matt → weit von #4daf4a)\n",
    "    14: \"#e6ab02\",  # Senfgelb\n",
    "    15: \"#a6761d\",  # Ocker\n",
    "    16: \"#666666\",  # Dunkelgrau\n",
    "    17: \"#1f78b4\",  # Dunkelblau (kräftig unterscheidbar)\n",
    "    18: \"#b2df8a\",  # helles, aber eindeutig blasses Grün\n",
    "    19: \"#6a3d9a\",  # Dunkellila\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "for _, r in gdf.iterrows():\n",
    "    c = cluster_colors.get(r.skater_cluster, \"#666666\")\n",
    "    folium.CircleMarker(\n",
    "        location=[r.lat, r.lon],\n",
    "        radius=3,\n",
    "        color=c,\n",
    "        fill=True,\n",
    "        fill_color=c,\n",
    "        fill_opacity=0.85,\n",
    "        tooltip=f\"{r.Straßenname} {r.Hsnr} – Cluster {r.skater_cluster}\"\n",
    "    ).add_to(m)\n",
    "\n",
    "# Optional: Layer Control\n",
    "folium.LayerControl().add_to(m)\n",
    "m"
   ],
   "id": "37bb9529b5b0103a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WohnlagenBRB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

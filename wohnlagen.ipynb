{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e58eeaf9ab328ebb",
   "metadata": {},
   "source": [
    "# Datenvorbereitung\n",
    "Zunächst werden für alle gewünschten Einflussfaktoren die Daten beschafft und in ein CSV-Format mit lat/lon oder GeoJSON-Geoemtry gebracht, sodass zu allen Adressen die gewünschten Eigenschaften vorliegen."
   ]
  },
  {
   "cell_type": "code",
   "id": "d68fa405f11e996b",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from geopandas import GeoDataFrame\n",
    "# Helper-Funktionen für Geodaten\n",
    "from shapely.geometry import Point\n",
    "\n",
    "EPSG_4326 = \"EPSG:4326\"\n",
    "\n",
    "HAUSNUMMERZUSATZ = \"HsnrZus\"\n",
    "HAUSNUMMER = \"Hsnr\"\n",
    "STRASSENNAME = \"Straßenname\"\n",
    "\n",
    "def load_geocsv(path, crs=\"EPSG:4326\", geometry_col=\"geometry\"):\n",
    "    df = pd.read_csv(path, encoding=\"utf-8\")\n",
    "\n",
    "    # FALL 1: \"geometry\" existiert\n",
    "    if geometry_col in df.columns:\n",
    "        # Parse vorhandene Werte; falls leer, bleibt es None\n",
    "        df[geometry_col] = df[geometry_col].apply(\n",
    "            lambda x: wkt.loads(x) if isinstance(x, str) and x.startswith(\"POINT\") else None\n",
    "        )\n",
    "    # FALL 2: \"geometry\" existiert NICHT\n",
    "    else:\n",
    "        if \"lon\" in df.columns and \"lat\" in df.columns:\n",
    "            # Erzeuge komplett neue \"geometry\"-Spalte\n",
    "            df[geometry_col] = df.apply(\n",
    "                lambda row: Point(float(row[\"lon\"]), float(row[\"lat\"]))\n",
    "                if pd.notna(row[\"lon\"]) and pd.notna(row[\"lat\"]) else None,\n",
    "                axis=1\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Fehlt sowohl 'geometry' als auch ('lat', 'lon')! \"\n",
    "                f\"Gefunden: {df.columns.tolist()}\"\n",
    "            )\n",
    "    # Mach GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geometry_col, crs=crs)\n",
    "    return gdf\n",
    "\n",
    "def geo_sjoin(left, right, value_cols, how=\"left\", predicate=\"intersects\", drop_index_cols=True,\n",
    "              suffixes=(\"\", \"_joined\")):\n",
    "    # Prüfe, ob Spalten bereits existieren\n",
    "    already_present = [col for col in value_cols if col in left.columns]\n",
    "    if already_present:\n",
    "        print(f\"Skip Join: Columns already present: {already_present}\")\n",
    "        return left\n",
    "    # Nur Join, wenn noch nicht passiert\n",
    "    result = gpd.sjoin(left, right[value_cols + [\"geometry\"]], how=how, predicate=predicate, lsuffix=suffixes[0],\n",
    "                       rsuffix=suffixes[1])\n",
    "    if drop_index_cols:\n",
    "        result = result[[col for col in result.columns if not col.startswith(\"index_\")]]\n",
    "    result = result.reset_index(drop=True)\n",
    "    return result\n",
    "\n",
    "def make_merge_addr(row):\n",
    "    s = str(row[STRASSENNAME]).strip().lower()\n",
    "    hn = str(row[HAUSNUMMER]).strip().lower()\n",
    "    hzusatz = str(row.get(HAUSNUMMERZUSATZ, '')).strip().lower() if HAUSNUMMERZUSATZ in row and not pd.isna(row.get(HAUSNUMMERZUSATZ, None)) else \"\"\n",
    "    if hzusatz and hzusatz != \"nan\":\n",
    "        hn += hzusatz\n",
    "    adr = f\"{s} {hn}\".replace(\"  \", \" \").strip()\n",
    "    return adr\n",
    "\n",
    "TOOLTIP_FORMAT = \"<b>{Name}</b><br>{Straßenname} {Hsnr}{HsnrZus}\"\n",
    "\n",
    "def add_markers_from_csv(\n",
    "    map_obj,\n",
    "    csv_path,\n",
    "    color=\"blue\",\n",
    "    icon=\"info-sign\",\n",
    "    tooltip_format=TOOLTIP_FORMAT,\n",
    "    fallback_label=\"Unbekannte Adresse\",\n",
    "    layer_name=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Fügt Marker aus einer CSV-Datei einer Folium-Karte hinzu.\n",
    "    Erwartet mindestens Spalten: 'lat', 'lon', 'Straßenname', 'Hsnr' (optional 'HsnrZus').\n",
    "    Zusätzlich wird eine Spalte verwendet, deren Name mit 'Name_' beginnt (z. B. 'Name_Arztpraxis').\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path, encoding=\"utf-8\")\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    df = df.dropna(subset=[\"lat\", \"lon\"])\n",
    "\n",
    "    # Alle potenziellen Namensspalten vorab bestimmen (z. B. Name_Arztpraxis, Name_Apotheke, ...)\n",
    "    name_cols = [c for c in df.columns if c.startswith(\"Name_\")]\n",
    "\n",
    "    layer = folium.FeatureGroup(name=layer_name) if layer_name else map_obj\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        # explizit fehlende Werte ersetzen\n",
    "        strasse = s(row.get(STRASSENNAME))\n",
    "        hsnr    = s(row.get(HAUSNUMMER))\n",
    "        hsnrzus = s(row.get(HAUSNUMMERZUSATZ))\n",
    "        hat_adresse = any([strasse, hsnr, hsnrzus])\n",
    "\n",
    "        # Name aus der ersten nicht-leeren 'Name_'-Spalte ableiten\n",
    "        name_value = \"\"\n",
    "        for nc in name_cols:\n",
    "            val = str(row.get(nc, \"\") or \"\").strip()\n",
    "            if val:\n",
    "                name_value = val\n",
    "                break\n",
    "\n",
    "        # Tooltip bauen (falls keine Adresse, Fallback)\n",
    "        if hat_adresse or name_value:\n",
    "            tooltip = tooltip_format.format(\n",
    "                Name=name_value,\n",
    "                Straßenname=strasse,\n",
    "                Hsnr=hsnr,\n",
    "                HsnrZus=hsnrzus\n",
    "            )\n",
    "        else:\n",
    "            tooltip = fallback_label\n",
    "\n",
    "        marker = folium.Marker(\n",
    "            location=[row[\"lat\"], row[\"lon\"]],\n",
    "            icon=folium.Icon(color=color, icon=icon, prefix=\"fa\"),\n",
    "            tooltip=tooltip\n",
    "        )\n",
    "        marker.add_to(layer)\n",
    "\n",
    "    if layer_name:\n",
    "        layer.add_to(map_obj)\n",
    "\n",
    "def min_max(series, invert=False):\n",
    "    s = series.copy()\n",
    "    if invert:\n",
    "        s = -s\n",
    "    return (s - s.min()) / (s.max() - s.min())\n",
    "\n",
    "def s(v) -> str:\n",
    "    \"\"\"NaN/None -> '', sonst getrimmt als String.\"\"\"\n",
    "    if v is None or pd.isna(v):\n",
    "        return \"\"\n",
    "    # manche CSVs haben das Literal \"nan\" als Text:\n",
    "    if isinstance(v, str) and v.strip().lower() == \"nan\":\n",
    "        return \"\"\n",
    "    return str(v).strip()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "87da6d87bee8556e",
   "metadata": {},
   "source": [
    "## Adressen einlesen\n",
    "Alle Adressen des Zielgebiets als CSV in einen GeoDataFrame einlesen."
   ]
  },
  {
   "cell_type": "code",
   "id": "9ade75ddfb40cfcf",
   "metadata": {},
   "source": [
    "import geopandas as gpd\n",
    "gdf_main = load_geocsv(\"data/adressen_mit_routen.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ef4f9c4ef5c70cf8",
   "metadata": {},
   "source": [
    "## Ortsteile der Stadt visualisieren und im Datensatz ergänzen"
   ]
  },
  {
   "cell_type": "code",
   "id": "cc640d3dc01dd49c",
   "metadata": {},
   "source": [
    "import json\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "# Datei laden\n",
    "with open(\"data/ortsteile_brandenburg.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "# FeatureCollection extrahieren\n",
    "features = raw[\"features\"]\n",
    "gdf_ortsteile = gpd.GeoDataFrame.from_features(features)\n",
    "gdf_ortsteile.set_crs(EPSG_4326, inplace=True)\n",
    "\n",
    "#  BBOX für Brandenburg an der Havel (nur relevante Ortsteile)\n",
    "bbox = box(12.3120236786, 52.2938432979, 12.7562682548, 52.5594777244)\n",
    "gdf_ortsteile = gdf_ortsteile.clip(bbox)\n",
    "\n",
    "# Karte zentrieren\n",
    "CITY_CENTER = (52.4116351153561, 12.556331280534392)\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=12, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Tooltip konfigurieren\n",
    "tooltip_fields = [\"otl_name\"]\n",
    "tooltip = folium.GeoJsonTooltip(\n",
    "    fields=tooltip_fields,\n",
    "    aliases=[\"Ortsteil\"],\n",
    "    localize=True,\n",
    "    sticky=True\n",
    ")\n",
    "\n",
    "# GeoJSON mit Tooltip zur Karte hinzufügen\n",
    "folium.GeoJson(\n",
    "    gdf_ortsteile,\n",
    "    name=\"Ortsteile\",\n",
    "    tooltip=tooltip\n",
    ").add_to(m)\n",
    "\n",
    "assert gdf_main.crs.to_epsg() == 4326\n",
    "assert gdf_ortsteile.crs.to_epsg() == 4326\n",
    "\n",
    "gdf_main = gpd.sjoin(gdf_main, gdf_ortsteile[[\"geometry\", \"otl_name\"]], how=\"left\", predicate=\"within\")\n",
    "gdf_main = gdf_main.rename(columns={\"otl_name\": \"ortsteil\"})\n",
    "gdf_main = gdf_main.drop(columns=[\"index_right\"], errors=\"ignore\")\n",
    "\n",
    "# Drop rows with NaN lat/lon\n",
    "gdf_main = gdf_main.dropna(subset=[\"lat\"])\n",
    "\n",
    "# Mögliche Erweiterung: Ergänzung einer Spalte \"stadtteil\" für spätere Validierung und auch Visualisierung\n",
    "# Adressen im Zentrum haben korrekterweise keinen Ortsteil\n",
    "\n",
    "# Karte anzeigen\n",
    "m\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e4a505c514a59316",
   "metadata": {},
   "source": [
    "## Explorative Datenanalyse"
   ]
  },
  {
   "cell_type": "code",
   "id": "ae54bd9392109709",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns           # nur für schönere Plots\n",
    "from helper import load_geocsv\n",
    "\n",
    "# Eindeutigen Merge-baren String aus Adresse erzeugen\n",
    "gdf_main[\"Adresse_merge\"] = gdf_main.apply(make_merge_addr, axis=1)\n",
    "\n",
    "gdf_main = gdf_main.rename(columns={\"geojson\": \"center_route\",\n",
    "                                    \"distance_m\" : \"center_distance\"})\n",
    "\n",
    "# Relevante Spalten auswählen\n",
    "gdf_main = gdf_main[[\"Straßenname\", \"Hsnr\", \"HsnrZus\",\n",
    "         \"center_distance\", \"lat\", \"lon\", \"geometry\", \"Adresse_merge\", \"ortsteil\", \"center_route\"]]\n",
    "\n",
    "# Histogramm der Distanzen zum Zentrum\n",
    "plt.figure(figsize=(6,3))\n",
    "sns.histplot(gdf_main[\"center_distance\"], bins=60, kde=False)\n",
    "plt.title(\"Verteilung der Fußentfernung zum Zentrum\")\n",
    "plt.xlabel(\"Distanz (Meter)\")\n",
    "plt.ylabel(\"Häufigkeit\")\n",
    "plt.show()\n",
    "print(gdf_main.shape)\n",
    "print(gdf_main.columns)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c212e1e7f8401b2d",
   "metadata": {},
   "source": [
    "## Daten bereinigen"
   ]
  },
  {
   "cell_type": "code",
   "id": "d977cdd0e53252b4",
   "metadata": {},
   "source": [
    "print(gdf_main.shape)\n",
    "# Dubletten aus Adressen entfernen\n",
    "dups = gdf_main[\"Adresse_merge\"].value_counts()\n",
    "dups = dups[dups > 1]\n",
    "print(f\"{len(dups)} doppelte Adressen gefunden\")\n",
    "print(dups.head())\n",
    "\n",
    "# Ersten Treffer behalten\n",
    "gdf_main = gdf_main.sort_values(\"Adresse_merge\").drop_duplicates(\"Adresse_merge\", keep=\"first\")\n",
    "print(gdf_main.shape)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "184ef02fc833f154",
   "metadata": {},
   "source": [
    "## Einzelhandel\n",
    "Separates Skript ```einzelhandel-adreessen.py``` ausfühen, um Datei \"adressen_mit_einzelhandel.csv\" zu erzeugen.\n",
    "Durch fußläufiges Routing berechnete Faktoren:\n",
    "- Anzahl von Einkaufsmöglichkeiten im Umkreis von 500 m\n",
    "- Anzahl von Einkaufsmöglichkeiten im Umkreis von 800 m\n",
    "- Geringste Distanz zum nächsten Einzelhandel"
   ]
  },
  {
   "cell_type": "code",
   "id": "f42b5b686e959068",
   "metadata": {},
   "source": [
    "import seaborn as sns, matplotlib.pyplot as plt\n",
    "\n",
    "# Lade vorberechnete Einzelhandel-Faktoren\n",
    "gdf_retail = load_geocsv(\"data/adressen_mit_einzelhandel.csv\")\n",
    "\n",
    "# Merge mit Haupt-GDF\n",
    "gdf_retail[\"Adresse_merge\"] = gdf_retail.apply(make_merge_addr, axis=1)\n",
    "gdf_retail = gdf_retail.sort_values(\"Adresse_merge\").drop_duplicates(\"Adresse_merge\", keep=\"first\")\n",
    "\n",
    "dups = gdf_retail[\"Adresse_merge\"].value_counts()\n",
    "print(dups[dups > 1])\n",
    "\n",
    "einzelhandel_attribute = [\"shop_min_m\", \"shops_500m_ct\", \"shops_800m_ct\"]\n",
    "\n",
    "gdf_main = pd.merge(\n",
    "    gdf_main,\n",
    "    gdf_retail[[\"Adresse_merge\"] + einzelhandel_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "print(gdf_main.shape)\n",
    "print(gdf_main[[\"Adresse_merge\", \"shop_min_m\"]].head())\n",
    "\n",
    "print(gdf_main.shape)\n",
    "\n",
    "# Speicher freigeben\n",
    "del(gdf_retail)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "40582ed950e765c9",
   "metadata": {},
   "source": [
    "# Verteilung Distanz zum nächsten Markt\n",
    "print(gdf_main.columns)\n",
    "sns.histplot(gdf_main[\"shop_min_m\"].dropna(), bins=40, kde=False)\n",
    "plt.title(\"Distanz zum nächsten Lebensmittel­markt\")\n",
    "plt.xlabel(\"Meter Fußweg\"); plt.ylabel(\"Adressen\")\n",
    "plt.show()\n",
    "\n",
    "# Scatter Zentralität vs. Nahversorgung\n",
    "sns.scatterplot(x=\"center_distance\", y=\"shop_min_m\", data=gdf_main, alpha=.3)\n",
    "plt.xlabel(\"Distanz Zentrum (m)\"); plt.ylabel(\"Distanz nächster Markt (m)\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d2f323afbef7d8d4",
   "metadata": {},
   "source": [
    "## Lärmbelastung\n",
    "Siehe ```laerm.ipynb``` zur Erzeugung, ansonsten einfach ```data/adressen_mit_laerm.csv``` verwenden und per Spalte 'geometry' verschneiden.\n",
    "\n",
    "Definition Lärm-Index:\n",
    "- NaN / leer: kein gemessener Straßenlärm\n",
    "- 0: 55 - 59 dB\n",
    "- 1: 60 - 64 dB\n",
    "- 2: 65 - 69 dB\n",
    "- 3: 70 - 74 dB\n",
    "- 4: >= 75 db"
   ]
  },
  {
   "cell_type": "code",
   "id": "68ddd77c43b68583",
   "metadata": {},
   "source": [
    "gdf_laerm_karte = load_geocsv(\"data/adressen_mit_laerm.csv\")\n",
    "print(gdf_laerm_karte.shape)\n",
    "print(gdf_main.shape)\n",
    "\n",
    "# Merge des Lärmindex mit Haupt-GDF\n",
    "gdf_laerm_karte[\"Adresse_merge\"] = gdf_laerm_karte.apply(make_merge_addr, axis=1)\n",
    "gdf_laerm_karte[\"Laerm_index_tag\"] = gdf_laerm_karte[\"Laerm_index_tag\"].fillna(-0.1)\n",
    "\n",
    "# Deduplicate, im Zweifel nimm den lautesten Wert\n",
    "gdf_laerm_karte = (\n",
    "    gdf_laerm_karte\n",
    "    .sort_values(\"Laerm_index_tag\", ascending=False)\n",
    "    .drop_duplicates(\"Adresse_merge\", keep=\"first\")\n",
    ")\n",
    "\n",
    "laerm_attribute = [\"Laerm_index_tag\"]\n",
    "gdf_main = pd.merge(\n",
    "    gdf_main,\n",
    "    gdf_laerm_karte[[\"Adresse_merge\"] + laerm_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "\n",
    "#print(gdf_main.columns)\n",
    "print(gdf_main.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "12690bd38c8a865e",
   "metadata": {},
   "source": [
    "## Bildung\n",
    "Weitere Faktoren\n",
    "- Fußläufige Entfernung zur nächstgelegenen Kita\n",
    "- Fußläufige Entfernung zur nächstgelegenen Schule\n",
    "- Anzahl Kitas im Umkreis von 500, 800 und 1000 Metern\n",
    "- Anzahl Schulen im Umkreis von 500, 800 und 1000 Metern"
   ]
  },
  {
   "cell_type": "code",
   "id": "1194b88750466342",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "\n",
    "# Daten als GeoDataFrame einlesen\n",
    "gdf_kitas = load_geocsv(\"data/adressen_mit_kita_routen.csv\")\n",
    "gdf_grundschulen = load_geocsv(\"data/adressen_mit_grundschul_routen.csv\")\n",
    "print(gdf_kitas.shape)\n",
    "print(gdf_grundschulen.shape)\n",
    "print(gdf_main.shape)\n",
    "\n",
    "# Eindeutige Adresse für den Merge generieren\n",
    "gdf_kitas[\"Adresse_merge\"] = gdf_kitas.apply(make_merge_addr, axis=1)\n",
    "gdf_kitas = gdf_kitas.drop_duplicates(\"Adresse_merge\")\n",
    "gdf_grundschulen[\"Adresse_merge\"] = gdf_grundschulen.apply(make_merge_addr, axis=1)\n",
    "gdf_grundschulen = gdf_grundschulen.drop_duplicates(\"Adresse_merge\")\n",
    "\n",
    "kitas_attribute = [\"kitas_min_distance_m\", \"kitas_geometry\", \"kitas_count_within_500m\", \"kitas_count_within_800m\", \"kitas_count_within_1000m\"]\n",
    "gdf_main = pd.merge(\n",
    "    gdf_main,\n",
    "    gdf_kitas[[\"Adresse_merge\"] + kitas_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "\n",
    "grundschulen_attribute = [\"grundschulen_min_distance_m\", \"grundschulen_geometry\", \"grundschulen_count_within_500m\", \"grundschulen_count_within_800m\", \"grundschulen_count_within_1000m\"]\n",
    "gdf_main = pd.merge(\n",
    "    gdf_main,\n",
    "    gdf_grundschulen[[\"Adresse_merge\"] + grundschulen_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "del(gdf_kitas, gdf_grundschulen)  # Speicher freigeben\n",
    "\n",
    "print(gdf_main.columns)\n",
    "print(gdf_main.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6461cab96260ab5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Medizinische Versorgung\n",
    "Ein \"medizinisches Zentrum\" wurde definiert als eine Apotheke mit zwei Ärzten im Umkreis von 100 Metern."
   ],
   "id": "4bc6829d0589c7ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "# Schritt 1: Geocoded Adressen von Apotheken und Ärzten laden\n",
    "gdf_aerzte = load_geocsv(\"data/aerzte_geocoded.csv\")\n",
    "gdf_apotheken = load_geocsv(\"data/apotheken_geocoded.csv\")\n"
   ],
   "id": "1ff01f993e15740f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Schritt 2: Geografisch Nähe (100 m) von Apotheken und Ärzten zu Zentren zusammenfassen und als Datei speichern\n",
    "\n",
    "\n",
    "#gdf_medizin = []\n",
    "#gdf_medizin = load_geocsv(\"data/medizinische-zentren-geocoded.csv\")\n",
    "\n",
    "# Schritt 3: Mit neuen Medizinischen Zentren (gdf_medizin) weiterarbeiten\n",
    "#print(gdf_medizin.columns)\n",
    "#print(gdf_medizin.shape)"
   ],
   "id": "afd5ce10da8085a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dc8d68c7ce48ddaa",
   "metadata": {},
   "source": [
    "## ÖPNV-Qualität\n",
    "\n",
    "Die Qualität des ÖPNV wird anhand der Fußläufigkeit zur nächsten Haltestelle und der Häufigkeit von Abfahrten (Headway) bewertet. Die Daten stammen vom Verkehrsverbund Berlin-Brandenburg (VBB), Lizenz: CC BY 4.0, [zu den Daten](https://unternehmen.vbb.de/digitale-services/datensaetze).\n",
    "\n",
    "Vorausgesetzte Datensätze:\n",
    "- ```data/GTFS/stops.txt```, der die Haltestellen mit ihren Geokoordinaten enthält.\n",
    "- ```data/adressen_mit_haltestellen_routen.csv```, der die Routen zu den Haltestellen und Anzahl von Haltestellen im Radius 500m und 800m enthält.\n",
    "\n",
    "Probleme mit Datenqualität:\n",
    "- In der \"2024_Haltestellen.csv\" fehlen die Haltestellen \"Libellenweg\" und \"Immenweg\" (Linie B). Dadurch werden diese Haltestellen nicht berücksichtigt und Wege zur nächsten Haltestelle werden länger eingeschätzt."
   ]
  },
  {
   "cell_type": "code",
   "id": "e307190bd56921b7",
   "metadata": {},
   "source": [
    "# Load GTFS stops data\n",
    "stops = pd.read_csv(\"data/GTFS/stops.txt\")\n",
    "stops[\"geometry\"] = stops.apply(lambda row: Point(row[\"stop_lon\"], row[\"stop_lat\"]), axis=1)\n",
    "gdf_stops = gpd.GeoDataFrame(stops, geometry=\"geometry\", crs=EPSG_4326)\n",
    "\n",
    "# Convert to UTM for precise metric distance calculations\n",
    "gdf_main = gdf_main.to_crs(epsg=32633)\n",
    "gdf_stops = gdf_stops.to_crs(epsg=32633)\n",
    "\n",
    "# Assign nearest stop to each address based on Point(X, Y) geometry\n",
    "gdf_main[\"nearest_stop_id\"] = gdf_main.geometry.apply(\n",
    "    lambda pt: gdf_stops.loc[gdf_stops.distance(pt).idxmin(), \"stop_id\"]\n",
    ")\n",
    "\n",
    "# Read routes from adresses to stops and stop count from prepared CSV\n",
    "gdf_haltestellen = load_geocsv(\"data/adressen_mit_haltestellen_routen.csv\")\n",
    "gdf_haltestellen[\"Adresse_merge\"] = gdf_haltestellen.apply(make_merge_addr, axis=1)\n",
    "\n",
    "# Merge haltestellen attributes into main GeoDataFrame\n",
    "haltestellen_attribute = [\"haltestellen_geometry\", \"haltestellen_min_distance_m\", \"haltestellen_count_within_500m\", \"haltestellen_count_within_800m\"]\n",
    "gdf_main = pd.merge(\n",
    "    gdf_main,\n",
    "    gdf_haltestellen[[\"Adresse_merge\"] + haltestellen_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "\n",
    "# Speicher freigeben\n",
    "del(gdf_haltestellen)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bb890f9e9a5f3e2c",
   "metadata": {},
   "source": [
    "### Berechnung der ÖPNV-Taktung"
   ]
  },
  {
   "cell_type": "code",
   "id": "a6f772eabddaacc9",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. GTFS laden\n",
    "stops = pd.read_csv(\"data/GTFS/stops.txt\")\n",
    "stop_times = pd.read_csv(\"data/GTFS/stop_times.txt\", low_memory=False)\n",
    "trips = pd.read_csv(\"data/GTFS/trips.txt\")\n",
    "calendar = pd.read_csv(\"data/GTFS/calendar.txt\")\n",
    "\n",
    "# 2. Zeit in Minuten umrechnen\n",
    "def parse_time_to_minutes(t):\n",
    "    try:\n",
    "        h, m, s = map(int, t.split(\":\"))\n",
    "        return h * 60 + m\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "stop_times[\"minutes\"] = stop_times[\"arrival_time\"].apply(parse_time_to_minutes)\n",
    "stop_times = stop_times.dropna(subset=[\"minutes\"])\n",
    "\n",
    "# 3. Filter nur auf werktägliche Dienste\n",
    "trips_filtered = trips.merge(calendar, on=\"service_id\")\n",
    "trips_filtered = trips_filtered[trips_filtered[\"monday\"] == 1]  # oder beliebig anpassbar\n",
    "\n",
    "# 4. Merge trips ↔ stop_times\n",
    "stopdata = stop_times.merge(trips_filtered[[\"trip_id\", \"route_id\"]], on=\"trip_id\")\n",
    "\n",
    "# 5. Headway-Funktion für beliebige Zeitfenster\n",
    "def compute_headways(df, time_col=\"minutes\", time_from=360, time_to=540):\n",
    "    result = {}\n",
    "    for stop_id, group in df.groupby(\"stop_id\"):\n",
    "        times = sorted(group[time_col])\n",
    "        times = [t for t in times if time_from <= t <= time_to]\n",
    "        if len(times) < 2:\n",
    "            continue\n",
    "        diffs = [b - a for a, b in zip(times, times[1:])]\n",
    "        result[stop_id] = sum(diffs) / len(diffs)\n",
    "    return result\n",
    "\n",
    "# 6. Berechne morgens + abends\n",
    "headway_morning = compute_headways(stopdata, time_from=360, time_to=540)     # 6–9 Uhr\n",
    "headway_evening = compute_headways(stopdata, time_from=960, time_to=1140)   # 16–19 Uhr\n",
    "\n",
    "# 7. In DataFrames umwandeln\n",
    "df_hm = pd.DataFrame.from_dict(headway_morning, orient=\"index\", columns=[\"headway_morning\"]).reset_index().rename(columns={\"index\": \"stop_id\"})\n",
    "df_he = pd.DataFrame.from_dict(headway_evening, orient=\"index\", columns=[\"headway_evening\"]).reset_index().rename(columns={\"index\": \"stop_id\"})\n",
    "df_headways = df_hm.merge(df_he, on=\"stop_id\", how=\"outer\", validate=\"one_to_one\")\n",
    "\n",
    "# 8. Merge mit gdf_main\n",
    "gdf_main[\"nearest_stop_id\"] = gdf_main[\"nearest_stop_id\"].astype(str)\n",
    "df_headways[\"stop_id\"] = df_headways[\"stop_id\"].astype(str)\n",
    "\n",
    "# Headway-Spalten explizit aus gdf_main entfernen, falls sie existieren\n",
    "for col in [\"headway_morning\", \"headway_evening\", \"headway_avg\", \"stop_id\"]:\n",
    "    if col in gdf_main.columns:\n",
    "        gdf_main = gdf_main.drop(columns=[col])\n",
    "\n",
    "headway_attribute = [\"headway_morning\", \"headway_evening\"]\n",
    "gdf_main = pd.merge(\n",
    "    gdf_main,\n",
    "    df_headways[[\"stop_id\"] + headway_attribute],\n",
    "    left_on=\"nearest_stop_id\",\n",
    "    right_on=\"stop_id\",\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"\n",
    ")\n",
    "\n",
    "# Langfristig stabile Skala für Vergleichbarkeit\n",
    "# Beispielwerte für \"vernünftige\" Bandbreite (z. B. Takt 5–60 Minuten)\n",
    "fixed_min, fixed_max = 5, 60\n",
    "for col in [\"headway_morning\", \"headway_evening\"]:\n",
    "    score_col = col + \"_score_fixed\"\n",
    "    gdf_main[score_col] = 1 - (\n",
    "        (gdf_main[col] - fixed_min) / (fixed_max - fixed_min)\n",
    "    ).clip(lower=0, upper=1)\n",
    "\n",
    "# Durchschnittlicher Headway\n",
    "gdf_main[\"headway_avg\"] = gdf_main[[\"headway_morning\", \"headway_evening\"]].mean(axis=1)\n",
    "\n",
    "# Speicher freigeben\n",
    "del(stops, stop_times, trips, calendar, df_hm, df_he, df_headways)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c392704b502cf76f",
   "metadata": {},
   "source": [
    "## Visualisierung der ÖPNV-Taktung"
   ]
  },
  {
   "cell_type": "code",
   "id": "2c4d67f47fbd596",
   "metadata": {},
   "source": [
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from branca.colormap import linear\n",
    "\n",
    "# Basiskarte anlegen\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=12, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Farbskala vorbereiten (linear, abgestimmt auf deine Daten)\n",
    "vmin, vmax = gdf_main[\"headway_avg\"].quantile([0.01, 0.99])  # Extremwerte abschneiden\n",
    "colormap = linear.RdYlGn_11.scale(vmin, vmax).to_step(n=9)\n",
    "colormap.caption = \"Durchschnittlicher Headway (Minuten)\"\n",
    "\n",
    "# Adressen als Punkte (gefärbt nach Headway)\n",
    "for idx, row in gdf_main.iterrows():\n",
    "    if pd.notnull(row[\"headway_avg\"]) and row.geometry:\n",
    "        folium.CircleMarker(\n",
    "            location=[row.geometry.y, row.geometry.x],\n",
    "            radius=5,\n",
    "            color=colormap(row[\"headway_avg\"]),\n",
    "            fill=True,\n",
    "            fill_opacity=0.8,\n",
    "            popup=f\"Adresse: {row.get('Adresse_merge', idx)}<br>Headway: {row['headway_avg']:.1f} min\"\n",
    "        ).add_to(m)\n",
    "\n",
    "# Haltestellen als schwarze Marker mit Cluster\n",
    "marker_cluster = MarkerCluster(name=\"ÖPNV-Haltestellen\").add_to(m)\n",
    "for idx, row in gdf_stops.iterrows():\n",
    "    if row.stop_lat and row.stop_lon:\n",
    "        folium.CircleMarker(\n",
    "            location=[row.stop_lon, row.stop_lat],\n",
    "            radius=4,\n",
    "            color=\"black\",\n",
    "            fill=True,\n",
    "            fill_opacity=1,\n",
    "            popup=row.get(\"stop_name\", str(row.get(\"stop_id\", idx)))\n",
    "        ).add_to(marker_cluster)\n",
    "\n",
    "# Legende\n",
    "colormap.add_to(m)\n",
    "\n",
    "# Layer control (optional)\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "# Karte anzeigen\n",
    "m\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "868139354b85b686",
   "metadata": {},
   "source": [
    "# Visualisierung aller Indikatoren\n",
    "Alle Einflussfaktoren (Supermärkte, Ärzte, Schulen etc.) werden zur Plausibilitätsprüfung auf einer Karte visualisiert."
   ]
  },
  {
   "cell_type": "code",
   "id": "420b28d5f45c67fb",
   "metadata": {},
   "source": [
    "import folium\n",
    "import branca.colormap as cm\n",
    "\n",
    "CITY_CENTER = (52.4116351153561, 12.556331280534392)\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Add layer markers\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"data/einzelhandel_geocoded.csv\", color=\"blue\", icon=\"shopping-cart\", layer_name=\"Einzelhandel\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"data/grundschulen_geocoded.csv\",color=\"green\", icon=\"graduation-cap\",layer_name=\"Grundschulen\")\n",
    "#add_markers_from_csv(map_obj=m, csv_path=\"data/kitas_geocoded.csv\", color=\"beige\", icon=\"child\",layer_name=\"Kitas\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"data/haltestellen_geocoded.csv\",color=\"lightgray\", icon=\"bus\", layer_name=\"Haltestellen\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"data/apotheken_geocoded.csv\",color=\"red\", icon=\"staff-snake\", layer_name=\"Apotheken\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"data/aerzte_geocoded.csv\",color=\"lightred\", icon=\"user-doctor\", layer_name=\"Ärzte\")\n",
    "\n",
    "# Lärmindex aus dem Geopackage\n",
    "gdf_laerm_karte = gpd.read_file(\"data/laerm.gpkg\")\n",
    "bbox = box(12.3120236786, 52.2938432979, 12.7562682548, 52.5594777244)\n",
    "gdf_laerm_karte = gdf_laerm_karte.clip(bbox)\n",
    "value_column = \"isov1\"\n",
    "min_val = gdf_laerm_karte[value_column].min()\n",
    "max_val = gdf_laerm_karte[value_column].max()\n",
    "colormap = cm.LinearColormap(colors=[\"green\", \"yellow\", \"red\"], vmin=min_val, vmax=max_val)\n",
    "colormap.caption = \"Lärmpegel (LDEN in dB)\"\n",
    "\n",
    "# Alle Adressen als Punkte\n",
    "adress_layer = folium.FeatureGroup(name=\"Wohnadressen\")\n",
    "for _, row in gdf_main.iterrows():\n",
    "    if pd.notna(row[\"lat\"]) and pd.notna(row[\"lon\"]):\n",
    "        strasse = str(row.get(HAUSNUMMER, \"\")).strip()\n",
    "        hsnr = str(row.get(HAUSNUMMER, \"\")).strip()\n",
    "        hsnrzus = str(row.get(HAUSNUMMERZUSATZ, \"\")).strip()\n",
    "\n",
    "        tooltip = strasse + \" \" + hsnr\n",
    "        \n",
    "        adressen_map = folium.CircleMarker(\n",
    "            location=[row[\"lat\"], row[\"lon\"]],\n",
    "            radius=3,\n",
    "            color=\"lightgray\",\n",
    "            fill=True,\n",
    "            fill_opacity=0.6,\n",
    "            tooltip=tooltip\n",
    "        ).add_to(adress_layer)\n",
    "adress_layer.add_to(m)\n",
    "\n",
    "def style_function(feature):\n",
    "    value = feature[\"properties\"][value_column]\n",
    "    return {\n",
    "        \"fillColor\": colormap(value),\n",
    "        \"color\": \"black\",\n",
    "        \"weight\": 0.3,\n",
    "        \"fillOpacity\": 0.2\n",
    "    }\n",
    "\n",
    "laerm_layer = folium.FeatureGroup(name=\"Lärmkarte (LDEN 2022)\")\n",
    "folium.GeoJson(\n",
    "    gdf_laerm_karte,\n",
    "    style_function=style_function,\n",
    ").add_to(laerm_layer)\n",
    "laerm_layer.add_to(m)\n",
    "colormap.add_to(m)\n",
    "\n",
    "# Schaltbare Layer\n",
    "folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "del(gdf_laerm_karte)  # Speicher freigeben\n",
    "\n",
    "m\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "af7678d3d6d93e1d",
   "metadata": {},
   "source": [
    "## Faktoren\n",
    "Hier werden z-Werte zu alle **Einflussfaktoren** gebildet, um die Abweichung einer Ausprägung vom Standard zu erfassen. Weiterhin werden die **Gewichte** festgelegt, mit denen die Faktoren in die Wohnlagenbewertung eingehen."
   ]
  },
  {
   "cell_type": "code",
   "id": "d1fb4551bdecba3",
   "metadata": {},
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "gdf = gdf_main # zum vereinfachten Umgang\n",
    "\n",
    "# Nur Zeilen mit vollständigen Daten verwenden\n",
    "score_vars = ([\"center_distance\"] +\n",
    "              haltestellen_attribute +\n",
    "              headway_attribute +\n",
    "              einzelhandel_attribute +\n",
    "              laerm_attribute +\n",
    "              kitas_attribute +\n",
    "              grundschulen_attribute\n",
    "              )\n",
    "mask_all = gdf[score_vars].notna().all(axis=1)\n",
    "\n",
    "# Z‑Scores, fehlende Werte bleiben NaN\n",
    "gdf.loc[mask_all, \"z_centrality\"]    = -zscore(gdf.loc[mask_all, \"center_distance\"])\n",
    "gdf.loc[mask_all, \"z_shop_distance\"] = -zscore(gdf.loc[mask_all, \"shop_min_m\"])\n",
    "gdf.loc[mask_all, \"z_shop_near_500\"] =  zscore(gdf.loc[mask_all, \"shops_500m_ct\"])\n",
    "gdf.loc[mask_all, \"z_shop_near_800\"] =  zscore(gdf.loc[mask_all, \"shops_800m_ct\"])\n",
    "gdf.loc[mask_all, \"z_laerm_index_tag\"] = -zscore(gdf.loc[mask_all, \"Laerm_index_tag\"])\n",
    "gdf.loc[mask_all, \"z_kita_distance\"] = -zscore(gdf.loc[mask_all, \"kitas_min_distance_m\"])\n",
    "gdf.loc[mask_all, \"z_kita_near_500\"] =  zscore(gdf.loc[mask_all, \"kitas_count_within_500m\"])\n",
    "gdf.loc[mask_all, \"z_kita_near_800\"] =  zscore(gdf.loc[mask_all, \"kitas_count_within_800m\"])\n",
    "gdf.loc[mask_all, \"z_kita_near_1000\"] =  zscore(gdf.loc[mask_all, \"kitas_count_within_1000m\"])\n",
    "gdf.loc[mask_all, \"z_grundschul_distance\"] = -zscore(gdf.loc[mask_all, \"grundschulen_min_distance_m\"])\n",
    "gdf.loc[mask_all, \"z_grundschulen_near_500\"] =  zscore(gdf.loc[mask_all, \"grundschulen_count_within_500m\"])\n",
    "gdf.loc[mask_all, \"z_grundschulen_near_800\"] =  zscore(gdf.loc[mask_all, \"grundschulen_count_within_800m\"])\n",
    "gdf.loc[mask_all, \"z_grundschulen_near_1000\"] =  zscore(gdf.loc[mask_all, \"grundschulen_count_within_1000m\"])\n",
    "gdf.loc[mask_all, \"z_haltestelle_distance\"] = -zscore(gdf.loc[mask_all, \"haltestellen_min_distance_m\"])\n",
    "gdf.loc[mask_all, \"z_headway_score\"] = -zscore(gdf.loc[mask_all, \"headway_avg\"])\n",
    "\n",
    "# Score-Zusammenfassung nur bei vollständigen Daten\n",
    "mm_central_score_vars = [\"center_distance\", \"shop_min_m\", \"shops_500m_ct\", \"shops_800m_ct\", \"Laerm_index_tag\"]\n",
    "mask_mm_central = gdf[mm_central_score_vars].notna().all(axis=1)\n",
    "\n",
    "gdf.loc[mask_mm_central, \"score_central\"] = (\n",
    "    0.5 * gdf.loc[mask_mm_central, \"center_distance\"] +\n",
    "    0.4 * (\n",
    "        0.4 * gdf.loc[mask_mm_central, \"shop_min_m\"] +\n",
    "        0.3 * gdf.loc[mask_mm_central, \"shops_500m_ct\"] +\n",
    "        0.3 * gdf.loc[mask_mm_central, \"shops_800m_ct\"]\n",
    "    ) +\n",
    "    0.1 * gdf.loc[mask_mm_central, \"Laerm_index_tag\"]\n",
    ")\n",
    "\n",
    "# Kitas\n",
    "# Anders als kita_attribute (kein \"geometry\", was bei der Maskierung leere Zeilen von geometry rausschmeißen würde)\n",
    "mm_kita_score_vars = [\n",
    "    \"kitas_min_distance_m\",\n",
    "    \"kitas_count_within_500m\",\n",
    "    \"kitas_count_within_800m\",\n",
    "    \"kitas_count_within_1000m\"\n",
    "]\n",
    "mask_mm_kita = gdf[mm_kita_score_vars].notna().all(axis=1)\n",
    "gdf.loc[mask_mm_kita, \"score_kita\"] = (\n",
    "    0.5 * gdf.loc[mask_mm_kita, \"kitas_min_distance_m\"] +\n",
    "    0.2 * gdf.loc[mask_mm_kita, \"kitas_count_within_500m\"] +\n",
    "    0.2 * gdf.loc[mask_mm_kita, \"kitas_count_within_800m\"] +\n",
    "    0.1 * gdf.loc[mask_mm_kita, \"kitas_count_within_1000m\"]\n",
    ")\n",
    "\n",
    "# Grundschulen\n",
    "mm_grundschulen_score_vars = [\n",
    "    \"grundschulen_min_distance_m\",\n",
    "    \"grundschulen_count_within_500m\",\n",
    "    \"grundschulen_count_within_800m\",\n",
    "    \"grundschulen_count_within_1000m\"\n",
    "]\n",
    "mask_mm_grundschule = gdf[mm_grundschulen_score_vars].notna().all(axis=1)\n",
    "gdf.loc[mask_mm_grundschule, \"score_grundschule\"] = (\n",
    "    0.5 * gdf.loc[mask_mm_grundschule, \"grundschulen_min_distance_m\"] +\n",
    "    0.2 * gdf.loc[mask_mm_grundschule, \"grundschulen_count_within_500m\"] +\n",
    "    0.2 * gdf.loc[mask_mm_grundschule, \"grundschulen_count_within_800m\"] +\n",
    "    0.1 * gdf.loc[mask_mm_grundschule, \"grundschulen_count_within_1000m\"]\n",
    ")\n",
    "\n",
    "# Gesamt-Score (falls alle Teil-Scores vorhanden)\n",
    "score_all_vars = [\"score_central\", \"score_kita\", \"score_grundschule\", \"z_haltestelle_distance\", \"z_headway_score\"]\n",
    "mask_all_scores = gdf[score_all_vars].notna().all(axis=1)\n",
    "\n",
    "# Skalierte Kombination (je niedriger desto besser)\n",
    "gdf.loc[mask_all_scores, \"score_total\"] = (\n",
    "    0.4 * gdf.loc[mask_all_scores, \"score_central\"] +\n",
    "    0.15 * gdf.loc[mask_all_scores, \"score_kita\"] +\n",
    "    0.15 * gdf.loc[mask_all_scores, \"score_grundschule\"] +\n",
    "    0.15 * gdf.loc[mask_all_scores, \"z_haltestelle_distance\"] +\n",
    "    0.15 * gdf.loc[mask_all_scores, \"z_headway_score\"]\n",
    ")\n",
    "\n",
    "print(\"Anzahl gültiger Gesamt-Scores:\", gdf[\"score_total\"].notna().sum())\n",
    "print(gdf[score_all_vars].notna().sum().sort_values())\n",
    "\n",
    "all_input_vars = mm_central_score_vars + mm_kita_score_vars + mm_grundschulen_score_vars\n",
    "missing_counts = gdf[all_input_vars].isna().sum().sort_values(ascending=False)\n",
    "print(\"\")\n",
    "print(missing_counts)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b801c93497168622",
   "metadata": {},
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "z_vars = [\n",
    "    \"z_centrality\",\n",
    "    \"z_shop_distance\", \"z_shop_near_500\", \"z_shop_near_800\",\n",
    "    \"z_laerm_index_tag\",\n",
    "    \"z_kita_distance\", \"z_kita_near_500\", \"z_kita_near_800\", \"z_kita_near_1000\",\n",
    "    \"z_grundschul_distance\", \"z_grundschulen_near_500\", \"z_grundschulen_near_800\", \"z_grundschulen_near_1000\",\n",
    "    \"z_haltestelle_distance\", \"z_headway_score\",\n",
    "]\n",
    "X = gdf[z_vars].dropna().values\n",
    "\n",
    "inertia = []\n",
    "cluster_range = range(2, 11)  # Du kannst bis 15 hochgehen\n",
    "\n",
    "for k in cluster_range:\n",
    "    model = KMeans(n_clusters=k, random_state=42)\n",
    "    model.fit(X)\n",
    "    inertia.append(model.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(cluster_range, inertia, marker='o')\n",
    "plt.title(\"Elbow-Methode: KMeans-Inertia vs. Clusteranzahl\")\n",
    "plt.xlabel(\"Anzahl Cluster (k)\")\n",
    "plt.ylabel(\"Inertia (Distanz innerhalb der Cluster)\")\n",
    "plt.xticks(cluster_range)\n",
    "plt.grid(True)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "399ea032fbc29c17",
   "metadata": {},
   "source": [
    "# Silhouetten-Analyse\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouettes = []\n",
    "\n",
    "for k in cluster_range:\n",
    "    model = KMeans(n_clusters=k, random_state=42)\n",
    "    labels = model.fit_predict(X)\n",
    "    score = silhouette_score(X, labels, random_state=42)\n",
    "    silhouettes.append(score)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(cluster_range, silhouettes, marker='o', color=\"green\")\n",
    "plt.title(\"Silhouetten-Score pro Clusteranzahl\")\n",
    "plt.xlabel(\"Anzahl Cluster (k)\")\n",
    "plt.ylabel(\"Durchschn. Silhouetten-Koeffizient\")\n",
    "plt.xticks(cluster_range)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5356ceff36097c79",
   "metadata": {},
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X = gdf[z_vars].dropna().values  # Nur vollständige Zeilen\n",
    "\n",
    "model = KMeans(n_clusters=5, random_state=42).fit(X)\n",
    "\n",
    "mask_complete = gdf[z_vars].notna().all(axis=1)\n",
    "gdf.loc[mask_complete, \"cluster\"] = model.labels_\n",
    "\n",
    "cluster_centers = pd.DataFrame(model.cluster_centers_, columns=z_vars)\n",
    "cluster_centers.index.name = \"Cluster\"\n",
    "print(cluster_centers.round(2))\n",
    "\n",
    "\n",
    "# Visualisierung mit Dimension Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "X_scaled = X  # bereits Z-Scores → keine erneute Skalierung nötig\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=model.labels_, cmap=\"tab10\", alpha=0.6)\n",
    "plt.title(\"KMeans-Cluster (PCA 2D-Projektion)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6097678054722e03",
   "metadata": {},
   "source": [
    "import pandas as pd, folium\n",
    "\n",
    "gdf = gdf[gdf[\"lat\"].notna() & gdf[\"lon\"].notna() & gdf[\"cluster\"].notna()]\n",
    "gdf[\"cluster\"] = gdf[\"cluster\"].astype(int)\n",
    "\n",
    "# Farbpalette für 5 Cluster\n",
    "cluster_colors = {\n",
    "    0: \"#e41a1c\",   # Cluster 0 - rot\n",
    "    1: \"#377eb8\",   # Cluster 1 - blau\n",
    "    2: \"#4daf4a\",   # Cluster 2 - grün\n",
    "    3: \"#984ea3\",   # Cluster 3 - lila\n",
    "    4: \"#ff7f00\",   # Cluster 4 - orange\n",
    "    5: \"#666666\",\n",
    "    6: \"#a65628\",\n",
    "    7: \"#66cd2c\",\n",
    "    # Füge weitere hinzu falls nötig!\n",
    "}\n",
    "\n",
    "# Farben für Wohnlagen (grün - gelb)\n",
    "color_map = {\n",
    "    \"1 Top\":      \"#fee08b\",\n",
    "    \"2\":          \"#d9ef8b\",\n",
    "    \"3\":          \"#a6d96a\",\n",
    "    \"4\":          \"#66bd63\",\n",
    "    \"5 schwach\":  \"#1a9850\",\n",
    "}\n",
    "\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Add layer markers\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"data/einzelhandel_geocoded.csv\", color=\"blue\", icon=\"shopping-cart\", tooltip_format=(TOOLTIP_FORMAT), layer_name=\"Einzelhandel\")\n",
    "add_markers_from_csv( map_obj=m,csv_path=\"data/grundschulen_geocoded.csv\",color=\"green\",icon=\"graduation-cap\",layer_name=\"Grundschulen\")\n",
    "add_markers_from_csv(map_obj=m,csv_path=\"data/kitas_geocoded.csv\", color=\"beige\",icon=\"child\",layer_name=\"Kitas\")\n",
    "#add_markers_from_csv(map_obj=m,csv_path=\"data/haltestellen_geocoded.csv\",color=\"lightgray\", icon=\"bus\", layer_name=\"Haltestellen\")\n",
    "\n",
    "valid_kita_json = gdf_main[\"kitas_geometry\"].apply(lambda x: isinstance(x, str))\n",
    "print(\"Gültige JSON-Einträge:\", valid_kita_json.sum(), \"/\", len(gdf_main))\n",
    "\n",
    "for _, r in gdf.iterrows():\n",
    "    c = cluster_colors.get(r.cluster, \"#666666\")\n",
    "    folium.CircleMarker(\n",
    "        location=[r.lat, r.lon],\n",
    "        radius=3,\n",
    "        color=c,\n",
    "        fill=True,\n",
    "        fill_color=c,\n",
    "        fill_opacity=0.85,\n",
    "        tooltip=f\"{r.Straßenname} {r.Hsnr} – Cluster {r.cluster}\"\n",
    "    ).add_to(m)\n",
    "\n",
    "# Optional: Layer Control\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "print(gdf.shape)\n",
    "\n",
    "#m.save(\"wohnlagen_clusterkarte.html\")\n",
    "m"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4682611337ac7fa7",
   "metadata": {},
   "source": [
    "# Validierung"
   ]
  },
  {
   "cell_type": "code",
   "id": "2a006e046a8d03a",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "zscore_cols = [\n",
    "    \"z_centrality\",\n",
    "    \"z_shop_distance\",\n",
    "    \"z_laerm_index_tag\",\n",
    "    \"z_kita_distance\",\n",
    "    \"z_grundschul_distance\",\n",
    "    \"z_haltestelle_distance\",\n",
    "    \"z_headway_score\",\n",
    "    \"z_haltestellen_count_500\"\n",
    "]\n",
    "\n",
    "# Nur Spalten verwenden, die im gdf enthalten sind\n",
    "cols = [col for col in zscore_cols if col in gdf.columns]\n",
    "\n",
    "# Korrelationsmatrix berechnen\n",
    "corr = gdf[cols].corr()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, cmap=\"vlag\", center=0)\n",
    "plt.title(\"Korrelationsmatrix der Z-Scores\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9fae0eebad9d76ad",
   "metadata": {},
   "source": [
    "## Interaktive Karte für Bewertung einzelner Adressen"
   ]
  },
  {
   "cell_type": "code",
   "id": "e551b9ad6731ac78",
   "metadata": {},
   "source": [
    "import folium\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Widget für Adresseingabe\n",
    "text_input = widgets.Text(\n",
    "    value='Immenweg 56',\n",
    "    placeholder='Straßenname Hausnummer',\n",
    "    description='Adresse:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Button\n",
    "button = widgets.Button(description=\"Zeige Routen\")\n",
    "\n",
    "# Ausgabe-Bereich für die Karte\n",
    "output = widgets.Output()\n",
    "\n",
    "# Funktion zum Einfügen einer Route + Zielmarker\n",
    "def add_route(m, geojson_str, color, label, icon, distance=None):\n",
    "    if isinstance(geojson_str, str):\n",
    "        try:\n",
    "            geo = json.loads(geojson_str)\n",
    "            if geo.get(\"type\") == \"LineString\":\n",
    "                coords = [(y, x) for x, y in geo[\"coordinates\"]]\n",
    "                distance_text = f\" – {int(distance)} m\" if distance else \"\"\n",
    "                tooltip_text = f\"{label}{distance_text}\"\n",
    "\n",
    "                folium.PolyLine(\n",
    "                    locations=coords,\n",
    "                    color=color,\n",
    "                    weight=4,\n",
    "                    opacity=0.9,\n",
    "                    tooltip=tooltip_text\n",
    "                ).add_to(m)\n",
    "\n",
    "                end = coords[-1]\n",
    "                folium.Marker(\n",
    "                    location=end,\n",
    "                    icon=folium.Icon(color=color, icon=icon, prefix=\"fa\"),\n",
    "                    tooltip=f\"Ziel: {label}{distance_text}\"\n",
    "                ).add_to(m)\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler bei {label}: {e}\")\n",
    "\n",
    "# Funktion zum Anzeigen der Karte\n",
    "def show_routes(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        addr = text_input.value.strip().lower()\n",
    "\n",
    "        filtered = gdf_main[gdf_main[\"Adresse_merge\"].str.lower().str.contains(addr)]\n",
    "        if filtered.empty:\n",
    "            print(\"Keine Adresse gefunden.\")\n",
    "            return\n",
    "\n",
    "        row = filtered.iloc[0]\n",
    "        m = folium.Map(location=[row.lat, row.lon], zoom_start=15, tiles=\"cartodbpositron\")\n",
    "        folium.Marker(location=[row.lat, row.lon], tooltip=\"Adresse\").add_to(m)\n",
    "\n",
    "        # ▸ Routen einfügen\n",
    "        add_route(m, row.get(\"kitas_geometry\"), \"orange\", \"Nächste Kita\", \"child\", row.get(\"kitas_min_distance_m\"))\n",
    "        add_route(m, row.get(\"grundschulen_geometry\"), \"green\", \"Nächste Grundschule\", \"graduation-cap\", row.get(\"grundschulen_min_distance_m\"))\n",
    "        add_route(m, row.get(\"center_route\"), \"lightgray\", \"Weg zum Zentrum\", \"arrows-to-circle\", row.get(\"center_distance\"))\n",
    "        add_route(m, row.get(\"haltestellen_geometry\"), \"gray\", \"Nächste Haltestelle\", \"bus\", row.get(\"haltestellen_min_distance_m\"))\n",
    "\n",
    "        display(m)\n",
    "\n",
    "# Button-Event\n",
    "button.on_click(show_routes)\n",
    "\n",
    "# UI anzeigen\n",
    "display(text_input, button, output)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WohnlagenBRB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

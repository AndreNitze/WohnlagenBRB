{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e58eeaf9ab328ebb",
   "metadata": {},
   "source": [
    "# Datenvorbereitung\n",
    "Zun√§chst werden f√ºr alle gew√ºnschten Einflussfaktoren die Daten beschafft und in ein CSV-Format mit lat/lon oder GeoJSON-Geoemtry gebracht, sodass zu allen Adressen die gew√ºnschten Eigenschaften vorliegen."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from shapely.geometry import box\n",
    "\n",
    "from helper import load_geocsv, s, clean_index_cols\n",
    "\n",
    "EPSG_4326 = \"EPSG:4326\"\n",
    "\n",
    "# BBOX f√ºr Brandenburg an der Havel\n",
    "CITY_BOUNDING_BOX = box(12.3120236786, 52.2938432979, 12.7562682548, 52.5594777244)\n",
    "\n",
    "#  Stadtzentrum f√ºr Brandenburg an der Havel\n",
    "CITY_CENTER = (52.4116351153561, 12.556331280534392)"
   ],
   "id": "c50d60922d6f74cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Adressen einlesen\n",
    "Alle Adressen des Zielgebiets als CSV in einen GeoDataFrame einlesen."
   ],
   "id": "5112fadb5098e98"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gdf = load_geocsv(\"out/adressen_mit_zentrum_routen.csv\")\n",
    "\n",
    "# Adressen ohne Geometrie entfernen\n",
    "gdf = gdf[~gdf.geometry.isna()].copy()"
   ],
   "id": "ef79a64303652c4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Nutzungsart als Merkmal erg√§nzen\n",
    "One-Hot-Encoding f√ºr sp√§tere Modellierung der Bebauungsdichte / Nutzungsart der Adresse."
   ],
   "id": "fe2c80156cb02d38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "gdf_bebauung = gpd.read_file(\"data/Bebauungsdichte/2025_Bebauungsdichte.shp\")\n",
    "gdf_bebauung = gdf_bebauung.to_crs(EPSG_4326)\n",
    "\n",
    "gdf = gpd.sjoin(\n",
    "    gdf,                                    # Punkte\n",
    "    gdf_bebauung[[\"nutzart\", \"geometry\"]],  # Polygone + Nutzungsart\n",
    "    how=\"left\",\n",
    "    predicate=\"within\"                      # point-in-polygon\n",
    ")\n",
    "\n",
    "gdf[\"nutzart\"] = gdf[\"nutzart\"].fillna(\"Unbekannt\")\n"
   ],
   "id": "fe5b562211015fbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mapping = {\n",
    "    \"Wohnbaufl√§che\": \"Wohnen\",\n",
    "    \"Sport-, Freizeit- und Erholungsfl√§che\": \"Gruen\",\n",
    "    \"Fl√§che gemischter Nutzung\": \"Gemischt\",\n",
    "    \"Industrie- und Gewerbefl√§che\": \"Gewerbe\",\n",
    "    \"Stra√üenverkehr\": \"Verkehr\",\n",
    "    \"Weg\": \"Verkehr\",\n",
    "    \"Platz\": \"Verkehr\",\n",
    "    \"Friedhof\": \"Gruen\",\n",
    "    \"Wald\": \"Gruen\",\n",
    "    \"Fl√§che besonderer funktionaler Pr√§gung\": \"Sonstiges\",\n",
    "}\n",
    "\n",
    "# Neues zusammengefasstes Merkmal hinzuf√ºgen\n",
    "gdf[\"nutzklasse\"] = gdf[\"nutzart\"].map(mapping).fillna(\"Sonstiges\")\n",
    "\n",
    "# One-Hot-Encoding der Nutzungsklasse f√ºr numerische Verarbeitung\n",
    "# neu erzeugen\n",
    "gdf_onehot = pd.get_dummies(gdf[\"nutzklasse\"], prefix=\"nutz\", dtype=int)\n",
    "gdf = gdf.join(gdf_onehot)\n",
    "\n",
    "# Fl√§che berechnen (in Meter-CRS)\n",
    "gdf_bebauung_m = gdf_bebauung.to_crs(32633)\n",
    "gdf_bebauung[\"area_sqm\"] = gdf_bebauung_m.area\n",
    "\n",
    "# Klassifizierung NACH mapping\n",
    "gdf_bebauung[\"nutzklasse\"] = gdf_bebauung[\"nutzart\"].map(mapping).fillna(\"Sonstiges\")\n",
    "\n",
    "# Filter gro√üe Fl√§chen (Schwellwert flexibel)\n",
    "MIN_AREA = 30000\n",
    "gdf_large = gdf_bebauung[gdf_bebauung[\"area_sqm\"] > MIN_AREA].copy()\n",
    "gdf\n"
   ],
   "id": "24f82d6f2ca4b91a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Farben f√ºr jede nutzklasse\n",
    "klassen = gdf_large[\"nutzklasse\"].unique()\n",
    "cmap = plt.colormaps[\"Set2\"]\n",
    "colors = {k: mcolors.to_hex(cmap(i / len(klassen))) for i, k in enumerate(klassen)}\n",
    "\n",
    "# Karte initialisieren\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"OpenStreetMap\")\n",
    "\n",
    "# Ein Layer pro Klasse anlegen\n",
    "layer_map = {}\n",
    "for k in klassen:\n",
    "    layer = folium.FeatureGroup(name=f\"Gro√üe {k}-Fl√§chen (> {MIN_AREA} m¬≤)\", show=True)\n",
    "    layer_map[k] = layer\n",
    "    m.add_child(layer)\n",
    "\n",
    "# Gro√üe Fl√§chen einzeichnen\n",
    "# Transformieren\n",
    "gdf_large_4326 = gdf_large.to_crs(4326)\n",
    "\n",
    "# Vereinfachung (wichtig f√ºr Performance!)\n",
    "gdf_large_4326[\"geometry\"] = gdf_large_4326.geometry.simplify(\n",
    "    tolerance=0.0002,  # ~20 m\n",
    "    preserve_topology=True\n",
    ")\n",
    "\n",
    "\n",
    "for _, row in gdf_large_4326.iterrows():\n",
    "    kls = row[\"nutzklasse\"]\n",
    "    layer = layer_map[kls]\n",
    "\n",
    "    folium.GeoJson(\n",
    "        row.geometry,\n",
    "        style_function=lambda x, k=kls: {\n",
    "            'color': 'black',\n",
    "            'weight': 1,\n",
    "            'fillColor': colors[k],\n",
    "            'fillOpacity': 0.6\n",
    "        },\n",
    "        tooltip=folium.Tooltip(\n",
    "            f\"<b>{row['bez']}</b><br>\"\n",
    "            f\"{kls}<br>\"\n",
    "            f\"Fl√§che: {row['area_sqm']:.0f} m¬≤\"\n",
    "        )\n",
    "    ).add_to(layer)\n",
    "\n",
    "# LayerControl aktivieren\n",
    "folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "# open map in browser\n",
    "m"
   ],
   "id": "bf01154dea7a2cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Explorative Datenanalyse",
   "id": "d082da0d61c0f1d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns           # nur f√ºr sch√∂nere Plots\n",
    "from helper import load_geocsv, make_merge_addr\n",
    "\n",
    "# Eindeutigen Merge-baren String aus Adresse erzeugen\n",
    "gdf[\"Adresse_merge\"] = gdf.apply(make_merge_addr, axis=1)\n",
    "\n",
    "gdf = gdf.rename(columns={\"geojson\": \"center_route\",\n",
    "                                    \"distance_m\" : \"center_distance_m\"})\n",
    "\n",
    "# Ein paar unben√∂tigte Spalten entfernen\n",
    "gdf = gdf.drop(columns=[\"index_right\", \"duration_s\", \"display_name\", \"type\", \"category\", \"Adresse_query\"], errors=\"ignore\")\n",
    "\n",
    "# Histogramm der Distanzen zum Zentrum\n",
    "plt.figure(figsize=(6,3))\n",
    "sns.histplot(gdf[\"center_distance_m\"], bins=60, kde=False)\n",
    "plt.title(\"Verteilung der Fu√üentfernung zum Zentrum\")\n",
    "plt.xlabel(\"Distanz (Meter)\")\n",
    "plt.ylabel(\"H√§ufigkeit\")\n",
    "plt.show()\n",
    "print(gdf.shape)\n",
    "print(gdf.columns)"
   ],
   "id": "de62fa81b281925b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Daten bereinigen",
   "id": "f14dc6214657a08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(gdf.shape)\n",
    "# Dubletten aus Adressen entfernen\n",
    "dups = gdf[\"Adresse_merge\"].value_counts()\n",
    "dups = dups[dups > 1]\n",
    "print(f\"{len(dups)} doppelte Adressen gefunden\")\n",
    "print(dups.head())\n",
    "\n",
    "# Ersten Treffer behalten\n",
    "gdf = gdf.sort_values(\"Adresse_merge\").drop_duplicates(\"Adresse_merge\", keep=\"first\")\n",
    "print(gdf.shape)\n"
   ],
   "id": "af2201946c11980d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Einzelhandel\n",
    "Separates Skript ```einzelhandel-adressen.py``` ausf√ºhen, um Datei \"adressen_mit_einzelhandel.csv\" zu erzeugen.\n",
    "Durch fu√ül√§ufiges Routing berechnete Faktoren:\n",
    "- Anzahl von Einkaufsm√∂glichkeiten im Umkreis von 500 m\n",
    "- Anzahl von Einkaufsm√∂glichkeiten im Umkreis von 800 m\n",
    "- Geringste Distanz zum n√§chsten Einzelhandel"
   ],
   "id": "fb6d05a628d926b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns, matplotlib.pyplot as plt\n",
    "\n",
    "# Lade vorberechnete Einzelhandel-Faktoren\n",
    "gdf_retail = load_geocsv(\"out/adressen_mit_einzelhandel_routen.csv\")\n",
    "\n",
    "# Merge mit Haupt-GDF\n",
    "gdf_retail[\"Adresse_merge\"] = gdf_retail.apply(make_merge_addr, axis=1)\n",
    "gdf_retail = gdf_retail.sort_values(\"Adresse_merge\").drop_duplicates(\"Adresse_merge\", keep=\"first\")\n",
    "\n",
    "dups = gdf_retail[\"Adresse_merge\"].value_counts()\n",
    "print(dups[dups > 1])\n",
    "\n",
    "einzelhandel_attribute = [\"einzelhandel_route\",\"einzelhandel_min_distance_m\", \"einzelhandel_500m_count\", \"einzelhandel_800m_count\", \"einzelhandel_1000m_count\"]\n",
    "\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_retail[[\"Adresse_merge\"] + einzelhandel_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "print(gdf.shape)\n",
    "print(gdf[[\"Adresse_merge\", \"einzelhandel_min_distance_m\"]].head())\n",
    "\n",
    "print(gdf.shape)\n",
    "\n",
    "# Speicher freigeben\n",
    "del(gdf_retail)"
   ],
   "id": "14c882fa9c070677",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Verteilung Distanz zum n√§chsten Markt\n",
    "print(gdf.columns)\n",
    "sns.histplot(gdf[\"einzelhandel_min_distance_m\"].dropna(), bins=40, kde=False)\n",
    "plt.title(\"Distanz zum n√§chsten Lebensmittel¬≠markt\")\n",
    "plt.xlabel(\"Meter Fu√üweg\"); plt.ylabel(\"Adressen\")\n",
    "plt.show()\n",
    "\n",
    "# Scatter Zentralit√§t vs. Nahversorgung\n",
    "sns.scatterplot(x=\"center_distance_m\", y=\"einzelhandel_min_distance_m\", data=gdf, alpha=.3)\n",
    "plt.xlabel(\"Distanz Zentrum (m)\"); plt.ylabel(\"Distanz n√§chster Markt (m)\")\n",
    "plt.show()"
   ],
   "id": "2425ee38a7ebf529",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## L√§rmbelastung\n",
    "Siehe ```laerm.ipynb``` zur Erzeugung, ansonsten einfach ```data/adressen_mit_laerm.csv``` verwenden und per Spalte 'geometry' verschneiden.\n",
    "\n",
    "Definition L√§rm-Index:\n",
    "- NaN / leer: kein gemessener Stra√üenl√§rm\n",
    "- 0: 55 - 59 dB\n",
    "- 1: 60 - 64 dB\n",
    "- 2: 65 - 69 dB\n",
    "- 3: 70 - 74 dB\n",
    "- 4: >= 75 db"
   ],
   "id": "d0c2655c478327a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gdf_laerm_karte = load_geocsv(\"out/adressen_mit_laerm.csv\")\n",
    "print(gdf_laerm_karte.shape)\n",
    "print(gdf.shape)\n",
    "\n",
    "# Merge des L√§rmindex mit Haupt-GDF\n",
    "gdf_laerm_karte[\"Adresse_merge\"] = gdf_laerm_karte.apply(make_merge_addr, axis=1)\n",
    "gdf_laerm_karte[\"laerm_index_tag\"] = gdf_laerm_karte[\"Laerm_index_tag\"].fillna(-0.1) # lowercase\n",
    "\n",
    "# Deduplicate, im Zweifel nimm den lautesten Wert\n",
    "gdf_laerm_karte = (\n",
    "    gdf_laerm_karte\n",
    "    .sort_values(\"laerm_index_tag\", ascending=False)\n",
    "    .drop_duplicates(\"Adresse_merge\", keep=\"first\")\n",
    ")\n",
    "\n",
    "laerm_attribute = [\"laerm_index_tag\"]\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_laerm_karte[[\"Adresse_merge\"] + laerm_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "\n",
    "#print(gdf.columns)\n",
    "print(gdf.shape)"
   ],
   "id": "f991ebcdf50656b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Bildung\n",
    "Weitere Faktoren\n",
    "- Fu√ül√§ufige Entfernung zur n√§chstgelegenen Kita\n",
    "- Fu√ül√§ufige Entfernung zur n√§chstgelegenen Schule\n",
    "- Anzahl Kitas im Umkreis von 500, 800 und 1000 Metern\n",
    "- Anzahl Schulen im Umkreis von 500, 800 und 1000 Metern"
   ],
   "id": "87cef8c157d06d58"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Daten als GeoDataFrame einlesen\n",
    "gdf_kitas = load_geocsv(\"out/adressen_mit_kitas_routen.csv\")\n",
    "gdf_grundschulen = load_geocsv(\"out/adressen_mit_grundschulen_routen.csv\")\n",
    "print(gdf_kitas.shape)\n",
    "print(gdf_grundschulen.shape)\n",
    "print(gdf.shape)\n",
    "\n",
    "# Eindeutige Adresse f√ºr den Merge generieren\n",
    "gdf_kitas[\"Adresse_merge\"] = gdf_kitas.apply(make_merge_addr, axis=1)\n",
    "gdf_kitas = gdf_kitas.drop_duplicates(\"Adresse_merge\")\n",
    "gdf_grundschulen[\"Adresse_merge\"] = gdf_grundschulen.apply(make_merge_addr, axis=1)\n",
    "gdf_grundschulen = gdf_grundschulen.drop_duplicates(\"Adresse_merge\")\n",
    "\n",
    "# Merge into main gdf\n",
    "kitas_attribute = [\"kitas_min_distance_m\", \"kitas_route\", \"kitas_count_within_500m\", \"kitas_count_within_800m\", \"kitas_count_within_1000m\"]\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_kitas[[\"Adresse_merge\"] + kitas_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "\n",
    "grundschulen_attribute = [\"grundschulen_min_distance_m\", \"grundschulen_route\", \"grundschulen_count_within_500m\", \"grundschulen_count_within_800m\", \"grundschulen_count_within_1000m\"]\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_grundschulen[[\"Adresse_merge\"] + grundschulen_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "\n",
    "print(gdf.columns)\n",
    "print(gdf.shape)"
   ],
   "id": "f3a118199fb1be23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Medizinische Versorgung\n",
    "Ein \"medizinisches Zentrum\" wurde definiert als eine Apotheke mit zwei √Ñrzten im Umkreis von 100 Metern. Diese Zentren werden separat in ```medizinische-zentren.py``` berechnet. Dazu wird die euklidische Distanz (\"Luftlinie\") zwischen Apotheken und umgebenden √Ñrzten berechnet.\n",
    "Dadurch entstehen f√ºr den Datensatz folgende neue Attribute:\n",
    "- Anzahl von medizinischen Zentren im Umkreis von 500 m\n",
    "- Anzahl von medizinischen Zentren im Umkreis von 800 m\n",
    "- Anzahl von medizinischen Zentren im Umkreis von 1000 m\n",
    "- Fu√ül√§ufige Distanz zum n√§chsten medizinischen Zentrum\n",
    "\n",
    "Die vollst√§ndige Erkl√§rung der Felder findet sich im Anhang.\n",
    "\n",
    "Die fu√ül√§ufige Distanz zum n√§chstgelegenen medizinischen Zentrum wird per ```routing.py``` f√ºr jede Adresse einzeln ermittelt und als Weg gespeichert (```out/adressen_mit_medzentren_routen.csv```)."
   ],
   "id": "a8b3a7b9ddd38f8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import ast\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 1) Daten laden\n",
    "# ------------------------------------------------------\n",
    "df_centers = pd.read_csv(\"out/medzentren_geocoded.csv\")\n",
    "df_arzte = pd.read_csv(\"out/aerzte_geocoded.csv\")\n",
    "\n",
    "# Normalize boolean\n",
    "df_centers[\"is_med_center\"] = (\n",
    "    df_centers[\"is_med_center\"].astype(str).str.lower().isin([\"true\", \"1\", \"yes\", \"y\"])\n",
    ")\n",
    "\n",
    "# Arztname ‚Üí Fachrichtung Mapping\n",
    "arzt_fach_map = (\n",
    "    df_arzte\n",
    "    .dropna(subset=[\"Name_Arztpraxis\"])\n",
    "    .set_index(\"Name_Arztpraxis\")[\"Fachrichtung\"]\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Robust: arzt_keys_100m kann String-List, echte Liste oder leer sein\n",
    "def parse_arzt_list(value):\n",
    "    if isinstance(value, list):\n",
    "        return value\n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            return ast.literal_eval(value)\n",
    "        except Exception:\n",
    "            # fallback: split by comma\n",
    "            return [v.strip() for v in value.split(\",\") if v.strip()]\n",
    "    return []\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 2) Popup Builder\n",
    "# ------------------------------------------------------\n",
    "def build_popup(row):\n",
    "    lines = []\n",
    "\n",
    "    # Titel\n",
    "    if bool(row[\"is_med_center\"]):\n",
    "        lines.append(\n",
    "            f\"<b>Medizinisches Zentrum<br>{row.get('Strassenname','')}</b><br>\"\n",
    "        )\n",
    "\n",
    "    # Apotheken-Name\n",
    "    apo = str(row.get(\"Name_Apotheke\", \"\")).strip()\n",
    "    if apo:\n",
    "        lines.append(f\"üè• {apo}<br>\")\n",
    "\n",
    "    # √Ñrzte im Umkreis (Liste aufl√∂sen)\n",
    "    arzt_list = parse_arzt_list(row.get(\"arzt_keys_100m\", []))\n",
    "\n",
    "    if len(arzt_list) > 0:\n",
    "        lines.append(f\"<b>{len(arzt_list)}</b> Arztpraxen im 100 m Radius:\")\n",
    "\n",
    "        # Fachrichtungen bestimmen\n",
    "        fachrichtungen = []\n",
    "        for name in arzt_list:\n",
    "            fr = arzt_fach_map.get(name)\n",
    "            if fr:\n",
    "                fachrichtungen.append(f\"{name} ‚Äì {fr}\")\n",
    "            else:\n",
    "                fachrichtungen.append(f\"{name} ‚Äì (Fachrichtung unbekannt)\")\n",
    "\n",
    "        # als Liste anzeigen\n",
    "        lines.append(\"<ul>\" + \"\".join([f\"<li>{f}</li>\" for f in fachrichtungen]) + \"</ul>\")\n",
    "\n",
    "    else:\n",
    "        lines.append(\"Keine √Ñrzte im 100 m Radius gefunden.\")\n",
    "\n",
    "    return \"<br>\".join(lines)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3) Icon Auswahl\n",
    "# ------------------------------------------------------\n",
    "def pick_icon(row):\n",
    "    if bool(row[\"is_med_center\"]):\n",
    "        return folium.Icon(color=\"green\", icon=\"plus-sign\", prefix=\"glyphicon\")\n",
    "    else:\n",
    "        return folium.Icon(color=\"gray\", icon=\"staff-snake\", prefix=\"fa\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 4) Karte rendern\n",
    "# ------------------------------------------------------\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=14)\n",
    "cluster = MarkerCluster(name=\"Medizinische Zentren / Apotheken\")\n",
    "cluster.add_to(m)\n",
    "\n",
    "for _, row in df_centers.iterrows():\n",
    "\n",
    "    lat = row.get(\"lat\")\n",
    "    lon = row.get(\"lon\")\n",
    "\n",
    "    if pd.isna(lat) or pd.isna(lon):\n",
    "        continue\n",
    "\n",
    "    popup_html = build_popup(row)\n",
    "    icon = pick_icon(row)\n",
    "\n",
    "    marker = folium.Marker(\n",
    "        location=[lat, lon],\n",
    "        tooltip=row.get(\"Strassenname\", \"MedZentrum\"),\n",
    "        icon=icon,\n",
    "    ).add_to(cluster)\n",
    "    marker.add_child(folium.Popup(popup_html, max_width=450))\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "m\n"
   ],
   "id": "a4533f83433b8618",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Medizinische Felder in gdf √ºbernehmen\n",
    "# 1. Routing-Ergebnis f√ºr medizinische Versorgung laden\n",
    "gdf_med = load_geocsv(\"out/adressen_mit_medzentren_routen.csv\")\n",
    "print(\"gdf_med shape:\", gdf_med.shape)\n",
    "print(\"gdf shape (vor Merge):\", gdf.shape)\n",
    "\n",
    "# 2. Merge-Key bauen (Adresse normalisieren)\n",
    "gdf_med[\"Adresse_merge\"] = gdf_med.apply(make_merge_addr, axis=1)\n",
    "gdf_med = gdf_med.drop_duplicates(\"Adresse_merge\")\n",
    "\n",
    "# 3. Relevante Attributspalten aus der medizinischen Versorgung definieren\n",
    "medzentren_attribute = [\n",
    "    \"medzentren_min_distance_m\",\n",
    "    \"medzentren_route\",\n",
    "    \"medzentren_count_within_500m\",\n",
    "    \"medzentren_count_within_800m\",\n",
    "    \"medzentren_count_within_1000m\",\n",
    "]\n",
    "\n",
    "# 4. Merge in Haupt-GDF\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_med[[\"Adresse_merge\"] + medzentren_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_one\",\n",
    ")\n",
    "\n",
    "print(\"gdf shape (nach Merge):\", gdf.shape)"
   ],
   "id": "2e57b491ca5f7e24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## √ñPNV-Qualit√§t\n",
    "\n",
    "Die Qualit√§t des √ñPNV wird anhand der Fu√ül√§ufigkeit zur n√§chsten Haltestelle und der H√§ufigkeit von Abfahrten (Headway) bewertet. Die Daten stammen vom Verkehrsverbund Berlin-Brandenburg (VBB), Lizenz: CC BY 4.0, [zu den Daten](https://unternehmen.vbb.de/digitale-services/datensaetze).\n",
    "\n",
    "Vorausgesetzte Datens√§tze:\n",
    "- ```data/GTFS/stops.txt```, der die Haltestellen mit ihren Geokoordinaten enth√§lt.\n",
    "- ```data/adressen_mit_haltestellen_routen.csv```, der die Routen zu den Haltestellen und Anzahl von Haltestellen im Radius 500m und 800m enth√§lt.\n",
    "\n",
    "Probleme mit Datenqualit√§t:\n",
    "- In der \"2024_Haltestellen.csv\" fehlen die Haltestellen \"Libellenweg\" und \"Immenweg\" (Linie B). Dadurch werden diese Haltestellen nicht ber√ºcksichtigt und Wege zur n√§chsten Haltestelle werden l√§nger eingesch√§tzt."
   ],
   "id": "97d042d0ef303f6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from shapely.geometry import Point\n",
    "\n",
    "# Load GTFS stops data\n",
    "stops = pd.read_csv(\"data/GTFS/stops.txt\")\n",
    "stops[\"geometry\"] = stops.apply(lambda row: Point(row[\"stop_lon\"], row[\"stop_lat\"]), axis=1)\n",
    "gdf_stops = gpd.GeoDataFrame(stops, geometry=\"geometry\", crs=EPSG_4326)\n",
    "\n",
    "# Convert to UTM for precise metric distance calculations\n",
    "gdf = gdf.to_crs(epsg=32633)\n",
    "gdf_stops = gdf_stops.to_crs(epsg=32633)\n",
    "\n",
    "# Assign nearest stop to each address based on Point(X, Y) geometry\n",
    "gdf[\"nearest_stop_id\"] = gdf.geometry.apply(\n",
    "    lambda pt: gdf_stops.loc[gdf_stops.distance(pt).idxmin(), \"stop_id\"]\n",
    ")\n",
    "\n",
    "# Read routes from adresses to stops and stop count from prepared CSV\n",
    "gdf_haltestellen = load_geocsv(\"out/adressen_mit_haltestellen_routen.csv\")\n",
    "gdf_haltestellen[\"Adresse_merge\"] = gdf_haltestellen.apply(make_merge_addr, axis=1)\n",
    "gdf_haltestellen = gdf_haltestellen.drop_duplicates(\"Adresse_merge\").copy()\n",
    "\n",
    "print(\"gdf_haltestellen shape:\", gdf_haltestellen.shape)\n",
    "print(\"gdf shape (vor Merge):\", gdf.shape)\n",
    "\n",
    "# Merge haltestellen attributes into main GeoDataFrame\n",
    "haltestellen_attribute = [\"haltestellen_route\", \"haltestellen_min_distance_m\", \"haltestellen_count_within_500m\", \"haltestellen_count_within_800m\"]\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_haltestellen[[\"Adresse_merge\"] + haltestellen_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_one\"\n",
    ")\n",
    "\n",
    "print(\"gdf shape (nach Merge):\", gdf.shape)"
   ],
   "id": "b032c3c18de695a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Berechnung der √ñPNV-Taktung",
   "id": "9b1c9bc9b0c3c80d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. GTFS laden\n",
    "# -------------------------------------------------\n",
    "stops = pd.read_csv(\"data/GTFS/stops.txt\")\n",
    "stop_times = pd.read_csv(\"data/GTFS/stop_times.txt\", low_memory=False)\n",
    "trips = pd.read_csv(\"data/GTFS/trips.txt\")\n",
    "calendar = pd.read_csv(\"data/GTFS/calendar.txt\")  # behalten wir f√ºr evtl. sp√§tere Filter\n",
    "# optional:\n",
    "# calendar_dates = pd.read_csv(\"data/GTFS/calendar_dates.txt\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Zeitspalte -> Minuten ab Mitternacht\n",
    "# -------------------------------------------------\n",
    "def parse_time_to_minutes(t):\n",
    "    if pd.isna(t):\n",
    "        return None\n",
    "    parts = str(t).split(\":\")\n",
    "    if len(parts) == 2:\n",
    "        h, m = parts\n",
    "    elif len(parts) == 3:\n",
    "        h, m, _s = parts\n",
    "    else:\n",
    "        return None\n",
    "    try:\n",
    "        h = int(h)\n",
    "        m = int(m)\n",
    "        return h * 60 + m\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "stop_times = stop_times.copy()\n",
    "stop_times[\"minutes\"] = stop_times[\"arrival_time\"].apply(parse_time_to_minutes)\n",
    "stop_times = stop_times.dropna(subset=[\"minutes\"])\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3. Wir interessieren uns f√ºr HVZ-Fenster\n",
    "#    Wir extrahieren NUR Stop-Zeiten, die √ºberhaupt in diesen Fenstern liegen.\n",
    "#    Damit behalten wir reale Pendlerfahrten selbst dann,\n",
    "#    wenn calendar.monday == 0 gesagt h√§tte.\n",
    "# -------------------------------------------------\n",
    "\n",
    "HVZ_WINDOWS = [\n",
    "    (360, 540),   # 06:00‚Äì09:00\n",
    "    (960, 1140),  # 16:00‚Äì19:00\n",
    "]\n",
    "\n",
    "def in_any_window(mins, windows):\n",
    "    for lo, hi in windows:\n",
    "        if lo <= mins <= hi:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "stop_times_hvz = stop_times[stop_times[\"minutes\"].apply(lambda mm: in_any_window(mm, HVZ_WINDOWS))].copy()\n",
    "\n",
    "# 3. Filter nur auf werkt√§gliche Dienste\n",
    "trips_filtered = trips.merge(calendar, on=\"service_id\")\n",
    "trips_filtered = trips_filtered[trips_filtered[\"monday\"] == 1]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4. stop_times_hvz ‚Üî trips (route_id etc.)\n",
    "# -------------------------------------------------\n",
    "trips[\"trip_id\"] = trips[\"trip_id\"].astype(str)\n",
    "\n",
    "stop_times_hvz[\"trip_id\"] = stop_times_hvz[\"trip_id\"].astype(str)\n",
    "\n",
    "stopdata = stop_times_hvz.merge(\n",
    "    trips[[\"trip_id\", \"route_id\", \"service_id\"]],\n",
    "    on=\"trip_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 5. Haltestellengeometrie + Clusterbildung (DBSCAN)\n",
    "# -------------------------------------------------\n",
    "stops = stops.copy()\n",
    "stops[\"stop_id\"] = stops[\"stop_id\"].astype(str)\n",
    "\n",
    "gdf_stops_all = gpd.GeoDataFrame(\n",
    "    stops,\n",
    "    geometry=gpd.points_from_xy(stops[\"stop_lon\"], stops[\"stop_lat\"]),\n",
    "    crs=EPSG_4326\n",
    ")\n",
    "\n",
    "gdf_stops_metric = gdf_stops_all.to_crs(epsg=25833).copy()\n",
    "coords = np.vstack([\n",
    "    gdf_stops_metric.geometry.x.values,\n",
    "    gdf_stops_metric.geometry.y.values\n",
    "]).T\n",
    "\n",
    "db = DBSCAN(eps=100, min_samples=1).fit(coords)\n",
    "gdf_stops_all[\"pt_cluster_id\"] = db.labels_.astype(int)\n",
    "\n",
    "stop_to_cluster = dict(zip(gdf_stops_all[\"stop_id\"], gdf_stops_all[\"pt_cluster_id\"]))\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 6. Cluster-ID an stopdata h√§ngen\n",
    "# -------------------------------------------------\n",
    "stopdata[\"stop_id\"] = stopdata[\"stop_id\"].astype(str)\n",
    "stopdata[\"pt_cluster_id\"] = stopdata[\"stop_id\"].map(stop_to_cluster)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 7. Headway je Cluster berechnen\n",
    "#    jetzt auf Basis ALLER HVZ-Fahrten, die tats√§chlich vorkommen,\n",
    "#    statt nur calendar.monday==1\n",
    "# -------------------------------------------------\n",
    "def compute_headway_for_window(df, lo, hi, group_col=\"pt_cluster_id\", time_col=\"minutes\"):\n",
    "    result = {}\n",
    "    for clus, group in df.groupby(group_col):\n",
    "        if pd.isna(clus):\n",
    "            continue\n",
    "        # nur Zeiten im Fenster\n",
    "        times = sorted([t for t in group[time_col] if lo <= t <= hi])\n",
    "        if len(times) < 2:\n",
    "            continue\n",
    "        diffs = [b - a for a, b in zip(times, times[1:])]\n",
    "        result[clus] = sum(diffs) / len(diffs)\n",
    "    return result\n",
    "\n",
    "headway_morning = compute_headway_for_window(stopdata, 360, 540)\n",
    "headway_evening = compute_headway_for_window(stopdata, 960, 1140)\n",
    "\n",
    "df_hm = (\n",
    "    pd.DataFrame.from_dict(headway_morning, orient=\"index\", columns=[\"headway_morning\"])\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"pt_cluster_id\"})\n",
    ")\n",
    "df_he = (\n",
    "    pd.DataFrame.from_dict(headway_evening, orient=\"index\", columns=[\"headway_evening\"])\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"pt_cluster_id\"})\n",
    ")\n",
    "\n",
    "df_headways = df_hm.merge(df_he, on=\"pt_cluster_id\", how=\"outer\", validate=\"one_to_one\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 8. Merge in gdf\n",
    "# -------------------------------------------------\n",
    "gdf[\"nearest_stop_id\"] = gdf[\"nearest_stop_id\"].astype(str)\n",
    "gdf[\"pt_cluster_id\"] = gdf[\"nearest_stop_id\"].map(stop_to_cluster)\n",
    "\n",
    "# weg mit alten Spalten falls rerun\n",
    "for col in [\n",
    "    \"headway_morning\", \"headway_evening\", \"headway_avg\",\n",
    "    \"headway_morning_score_fixed\", \"headway_evening_score_fixed\",\n",
    "    \"headway_avg_score_fixed\",\n",
    "]:\n",
    "    if col in gdf.columns:\n",
    "        gdf = gdf.drop(columns=[col])\n",
    "\n",
    "gdf = gdf.merge(\n",
    "    df_headways,\n",
    "    on=\"pt_cluster_id\",\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 9. Kennzahlen\n",
    "# -------------------------------------------------\n",
    "for col in [\"headway_morning\", \"headway_evening\"]:\n",
    "    gdf[col] = pd.to_numeric(gdf[col], errors=\"coerce\")\n",
    "\n",
    "gdf[\"headway_avg\"] = gdf[[\"headway_morning\", \"headway_evening\"]].mean(axis=1)\n",
    "\n",
    "fixed_min, fixed_max = 5, 60\n",
    "def scoreify(series):\n",
    "    return 1 - ((series - fixed_min) / (fixed_max - fixed_min)).clip(lower=0, upper=1)\n",
    "\n",
    "gdf[\"headway_morning_score_fixed\"] = scoreify(gdf[\"headway_morning\"])\n",
    "gdf[\"headway_evening_score_fixed\"] = scoreify(gdf[\"headway_evening\"])\n",
    "gdf[\"headway_avg_score_fixed\"]     = scoreify(gdf[\"headway_avg\"])\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 10. Debug neu\n",
    "# -------------------------------------------------\n",
    "no_headway_mask = gdf[\"headway_avg\"].isna()\n",
    "\n",
    "print(\"Adressen ohne Headway_avg:\", int(no_headway_mask.sum()))\n",
    "\n",
    "na_clusters = (\n",
    "    gdf.loc[no_headway_mask, \"pt_cluster_id\"]\n",
    "    .value_counts()\n",
    ")\n",
    "print(\"Problem-Cluster:\", len(na_clusters))\n",
    "print(na_clusters.head(20))\n",
    "\n",
    "# sicherstellen, dass wir wirklich noch Stops ohne Window-Fahrten haben\n",
    "clusters_with_headway = set(df_headways[\"pt_cluster_id\"].tolist())\n",
    "clusters_without = [cid for cid in gdf[\"pt_cluster_id\"].dropna().unique()\n",
    "                    if cid not in clusters_with_headway]\n",
    "print(\"Cluster ohne Eintrag in df_headways:\", len(clusters_without))\n",
    "print(clusters_without[:20])\n",
    "\n",
    "# Spot-check: nimm den gr√∂√üten Problem-Cluster\n",
    "if len(clusters_without) > 0:\n",
    "    test_cluster = clusters_without[0]\n",
    "    sample_times = stopdata.loc[stopdata[\"pt_cluster_id\"] == test_cluster, \"minutes\"]\n",
    "    print(\"Beispiel-Cluster\", test_cluster, \"HVZ Zeiten:\",\n",
    "          sorted([t for t in sample_times if 360 <= t <= 540])[:20])\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 11. Debug: Wo fehlen noch Headways?\n",
    "# -------------------------------------------------\n",
    "no_headway_mask = gdf[\"headway_avg\"].isna()\n",
    "\n",
    "print(\"Adressen ohne Headway_avg:\", int(no_headway_mask.sum()))\n",
    "\n",
    "# Welche Stop-IDs sind schuld, nach nearest_stop_id\n",
    "na_stops = (\n",
    "    gdf.loc[no_headway_mask, \"nearest_stop_id\"]\n",
    "    .value_counts()\n",
    ")\n",
    "print(\"Anzahl unterschiedlicher problematischer Haltestellen (Steig-Ebene):\", len(na_stops))\n",
    "print(na_stops.head(20))\n",
    "\n",
    "# Welche Cluster sind schuld\n",
    "na_clusters = (\n",
    "    gdf.loc[no_headway_mask, \"pt_cluster_id\"]\n",
    "    .value_counts()\n",
    ")\n",
    "print(\"Anzahl problematischer Cluster:\", len(na_clusters))\n",
    "print(na_clusters.head(20))\n",
    "\n",
    "# Pr√ºfen, ob diese Cluster √ºberhaupt Headways in df_headways haben\n",
    "clusters_with_headway = set(df_headways[\"pt_cluster_id\"].astype(int).tolist())\n",
    "clusters_without = [cid for cid in na_clusters.index if cid not in clusters_with_headway]\n",
    "print(\"Cluster ohne Eintrag in df_headways:\", len(clusters_without))\n",
    "print(clusters_without[:20])\n",
    "\n",
    "# Sanity check: f√ºr einen der Top-Cluster, zeig alle Abfahrtszeiten morgens\n",
    "if len(clusters_without) > 0:\n",
    "    test_cluster = clusters_without[0]\n",
    "    sample_times = stopdata.loc[stopdata[\"pt_cluster_id\"] == test_cluster, \"minutes\"]\n",
    "    print(\"Beispiel-Cluster\", test_cluster, \"hat morgens Zeiten in 6-9?:\",\n",
    "          sample_times[(sample_times>=360)&(sample_times<=540)].sort_values().head(20).tolist())\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 12. Cleanup (optional)\n",
    "# -------------------------------------------------\n",
    "#del(stop_times, trips, calendar, trips_filtered,\n",
    "#    stopdata, df_hm, df_he, df_headways,\n",
    "#    gdf_stops_metric, coords, db)\n"
   ],
   "id": "ad2f3fdb3ae58eb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# √ñPMV in gdf mergen\n",
    "headway_attribute = [\"headway_avg\"]"
   ],
   "id": "a1e92bc343809d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualisierung der √ñPNV-Taktung",
   "id": "f3be44369f64d5db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "from branca.colormap import linear, LinearColormap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Convert gdf_stops geometry to WGS84\n",
    "gdf_stops = gdf_stops.to_crs(epsg=4326).copy()\n",
    "\n",
    "# Haltestellen innerhalb Stadt\n",
    "gdf_stops_clip = gdf_stops[gdf_stops.geometry.within(CITY_BOUNDING_BOX)].copy()\n",
    "print(\"Haltestellen im Stadtpolygon:\", len(gdf_stops_clip))\n",
    "\n",
    "#\n",
    "# 2. Farbskala nur aus Adressen-Headway\n",
    "#\n",
    "# headway_avg = durchschnittliche Taktzeit (Minuten) f√ºr diese Adresse\n",
    "# Annahme: kleiner Wert = besser (h√§ufigere Bedienung)\n",
    "addr_headway = pd.to_numeric(gdf[\"headway_avg\"], errors=\"coerce\")\n",
    "\n",
    "hv_valid = addr_headway.dropna()\n",
    "if len(hv_valid) > 0:\n",
    "    vmin, vmax = hv_valid.quantile([0.01, 0.99])\n",
    "    if vmin == vmax:\n",
    "        # falls alles gleich (z. B. nur eine Linie), spreizen f√ºr die Farbskala\n",
    "        vmin = vmin - 0.1\n",
    "        vmax = vmax + 0.1\n",
    "else:\n",
    "    # Fallback, falls ALLE Adressen NaN sind\n",
    "    vmin, vmax = (0, 1)\n",
    "\n",
    "palette_normal = list(linear.RdYlGn_11.colors)\n",
    "palette_inverted = palette_normal[::-1]\n",
    "colormap = LinearColormap(\n",
    "    colors=palette_inverted,\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    ").to_step(n=9)\n",
    "colormap.caption = \"Headway pro Adresse (Minuten, kleiner = besser)\"\n",
    "\n",
    "# 3. Karte initialisieren\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"cartodbpositron\")\n",
    "\n",
    "# 4. Adressen plotten (farbig nach headway_avg)\n",
    "#    - Farbig wenn headway_avg da\n",
    "#    - Hellgrau wenn kein Wert\n",
    "for _, row in gdf.iterrows():\n",
    "    hv_addr = row.get(\"headway_avg\", np.nan)\n",
    "    hv_morning = row.get(\"headway_morning\", np.nan)\n",
    "    hv_evening = row.get(\"headway_evening\", np.nan)\n",
    "\n",
    "    if pd.isna(hv_addr):\n",
    "        # Kein Wert berechnet -> zeichne neutral\n",
    "        color = \"#BBBBBB\"\n",
    "        fill_color = \"#BBBBBB\"\n",
    "        hv_label = \"kein Wert\"\n",
    "    else:\n",
    "        color = colormap(hv_addr)\n",
    "        fill_color = colormap(hv_addr)\n",
    "        hv_label = f\"{hv_addr:.1f} min\"\n",
    "\n",
    "    # Popup mit allen Headways, falls vorhanden\n",
    "    popup_lines = [\n",
    "        f\"{row.get('Stra√üenname', '')} {row.get('Hsnr', '')}\",\n",
    "        f\"<b>Headway (avg):</b> {hv_label}\",\n",
    "    ]\n",
    "    if pd.notna(hv_morning):\n",
    "        popup_lines.append(f\"Fr√ºhspitze: {hv_morning:.1f} min\")\n",
    "    if pd.notna(hv_evening):\n",
    "        popup_lines.append(f\"Abendspitze: {hv_evening:.1f} min\")\n",
    "\n",
    "    popup_html = \"<br>\".join(popup_lines)\n",
    "\n",
    "    folium.CircleMarker(\n",
    "        location=[row.lat, row.lon],\n",
    "        radius=5,\n",
    "        color=color,\n",
    "        fill=True,\n",
    "        fill_color=fill_color,\n",
    "        fill_opacity=0.8,\n",
    "        weight=1,\n",
    "        popup=popup_html,\n",
    "    ).add_to(m)\n",
    "\n",
    "# 5. Haltestellen plotten (schwarz, neutral)\n",
    "#    Du zeigst hier die Infrastrukturpunkte, ohne Qualit√§tsfarbe.\n",
    "for _, row in gdf_stops_clip.iterrows():\n",
    "    lat_s = row[\"stop_lat\"]\n",
    "    lon_s = row[\"stop_lon\"]\n",
    "\n",
    "    # Popup Haltestellenname\n",
    "    stop_label = row.get(\"stop_name\", row.get(\"stop_id\", \"Haltestelle\"))\n",
    "\n",
    "    folium.CircleMarker(\n",
    "        location=[lat_s, lon_s],\n",
    "        radius=3,\n",
    "        color=\"black\",\n",
    "        fill=True,\n",
    "        fill_color=\"black\",\n",
    "        fill_opacity=1,\n",
    "        weight=1,\n",
    "        popup=f\"<b>Haltestelle:</b> {stop_label}<br>\",\n",
    "    ).add_to(m)\n",
    "\n",
    "# 6. Legende f√ºr die Adressen-Headways\n",
    "colormap.add_to(m)\n",
    "m\n"
   ],
   "id": "24544ac9ee9f7dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Umwelt\n",
    "### Gro√üfl√§chen\n",
    "- Luftlinie in m zum n√§chsten gro√üen Wald oder See\n",
    "- Luftlinie in m zum n√§chsten gro√üen Gewerbe- oder Industriegebiet\n"
   ],
   "id": "51f2302c42d26989"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import geopandas as gpd\n",
    "from shapely.strtree import STRtree\n",
    "from shapely.geometry.base import BaseGeometry\n",
    "import numpy as np\n",
    "\n",
    "# --------------------------------------------\n",
    "# 1) Gro√üe Fl√§chen in metrischem CRS vorbereiten\n",
    "# --------------------------------------------\n",
    "gdf_m = gdf.to_crs(32633)\n",
    "gdf_large_m = gdf_large.to_crs(32633)\n",
    "\n",
    "TARGET_CLASSES = {\n",
    "    \"gewerbe\": \"Gewerbe\",\n",
    "    \"gruen\": \"Gruen\",\n",
    "    \"sonstiges\": \"Sonstiges\"\n",
    "}\n",
    "\n",
    "# --------------------------------------------\n",
    "# 2) Geometrien pro Klasse + STRtree vorbereiten\n",
    "# --------------------------------------------\n",
    "targets = {}\n",
    "\n",
    "for key, cls in TARGET_CLASSES.items():\n",
    "    geoms = list(gdf_large_m[gdf_large_m[\"nutzklasse\"] == cls].geometry)\n",
    "\n",
    "    # Leere Klassen √ºberspringen\n",
    "    if not geoms:\n",
    "        print(f\"Warnung: keine Geometrien f√ºr Klasse {cls} gefunden.\")\n",
    "        continue\n",
    "\n",
    "    tree = STRtree(geoms)\n",
    "    targets[key] = {\n",
    "        \"geoms\": geoms,\n",
    "        \"tree\": tree,\n",
    "    }\n",
    "\n",
    "print(\"STRtrees vorbereitet f√ºr:\", list(targets.keys()))\n",
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "# 3) Distanzfunktion: Punkt ‚Üí n√§chstgelegene Fl√§che\n",
    "# --------------------------------------------\n",
    "def fast_distance_to_area(pt, target):\n",
    "    \"\"\"\n",
    "    pt: shapely Point (im selben CRS wie target-geoms)\n",
    "    target: Dict mit 'geoms' (Liste) und 'tree' (STRtree)\n",
    "    \"\"\"\n",
    "    if pt is None or (hasattr(pt, \"is_empty\") and pt.is_empty):\n",
    "        return np.nan\n",
    "\n",
    "    tree = target[\"tree\"]\n",
    "    geoms = target[\"geoms\"]\n",
    "\n",
    "    # nearest() liefert hier einen INDEX in der Geom-Liste zur√ºck\n",
    "    idx = tree.nearest(pt)\n",
    "\n",
    "    # falls doch mal ein Geometry zur√ºckk√§me: beides abfangen\n",
    "    if isinstance(idx, BaseGeometry):\n",
    "        nearest_geom = idx\n",
    "    else:\n",
    "        nearest_geom = geoms[int(idx)]\n",
    "\n",
    "    try:\n",
    "        return float(pt.distance(nearest_geom))\n",
    "    except TypeError:\n",
    "        # Falls unerwartete Typen auftauchen\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "# 4) Distanzen f√ºr jede Kategorie berechnen\n",
    "# --------------------------------------------\n",
    "for key, target in targets.items():\n",
    "    print(f\"Berechne Distanz f√ºr Kategorie: {key} ...\")\n",
    "    gdf_m[f\"dist_gross_{key}\"] = gdf_m.geometry.apply(\n",
    "        lambda pt, t=target: fast_distance_to_area(pt, t)\n",
    "    )\n",
    "\n",
    "# --------------------------------------------\n",
    "# 5) Ergebnisse zur√ºck nach WGS84\n",
    "# --------------------------------------------\n",
    "gdf_back = gdf_m.to_crs(4326)\n",
    "\n",
    "dist_cols = [f\"dist_gross_{k}\" for k in targets.keys()]\n",
    "gdf[dist_cols] = gdf_back[dist_cols]\n",
    "\n",
    "print(\"Fertig! Neue Distanzfelder berechnet:\", dist_cols)\n"
   ],
   "id": "ed393f2798a56388",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "import geopandas as gpd\n",
    "from shapely.ops import linemerge\n",
    "\n",
    "# ------------------------------\n",
    "# 1) Metrische Projektion\n",
    "# ------------------------------\n",
    "gdf_m = gdf.to_crs(32633)\n",
    "gdf_large_m = gdf_large.to_crs(32633)\n",
    "\n",
    "# Fl√§che in ha berechnen (1 ha = 10.000 m¬≤) und runden\n",
    "gdf_large_m[\"area_ha\"] = (gdf_large_m.area / 10000).round(1)\n",
    "\n",
    "# zur√ºck nach WGS84 f√ºr Darstellung\n",
    "gdf_large_4326 = gdf_large_m.to_crs(4326)\n",
    "\n",
    "# ------------------------------\n",
    "# 2) Fl√§chen nach Kategorien\n",
    "# ------------------------------\n",
    "TARGET_CLASSES = {\n",
    "    \"gewerbe\": \"Gewerbe\",\n",
    "    \"gruen\": \"Gruen\",\n",
    "    \"sonstiges\": \"Sonstiges\"\n",
    "}\n",
    "\n",
    "areas = {\n",
    "    key: gdf_large_4326[gdf_large_4326[\"nutzklasse\"] == cls].copy()\n",
    "    for key, cls in TARGET_CLASSES.items()\n",
    "}\n",
    "\n",
    "colors = {\"gewerbe\": \"red\", \"gruen\": \"green\", \"sonstiges\": \"blue\"}\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 3) Distanzfunktionen\n",
    "# ------------------------------\n",
    "def nearest_boundary_point(pt, polygon):\n",
    "    boundary = polygon.boundary\n",
    "    if boundary.geom_type == \"MultiLineString\":\n",
    "        boundary = linemerge(boundary)\n",
    "    proj = boundary.project(pt)\n",
    "    nearest_pt = boundary.interpolate(proj)\n",
    "    return nearest_pt\n",
    "\n",
    "\n",
    "def compute_nearest_area(pt, df):\n",
    "    \"\"\"\n",
    "    pt: Point (UTM)\n",
    "    df: GeoDataFrame (WGS84!), deshalb f√ºr Distanz kurz in UTM projizieren\n",
    "    \"\"\"\n",
    "    # in metrisches CRS bringen\n",
    "    df_utm = df.to_crs(32633)\n",
    "\n",
    "    best_dist = 1e12\n",
    "    best_point = None\n",
    "\n",
    "    for poly in df_utm.geometry:\n",
    "        nb = nearest_boundary_point(pt, poly)\n",
    "        d = pt.distance(nb)\n",
    "        if d < best_dist:\n",
    "            best_dist = d\n",
    "            best_point = nb\n",
    "\n",
    "    return best_dist, best_point\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 4) Karte aufbauen\n",
    "# ------------------------------\n",
    "def build_map():\n",
    "    # 5 zuf√§llige Adressen\n",
    "    rows = gdf.sample(5, random_state=42)\n",
    "\n",
    "    m = folium.Map(location=CITY_CENTER, zoom_start=12, tiles=\"cartodbpositron\")\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # Fl√§chenlayer (mit Tooltip: bez + area_ha)\n",
    "    # ------------------------------------------\n",
    "    for key, df in areas.items():\n",
    "\n",
    "        layer = folium.FeatureGroup(name=f\"Fl√§chen ‚Äì {key}\", show=True)\n",
    "\n",
    "        df_safe = df[[\"geometry\", \"nutzklasse\", \"bez\", \"area_ha\"]].copy()\n",
    "\n",
    "        folium.GeoJson(\n",
    "            df_safe,\n",
    "            name=key,\n",
    "            style_function=lambda feature, col=colors[key]: {\n",
    "                \"fillColor\": col,\n",
    "                \"color\": col,\n",
    "                \"weight\": 1,\n",
    "                \"fillOpacity\": 0.25,\n",
    "            },\n",
    "            tooltip=folium.features.GeoJsonTooltip(\n",
    "                fields=[\"bez\", \"nutzklasse\", \"area_ha\"],\n",
    "                aliases=[\"Objekt:\", \"Kategorie:\", \"Fl√§che (ha):\"],\n",
    "                localize=True,\n",
    "                sticky=True,\n",
    "            ),\n",
    "        ).add_to(layer)\n",
    "\n",
    "        layer.add_to(m)\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # Adressen + Luftlinien\n",
    "    # ------------------------------------------\n",
    "    for idx, row in rows.iterrows():\n",
    "\n",
    "        # Adresspunkt in UTM\n",
    "        addr_pt_utm = gdf_m.loc[row.name].geometry\n",
    "\n",
    "        # Adresse markieren (WGS84-Koordinaten aus gdf)\n",
    "        folium.CircleMarker(\n",
    "            location=[row.lat, row.lon],\n",
    "            radius=7,\n",
    "            color=\"black\",\n",
    "            fill=True,\n",
    "            fill_opacity=1,\n",
    "            tooltip=row[\"Adresse_merge\"],\n",
    "        ).add_to(m)\n",
    "\n",
    "        # Linien zu Fl√§chenkategorien\n",
    "        for key, df in areas.items():\n",
    "\n",
    "            dist, nearest_pt_utm = compute_nearest_area(addr_pt_utm, df)\n",
    "\n",
    "            # n√§chster Punkt zur√ºck in WGS84\n",
    "            nearest_pt_wgs = (\n",
    "                gpd.GeoSeries([nearest_pt_utm], crs=32633).to_crs(4326).iloc[0]\n",
    "            )\n",
    "\n",
    "            # Linie\n",
    "            folium.PolyLine(\n",
    "                locations=[\n",
    "                    (row.lat, row.lon),\n",
    "                    (nearest_pt_wgs.y, nearest_pt_wgs.x),\n",
    "                ],\n",
    "                color=colors[key],\n",
    "                weight=3,\n",
    "                opacity=0.9,\n",
    "                tooltip=f\"{key}: {int(dist)} m\",\n",
    "            ).add_to(m)\n",
    "\n",
    "            # Zielmarker\n",
    "            folium.CircleMarker(\n",
    "                location=[nearest_pt_wgs.y, nearest_pt_wgs.x],\n",
    "                radius=4,\n",
    "                color=colors[key],\n",
    "                fill=True,\n",
    "                fill_opacity=0.9,\n",
    "                tooltip=f\"Rand {key}: {int(dist)} m\",\n",
    "            ).add_to(m)\n",
    "\n",
    "    folium.LayerControl(collapsed=False).add_to(m)\n",
    "    return m\n",
    "\n",
    "\n",
    "m = build_map()\n",
    "m\n"
   ],
   "id": "dadcf605e73e7658",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Freizeit- und Erholungsfl√§chen\n",
    "\n",
    "- Fu√ül√§ufige Distanz zur n√§chstgelegenen Freizeit- und Erholungsfl√§chen (Spielpl√§tze, Parks, Gr√ºnanlagen)\n",
    "\n",
    "Die Freizeit- und Erholungsfl√§chen laut Auftrag sind:\n",
    "- Marienberg\n",
    "- Humboldthain\n",
    "- Salzhofufer\n",
    "- Wallpromenade\n",
    "- Theaterpark\n",
    "- Grabenpromenade\n",
    "- Schlosspark Plaue\n",
    "- Schlosspark Gollwitz\n",
    "- Krugpark\n",
    "\n",
    "Aus den bereitgestellten Shape-Dateien werden anhand der Objektbezeichnung (Spalte \"objektbeze\") im Routing-Skript ca. 100 zusammenh√§ngende Fl√§chen gebildet, deren R√§nder als Ziele f√ºr die fu√ül√§ufige Distanzberechnung genutzt werden. Dadurch werden mehr als die angegebenen Fl√§chen genutzt.\n",
    "\n",
    "Einschr√§nkung der Validit√§t: Durch die Beschr√§nkung auf diese Fl√§chenarten erhalten zentrumsferne Adressen trotz der Lage z. B. an W√§ldern schlechtere Bewertungen."
   ],
   "id": "94649ee801aa7560"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "path = \"data/Gr√ºnfl√§chen_Verkehrszeichen/20251029_Vegetation_KSP_GP_31.shp\"\n",
    "gdf_gruen_shape = gpd.read_file(path)\n",
    "#gdf_gruen"
   ],
   "id": "aa43fe538b4bc67a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=14)\n",
    "\n",
    "def random_color(seed):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    r = rng.integers(80, 200)\n",
    "    g = rng.integers(80, 200)\n",
    "    b = rng.integers(80, 200)\n",
    "    return f\"#{r:02x}{g:02x}{b:02x}\"\n",
    "\n",
    "# Ein Farbschema erzeugen\n",
    "unique_ids = gdf_gruen_shape[\"objektbeze\"].unique()\n",
    "color_map = {uid: random_color(i) for i, uid in enumerate(unique_ids)}\n",
    "\n",
    "# Polygone hinzuf√ºgen\n",
    "folium.GeoJson(\n",
    "    gdf_gruen_shape,\n",
    "    style_function=lambda feature: {\n",
    "        \"color\": \"black\",\n",
    "        \"weight\": 0.5,\n",
    "        \"fillOpacity\": 0.9,\n",
    "        \"fillColor\": color_map[feature[\"properties\"][\"objektbeze\"]]\n",
    "    },\n",
    "    tooltip=folium.GeoJsonTooltip(fields=[\"objektbeze\"])\n",
    ").add_to(m)\n",
    "\n",
    "m"
   ],
   "id": "2ae81272462576a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gdf_gruen_m = gdf_gruen_shape.to_crs(32633)\n",
    "\n",
    "# Gruppieren & union der Fl√§chen\n",
    "gdf_gruen_area = (gdf_gruen_shape.dissolve(by=\"objektbeze\").reset_index())\n",
    "\n",
    "# Fl√§che berechnen (m¬≤)\n",
    "gdf_gruen_area[\"flaeche_m2\"] = gdf_gruen_area.area\n",
    "gdf_gruen_area[\"flaeche_ha\"] = gdf_gruen_area[\"flaeche_m2\"] / 10_000\n",
    "\n",
    "bad = gdf_gruen_area.geometry.apply(lambda g: not g.is_valid)\n",
    "print(\"Ung√ºltige Geometrien:\", bad.sum())\n",
    "\n",
    "bb = gdf_gruen_area.geometry.boundary\n",
    "print(\"Boundary is empty:\", sum(bb.is_empty))\n",
    "\n",
    "# Optional: Die Fl√§che der n√§chstgelegenen Anlage k√∂nnte noch als Qualit√§tskriterium hinzugef√ºgt werden. Vorerst nutzen wir nur die Entfernung zu den Anlagen.\n",
    "\n",
    "del(gdf_gruen_m, gdf_gruen_area)"
   ],
   "id": "70328158908d4bc8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Lade vorberechnete Routen zur n√§chstgelegenen Anlage und Anzahl von Funden im Umkreis\n",
    "gdf_gruen = load_geocsv(\"out/adressen_mit_gruen_routen.csv\")"
   ],
   "id": "aa74c34fdcf6a9a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Merge mit Haupt-GDF\n",
    "gdf_gruen[\"Adresse_merge\"] = gdf_gruen.apply(make_merge_addr, axis=1)\n",
    "gdf_gruen = gdf_gruen.sort_values(\"Adresse_merge\").drop_duplicates(\"Adresse_merge\", keep=\"first\")\n",
    "\n",
    "dups = gdf_gruen[\"Adresse_merge\"].value_counts()\n",
    "print(dups[dups > 1])\n",
    "\n",
    "gruen_attribute = [\"gruen_route\",\"gruen_min_distance_m\", \"gruen_count_within_500m\", \"gruen_count_within_800m\", \"gruen_count_within_1000m\"]\n",
    "\n",
    "gdf = pd.merge(\n",
    "    gdf,\n",
    "    gdf_gruen[[\"Adresse_merge\"] + gruen_attribute],\n",
    "    on=\"Adresse_merge\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_many\"\n",
    ")\n",
    "\n",
    "# Plausibili√§tspr√ºfung\n",
    "print(gdf[[\"Adresse_merge\", \"gruen_min_distance_m\", \"gruen_route\"]].head())\n",
    "print(gdf.shape)"
   ],
   "id": "7390decad77bb1da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Begenzung durch dauerhafte Bahnlininen / Schranken\n",
    "Als zus√§tzlicher Indikator wird berechnet, ob eine Adresse durch eine Bahnlinie oder eine stark befahrene Stra√üe (Autobahn, Bundesstra√üe) vom Stadtzentrum getrennt ist. Damit wird abgebildet, ob eine Adresse trotz N√§he zum Zentrum durch eine Barriere erschwerten Zugang hat (z. B., durch Wartezeiten an Bahn√ºberg√§ngen)."
   ],
   "id": "9d1da8cf2f7610c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import osmnx as ox\n",
    "\n",
    "# Schritt 1: Bahnlinien von OSM laden\n",
    "\n",
    "place = \"Brandenburg an der Havel, Germany\"\n",
    "\n",
    "# Eisenbahnlinien holen\n",
    "rails = ox.features_from_place(\n",
    "    place,\n",
    "    tags={\"railway\": True}  # includes rail, light_rail, tram, etc.\n",
    ")\n",
    "\n",
    "# nur Schienenverkehr (keine Haltestellen)\n",
    "rails = rails[rails[\"railway\"].isin([\"rail\"])]"
   ],
   "id": "d902584f88044dd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "# Schritt 2: Fu√üƒ∫√§ufige Routen zum Stadtzentrum auf Schnittpunkt mit Bahnlinie pr√ºfen und im Datensatz speichern\n",
    "\n",
    "def route_crosses_rail(route_geojson_str, rail_geom):\n",
    "    if not isinstance(route_geojson_str, str):\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        geo = json.loads(route_geojson_str)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "    if geo.get(\"type\") != \"LineString\":\n",
    "        return False\n",
    "\n",
    "    # Koordinaten (lon, lat) ‚Üí Shapely LineString nutzen\n",
    "    coords = geo[\"coordinates\"]\n",
    "    line = LineString(coords)\n",
    "\n",
    "    # Schnitt-Test\n",
    "    return line.intersects(rail_geom)\n",
    "\n",
    "rail_union = rails.union_all()\n",
    "gdf[\"behind_rail_from_center\"] = gdf[\"center_route\"].apply(\n",
    "    lambda r: int(route_crosses_rail(r, rail_union))\n",
    ")\n"
   ],
   "id": "e81e3b0dad416510",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "import json\n",
    "import folium\n",
    "\n",
    "# 10 zuf√§llige Adressen ziehen\n",
    "sample_gdf = gdf.sample(10, random_state=42)\n",
    "\n",
    "center_lat, center_lon = CITY_CENTER  # CITY_CENTER ist [lat, lon]\n",
    "center_point = (center_lat, center_lon)\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Zentrum markieren\n",
    "folium.Marker(\n",
    "    location=CITY_CENTER,\n",
    "    tooltip=\"Stadtzentrum\",\n",
    "    icon=folium.Icon(color=\"red\", icon=\"star\")\n",
    ").add_to(m)\n",
    "\n",
    "# Route + Marker je Adresse\n",
    "for idx, row in sample_gdf.iterrows():\n",
    "    if pd.isna(row[\"lat\"]) or pd.isna(row[\"lon\"]):\n",
    "        continue\n",
    "\n",
    "    addr_point = (row[\"lat\"], row[\"lon\"])\n",
    "    behind_flag = row.get(\"behind_rail_from_center\", None)\n",
    "\n",
    "    tooltip = f\"Adresse {idx}<br>behind_rail_from_center: {behind_flag}\"\n",
    "\n",
    "    # Route zum Zentrum (GeoJSON)\n",
    "    route_json = row.get(\"center_route\")\n",
    "\n",
    "    if isinstance(route_json, str):\n",
    "        try:\n",
    "            route_geo = json.loads(route_json)\n",
    "\n",
    "            if route_geo.get(\"type\") == \"LineString\":\n",
    "                # GeoJSON Koordinaten sind (lon, lat)\n",
    "                coords = [(c[1], c[0]) for c in route_geo[\"coordinates\"]]\n",
    "\n",
    "                folium.PolyLine(\n",
    "                    locations=coords,\n",
    "                    color=\"blue\",\n",
    "                    weight=4,\n",
    "                    opacity=0.7,\n",
    "                    tooltip=f\"Route zu Adresse {idx}\"\n",
    "                ).add_to(m)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Zeichnen der Route f√ºr Adresse {idx}: {e}\")\n",
    "\n",
    "    # Adressmarker\n",
    "    folium.CircleMarker(\n",
    "        location=addr_point,\n",
    "        radius=4,\n",
    "        color=\"blue\",\n",
    "        fill=True,\n",
    "        fill_opacity=0.8,\n",
    "        tooltip=folium.Tooltip(tooltip)\n",
    "    ).add_to(m)\n",
    "\n",
    "# Bahnlinien-Layer\n",
    "bahn_layer = folium.FeatureGroup(name=\"Bahnlinien (OSM)\", show=True)\n",
    "\n",
    "for _, row in rails.iterrows():\n",
    "    geom = row.geometry\n",
    "    if geom is None:\n",
    "        continue\n",
    "\n",
    "    if geom.geom_type == \"LineString\":\n",
    "        coords = [(y, x) for x, y in geom.coords]\n",
    "        folium.PolyLine(\n",
    "            locations=coords,\n",
    "            color=\"darkred\",\n",
    "            weight=4,\n",
    "            opacity=0.8\n",
    "        ).add_to(bahn_layer)\n",
    "\n",
    "    elif geom.geom_type == \"MultiLineString\":\n",
    "        for part in geom:\n",
    "            coords = [(y, x) for x, y in part.coords]\n",
    "            folium.PolyLine(\n",
    "                locations=coords,\n",
    "                color=\"darkred\",\n",
    "                weight=4,\n",
    "                opacity=0.8\n",
    "            ).add_to(bahn_layer)\n",
    "\n",
    "bahn_layer.add_to(m)\n",
    "\n",
    "m"
   ],
   "id": "44fcb8f889ac1cf4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Visualisierung aller Indikatoren\n",
    "Alle Einflussfaktoren (Superm√§rkte, √Ñrzte, Schulen etc.) werden zur Plausibilit√§tspr√ºfung auf einer Karte visualisiert."
   ],
   "id": "1a1d9689bda3a442"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "import branca.colormap as cm\n",
    "from helper import add_markers_from_csv, STRASSENNAME, HAUSNUMMER, HAUSNUMMERZUSATZ\n",
    "import ast\n",
    "\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"cartodbpositron\")\n",
    "\n",
    "# √Ñrzte laden\n",
    "df_aerzte = pd.read_csv(\"out/aerzte_geocoded.csv\")\n",
    "# Lookup Dictionary: Name_Arzt -> Fachrichtung\n",
    "fach_lookup = dict(zip(df_aerzte[\"Name_Arzt\"], df_aerzte[\"Fachrichtung\"]))\n",
    "\n",
    "def add_medcenter_markers(map_obj, csv_path, color=\"red\", icon=\"staff-snake\", layer_name=\"Medizinische Zentren\"):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    layer = folium.FeatureGroup(name=layer_name)\n",
    "    layer.add_to(map_obj)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        lat, lon = row[\"lat\"], row[\"lon\"]\n",
    "        if pd.isna(lat) or pd.isna(lon):\n",
    "            continue\n",
    "\n",
    "        # Arztliste parsen\n",
    "        arzt_keys = row.get(\"arzt_keys_100m\", \"[]\")\n",
    "        if isinstance(arzt_keys, str):\n",
    "            arzt_keys = ast.literal_eval(arzt_keys)\n",
    "\n",
    "        # Popup zusammenbauen\n",
    "        lines = []\n",
    "\n",
    "        if bool(row.get(\"is_med_center\", False)):\n",
    "            lines.append(f\"<b>Medizinisches Zentrum<br>{row.get('Strassenname','')}</b><br>\")\n",
    "\n",
    "        # Apotheke\n",
    "        name_ap = str(row.get(\"Name_Apotheke\", \"\")).strip()\n",
    "        if name_ap:\n",
    "            lines.append(f\"üè• {name_ap}<br>\")\n",
    "\n",
    "        # Anzahl √Ñrzte\n",
    "        if len(arzt_keys) > 0:\n",
    "            lines.append(f\"<br><b>{len(arzt_keys)} Arztpraxen im 100 m Radius:</b><br>\")\n",
    "\n",
    "        # √Ñrzte + Fachrichtung\n",
    "        for arzt in arzt_keys:\n",
    "            fach = fach_lookup.get(arzt, \"(Fachrichtung unbekannt)\")\n",
    "            lines.append(f\"{arzt} ‚Äì {fach}<br>\")\n",
    "\n",
    "        popup_html = \"\".join(lines)\n",
    "\n",
    "        # Icon w√§hlen\n",
    "        ico = folium.Icon(color=color, icon=icon, prefix=\"fa\")\n",
    "\n",
    "        marker = folium.Marker(\n",
    "            location=[lat, lon],\n",
    "            tooltip=row.get(\"Strassenname\", \"MedZentrum\"),\n",
    "            icon=ico\n",
    "        ).add_to(layer)\n",
    "\n",
    "        # Popup breiter machen\n",
    "        marker.add_child(folium.Popup(popup_html, max_width=450))\n",
    "\n",
    "# Add layer markers\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/einzelhandel_geocoded.csv\", color=\"blue\", icon=\"shopping-cart\", layer_name=\"Einzelhandel\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/grundschulen_geocoded.csv\", color=\"green\", icon=\"graduation-cap\", layer_name=\"Grundschulen\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/kitas_geocoded.csv\", color=\"beige\", icon=\"child\", layer_name=\"Kitas\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/haltestellen_geocoded.csv\", color=\"lightgray\", icon=\"bus\", layer_name=\"Haltestellen\")\n",
    "add_medcenter_markers(map_obj=m, csv_path=\"out/medzentren_geocoded.csv\")\n",
    "\n",
    "# L√§rmindex aus dem Geopackage\n",
    "gdf_laerm_karte = gpd.read_file(\"data/laerm.gpkg\", layer=\"laerm\")\n",
    "gdf_laerm_karte = gdf_laerm_karte.clip(CITY_BOUNDING_BOX)\n",
    "value_column = \"isov1\"\n",
    "min_val = gdf_laerm_karte[value_column].min()\n",
    "max_val = gdf_laerm_karte[value_column].max()\n",
    "colormap = cm.LinearColormap(colors=[\"green\", \"yellow\", \"red\"], vmin=min_val, vmax=max_val)\n",
    "colormap.caption = \"L√§rmpegel (LDEN in dB)\"\n",
    "\n",
    "# √Ñrzte\n",
    "df_aerzte = pd.read_csv(\"out/aerzte_geocoded.csv\")\n",
    "fach_lookup = dict(zip(df_aerzte[\"Name_Arzt\"], df_aerzte[\"Fachrichtung\"]))\n",
    "\n",
    "# Alle Adressen als Punkte\n",
    "adress_layer = folium.FeatureGroup(name=\"Wohnadressen\", show=False)\n",
    "for _, row in gdf.iterrows():\n",
    "    if pd.notna(row[\"lat\"]) and pd.notna(row[\"lon\"]):\n",
    "        strasse = s(row.get(STRASSENNAME))\n",
    "        hsnr = s(row.get(HAUSNUMMER))\n",
    "        hsnrzus = s(row.get(HAUSNUMMERZUSATZ))\n",
    "\n",
    "        tooltip = strasse + \" \" + hsnr\n",
    "\n",
    "        adressen_map = folium.CircleMarker(\n",
    "            location=[row[\"lat\"], row[\"lon\"]],\n",
    "            radius=3,\n",
    "            color=\"lightgray\",\n",
    "            fill=True,\n",
    "            fill_opacity=0.6,\n",
    "            tooltip=tooltip\n",
    "        ).add_to(adress_layer)\n",
    "adress_layer.add_to(m)\n",
    "\n",
    "def style_function(feature):\n",
    "    value = feature[\"properties\"][value_column]\n",
    "    return {\n",
    "        \"fillColor\": colormap(value),\n",
    "        \"color\": \"black\",\n",
    "        \"weight\": 0.3,\n",
    "        \"fillOpacity\": 0.2\n",
    "    }\n",
    "\n",
    "laerm_layer = folium.FeatureGroup(name=\"L√§rmkarte (LDEN 2022)\")\n",
    "folium.GeoJson(\n",
    "    gdf_laerm_karte,\n",
    "    style_function=style_function,\n",
    ").add_to(laerm_layer)\n",
    "laerm_layer.add_to(m)\n",
    "colormap.add_to(m)\n",
    "\n",
    "# Gr√ºnfl√§chen hinzuf√ºgen\n",
    "gruen_layer = folium.FeatureGroup(name=\"Freizeit- und Erholungsfl√§chen\")\n",
    "folium.GeoJson(\n",
    "    gdf_gruen_shape,\n",
    "    style_function=lambda feature: {\n",
    "        \"color\": \"black\",\n",
    "        \"weight\": 0.2,\n",
    "        \"fillOpacity\": 0.9,\n",
    "        \"fillColor\": \"green\"\n",
    "    }\n",
    ").add_to(gruen_layer)\n",
    "gruen_layer.add_to(m)\n",
    "\n",
    "# Bahnlinien layer hinzuf√ºgen\n",
    "bahn_layer = folium.FeatureGroup(name=\"Bahnlinien (OSM)\", show=True)\n",
    "\n",
    "for _, row in rails.iterrows():\n",
    "    geom = row.geometry\n",
    "    if geom is None:\n",
    "        continue\n",
    "\n",
    "    if geom.geom_type == \"LineString\":\n",
    "        coords = [(y, x) for x, y in geom.coords]\n",
    "        folium.PolyLine(\n",
    "            locations=coords,\n",
    "            color=\"darkred\",\n",
    "            weight=4,\n",
    "            opacity=0.8\n",
    "        ).add_to(bahn_layer)\n",
    "\n",
    "    elif geom.geom_type == \"MultiLineString\":\n",
    "        for part in geom:\n",
    "            coords = [(y, x) for x, y in part.coords]\n",
    "            folium.PolyLine(\n",
    "                locations=coords,\n",
    "                color=\"darkred\",\n",
    "                weight=4,\n",
    "                opacity=0.8\n",
    "            ).add_to(bahn_layer)\n",
    "\n",
    "bahn_layer.add_to(m)\n",
    "\n",
    "# Schaltbare Layer\n",
    "folium.LayerControl(collapsed=False).add_to(m)\n",
    "del gdf_laerm_karte  # Speicher freigeben\n",
    "m"
   ],
   "id": "779464ac37bb84c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Scoring / Punktesystem\n",
    "Hier werden z-Werte zu alle **Einflussfaktoren** gebildet, um die Abweichung einer Auspr√§gung vom Standard (im betrachteten Gebiet) zu erfassen. Weiterhin werden die **Gewichte** festgelegt, mit denen die Faktoren in die Wohnlagenbewertung eingehen."
   ],
   "id": "92944c1fbc1d51d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# ---------------------------------------\n",
    "# 1) Numerische & bin√§re Features\n",
    "# ---------------------------------------\n",
    "numeric_features = (\n",
    "        [\"center_distance_m\"] +\n",
    "        haltestellen_attribute +\n",
    "        headway_attribute +\n",
    "        einzelhandel_attribute +\n",
    "        laerm_attribute +\n",
    "        kitas_attribute +\n",
    "        grundschulen_attribute +\n",
    "        medzentren_attribute +\n",
    "        gruen_attribute\n",
    ")\n",
    "\n",
    "binary_features = [\"behind_rail_from_center\"]\n",
    "\n",
    "score_vars = numeric_features + binary_features\n",
    "\n",
    "# Masken nur auf numerische Daten!\n",
    "mask_all = gdf[numeric_features].notna().all(axis=1)\n",
    "\n",
    "# ---------------------------------------\n",
    "# 2) Z-Scores f√ºr numerische Variablen\n",
    "#    (immer: hoch = gut!)\n",
    "# ---------------------------------------\n",
    "\n",
    "# Zentralit√§t\n",
    "gdf.loc[mask_all, \"z_centrality\"] = -zscore(gdf.loc[mask_all, \"center_distance_m\"])\n",
    "\n",
    "# Einzelhandel\n",
    "gdf.loc[mask_all, \"z_einzelhandel_distance\"]    = -zscore(gdf.loc[mask_all, \"einzelhandel_min_distance_m\"])\n",
    "gdf.loc[mask_all, \"z_einzelhandel_near_500\"]    =  zscore(gdf.loc[mask_all, \"einzelhandel_500m_count\"])\n",
    "gdf.loc[mask_all, \"z_einzelhandel_near_800\"]    =  zscore(gdf.loc[mask_all, \"einzelhandel_800m_count\"])\n",
    "gdf.loc[mask_all, \"z_einzelhandel_near_1000\"]   =  zscore(gdf.loc[mask_all, \"einzelhandel_1000m_count\"])\n",
    "\n",
    "# L√§rm\n",
    "gdf.loc[mask_all, \"z_laerm_index_tag\"]          = -zscore(gdf.loc[mask_all, \"laerm_index_tag\"])\n",
    "\n",
    "# Kitas\n",
    "gdf.loc[mask_all, \"z_kita_distance\"]            = -zscore(gdf.loc[mask_all, \"kitas_min_distance_m\"])\n",
    "gdf.loc[mask_all, \"z_kita_near_500\"]            =  zscore(gdf.loc[mask_all, \"kitas_count_within_500m\"])\n",
    "gdf.loc[mask_all, \"z_kita_near_800\"]            =  zscore(gdf.loc[mask_all, \"kitas_count_within_800m\"])\n",
    "gdf.loc[mask_all, \"z_kita_near_1000\"]           =  zscore(gdf.loc[mask_all, \"kitas_count_within_1000m\"])\n",
    "\n",
    "# Grundschulen\n",
    "gdf.loc[mask_all, \"z_grundschulen_distance\"]    = -zscore(gdf.loc[mask_all, \"grundschulen_min_distance_m\"])\n",
    "gdf.loc[mask_all, \"z_grundschulen_near_500\"]    =  zscore(gdf.loc[mask_all, \"grundschulen_count_within_500m\"])\n",
    "gdf.loc[mask_all, \"z_grundschulen_near_800\"]    =  zscore(gdf.loc[mask_all, \"grundschulen_count_within_800m\"])\n",
    "gdf.loc[mask_all, \"z_grundschulen_near_1000\"]   =  zscore(gdf.loc[mask_all, \"grundschulen_count_within_1000m\"])\n",
    "\n",
    "# Mobilit√§t\n",
    "gdf.loc[mask_all, \"z_haltestelle_distance\"]     = -zscore(gdf.loc[mask_all, \"haltestellen_min_distance_m\"])\n",
    "gdf.loc[mask_all, \"z_haltestellen_count_within_500m\"] =  zscore(gdf.loc[mask_all, \"haltestellen_count_within_500m\"])\n",
    "gdf.loc[mask_all, \"z_haltestellen_count_within_800m\"] =  zscore(gdf.loc[mask_all, \"haltestellen_count_within_800m\"])\n",
    "gdf.loc[mask_all, \"z_headway_score\"]            = -zscore(gdf.loc[mask_all, \"headway_avg\"])\n",
    "\n",
    "# Medizinische Versorgung\n",
    "gdf.loc[mask_all, \"z_medzentrum_distance\"]      = -zscore(gdf.loc[mask_all, \"medzentren_min_distance_m\"])\n",
    "gdf.loc[mask_all, \"z_medzentrum_near_500\"]      =  zscore(gdf.loc[mask_all, \"medzentren_count_within_500m\"])\n",
    "gdf.loc[mask_all, \"z_medzentrum_near_800\"]      =  zscore(gdf.loc[mask_all, \"medzentren_count_within_800m\"])\n",
    "gdf.loc[mask_all, \"z_medzentrum_near_1000\"]     =  zscore(gdf.loc[mask_all, \"medzentren_count_within_1000m\"])\n",
    "\n",
    "# Gr√ºnfl√§chen\n",
    "gdf.loc[mask_all, \"z_gruen_distance\"]           = -zscore(gdf.loc[mask_all, \"gruen_min_distance_m\"])\n",
    "gdf.loc[mask_all, \"z_gruen_near_500\"]           =  zscore(gdf.loc[mask_all, \"gruen_count_within_500m\"])\n",
    "gdf.loc[mask_all, \"z_gruen_near_800\"]           =  zscore(gdf.loc[mask_all, \"gruen_count_within_800m\"])\n",
    "gdf.loc[mask_all, \"z_gruen_near_1000\"]          =  zscore(gdf.loc[mask_all, \"gruen_count_within_1000m\"])\n",
    "\n",
    "def safe_z(x):\n",
    "    z = zscore(x)\n",
    "    # Falls Varianz = 0 oder einzelne Werte fehlen:\n",
    "    return np.where(np.isfinite(z), z, 0)\n",
    "\n",
    "# Gewerbe (Industrie) -> weiter weg = gut\n",
    "mask_mm_gewerbe = gdf[\"dist_gross_gewerbe\"].notna()\n",
    "gdf.loc[mask_mm_gewerbe, \"z_dist_gross_gewerbe\"] = zscore(gdf.loc[mask_mm_gewerbe, \"dist_gross_gewerbe\"])\n",
    "\n",
    "# Gruen -> n√§her = gut\n",
    "mask_mm_gruen = gdf[\"dist_gross_gruen\"].notna()\n",
    "gdf.loc[mask_mm_gruen, \"z_dist_gross_gruen\"]    = -zscore(gdf.loc[mask_mm_gruen, \"dist_gross_gruen\"])\n",
    "\n",
    "# Sonstiges (Wasser) -> n√§her = gut\n",
    "mask_mm_sonst = gdf[\"dist_gross_sonstiges\"].notna()\n",
    "gdf.loc[mask_mm_sonst, \"z_dist_gross_sonstiges\"] = -zscore(gdf.loc[mask_mm_sonst, \"dist_gross_sonstiges\"])\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# 3) Score-Dimensionen (alle Summen = 1.0)\n",
    "# ---------------------------------------\n",
    "\n",
    "### 3.1 Zentralit√§t (1 Dimension, Summe = 1.0)\n",
    "mask_mm_central = gdf[\"center_distance_m\"].notna()\n",
    "gdf.loc[mask_mm_central, \"score_zentralitaet\"] = gdf.loc[mask_mm_central, \"z_centrality\"]\n",
    "\n",
    "\n",
    "### 3.2 Versorgung (Summe = 1.0)\n",
    "mask_mm_versorgung = gdf[[\n",
    "    \"einzelhandel_min_distance_m\",\n",
    "    \"einzelhandel_500m_count\",\n",
    "    \"einzelhandel_800m_count\",\n",
    "    \"einzelhandel_1000m_count\",\n",
    "    \"medzentren_min_distance_m\",\n",
    "    \"medzentren_count_within_500m\",\n",
    "    \"medzentren_count_within_800m\",\n",
    "    \"medzentren_count_within_1000m\"\n",
    "]].notna().all(axis=1)\n",
    "\n",
    "gdf.loc[mask_mm_versorgung, \"score_versorgung\"] = (\n",
    "      0.20 * gdf.loc[mask_mm_versorgung, \"z_einzelhandel_distance\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_versorgung, \"z_einzelhandel_near_500\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_versorgung, \"z_einzelhandel_near_800\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_versorgung, \"z_einzelhandel_near_1000\"]\n",
    "    + 0.20 * gdf.loc[mask_mm_versorgung, \"z_medzentrum_distance\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_versorgung, \"z_medzentrum_near_500\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_versorgung, \"z_medzentrum_near_800\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_versorgung, \"z_medzentrum_near_1000\"]\n",
    ")\n",
    "\n",
    "\n",
    "### 3.3 Mobilit√§t (Summe = 1.0)\n",
    "mask_mm_mobilitaet = gdf[[\n",
    "    \"headway_avg\",\n",
    "    \"haltestellen_min_distance_m\",\n",
    "    \"haltestellen_count_within_500m\",\n",
    "    \"haltestellen_count_within_800m\"\n",
    "]].notna().all(axis=1)\n",
    "\n",
    "gdf.loc[mask_mm_mobilitaet, \"score_mobilitaet\"] = (\n",
    "      0.00 * gdf.loc[mask_mm_mobilitaet, \"z_headway_score\"]\n",
    "    + 0.80 * gdf.loc[mask_mm_mobilitaet, \"z_haltestelle_distance\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_mobilitaet, \"z_haltestellen_count_within_500m\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_mobilitaet, \"z_haltestellen_count_within_800m\"]\n",
    ")\n",
    "\n",
    "\n",
    "### 3.4 Bildung (Summe = 1.0)\n",
    "mask_mm_bildung = gdf[[\n",
    "    \"kitas_min_distance_m\",\n",
    "    \"kitas_count_within_500m\",\n",
    "    \"kitas_count_within_800m\",\n",
    "    \"kitas_count_within_1000m\",\n",
    "    \"grundschulen_min_distance_m\",\n",
    "    \"grundschulen_count_within_500m\",\n",
    "    \"grundschulen_count_within_800m\",\n",
    "    \"grundschulen_count_within_1000m\"\n",
    "]].notna().all(axis=1)\n",
    "\n",
    "gdf.loc[mask_mm_bildung, \"score_bildung\"] = (\n",
    "      0.15 * gdf.loc[mask_mm_bildung, \"z_kita_distance\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_bildung, \"z_kita_near_500\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_bildung, \"z_kita_near_800\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_bildung, \"z_kita_near_1000\"]\n",
    "    + 0.15 * gdf.loc[mask_mm_bildung, \"z_grundschulen_distance\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_bildung, \"z_grundschulen_near_500\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_bildung, \"z_grundschulen_near_800\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_bildung, \"z_grundschulen_near_1000\"]\n",
    ")\n",
    "\n",
    "\n",
    "### 3.5 Umwelt (Summe = 1.0)\n",
    "# Umwelt (Summe = 1.0)\n",
    "mask_mm_umwelt = gdf[[\n",
    "    \"gruen_min_distance_m\",\n",
    "    \"gruen_count_within_500m\",\n",
    "    \"gruen_count_within_800m\",\n",
    "    \"gruen_count_within_1000m\",\n",
    "    \"laerm_index_tag\",\n",
    "    \"z_dist_gross_gewerbe\",\n",
    "    \"z_dist_gross_gruen\",\n",
    "    \"z_dist_gross_sonstiges\"\n",
    "]].notna().all(axis=1)\n",
    "\n",
    "gdf.loc[mask_mm_umwelt, \"score_umwelt\"] = (\n",
    "      0.30 * gdf.loc[mask_mm_umwelt, \"z_gruen_distance\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_umwelt, \"z_gruen_near_500\"]\n",
    "    + 0.10 * gdf.loc[mask_mm_umwelt, \"z_gruen_near_800\"]\n",
    "    + 0.05 * gdf.loc[mask_mm_umwelt, \"z_gruen_near_1000\"]\n",
    "    + 0.15 * gdf.loc[mask_mm_umwelt, \"z_laerm_index_tag\"]\n",
    "    + 0.15 * gdf.loc[mask_mm_umwelt, \"z_dist_gross_gewerbe\"]     # Industrie\n",
    "    + 0.10 * gdf.loc[mask_mm_umwelt, \"z_dist_gross_gruen\"]       # Gr√ºn\n",
    "    + 0.05 * gdf.loc[mask_mm_umwelt, \"z_dist_gross_sonstiges\"]   # Wasser\n",
    ")\n",
    "\n",
    "# ---------------------------------------\n",
    "# 4) Gesamt-Score (alle Dimensionen verf√ºgbar)\n",
    "# ---------------------------------------\n",
    "score_all_vars = [\n",
    "    \"score_zentralitaet\",\n",
    "    \"score_bildung\",\n",
    "    \"score_versorgung\",\n",
    "    \"score_umwelt\",\n",
    "    \"score_mobilitaet\"\n",
    "]\n",
    "\n",
    "mask_all_scores = gdf[score_all_vars].notna().all(axis=1)\n",
    "\n",
    "gdf.loc[mask_all_scores, \"score_total\"] = (\n",
    "      0.20 * gdf.loc[mask_all_scores, \"score_zentralitaet\"]\n",
    "    + 0.20 * gdf.loc[mask_all_scores, \"score_bildung\"]\n",
    "    + 0.20 * gdf.loc[mask_all_scores, \"score_versorgung\"]\n",
    "    + 0.20 * gdf.loc[mask_all_scores, \"score_umwelt\"]\n",
    "    + 0.20 * gdf.loc[mask_all_scores, \"score_mobilitaet\"]\n",
    ")\n",
    "\n",
    "print(\"Anzahl g√ºltiger Gesamt-Scores:\", gdf[\"score_total\"].notna().sum())\n"
   ],
   "id": "36111c65c1e0e5b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Validierung\n",
    "\n",
    "Im Folgenden werden die Z-Variablen genutzt, um mittels K-Means-Clustering Wohnlagen zu identifizieren. Zun√§chst wird die optimale Clusteranzahl mittels Elbow-Methode und Silhouetten-Analyse bestimmt. Danach wird das finale K-Means-Modell mit der gew√§hlten Clusteranzahl trainiert und die Wohnlagen den Adressen zugewiesen."
   ],
   "id": "38efad5274a30e01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------\n",
    "# Z-Variablen aus allen Kategorien\n",
    "# ---------------------------------------\n",
    "z_vars = [\n",
    "    # Zentralit√§t\n",
    "    \"z_centrality\",\n",
    "\n",
    "    # Einzelhandel\n",
    "    \"z_einzelhandel_distance\",\n",
    "    \"z_einzelhandel_near_500\",\n",
    "    \"z_einzelhandel_near_800\",\n",
    "    \"z_einzelhandel_near_1000\",\n",
    "\n",
    "    # L√§rm\n",
    "    \"z_laerm_index_tag\",\n",
    "\n",
    "    # Kitas\n",
    "    \"z_kita_distance\",\n",
    "    \"z_kita_near_500\",\n",
    "    \"z_kita_near_800\",\n",
    "    \"z_kita_near_1000\",\n",
    "\n",
    "    # Grundschulen\n",
    "    \"z_grundschulen_distance\",\n",
    "    \"z_grundschulen_near_500\",\n",
    "    \"z_grundschulen_near_800\",\n",
    "    \"z_grundschulen_near_1000\",\n",
    "\n",
    "    # Haltestellen / Headway\n",
    "    \"z_haltestelle_distance\",\n",
    "    \"z_haltestellen_count_within_500m\",\n",
    "    \"z_haltestellen_count_within_800m\",\n",
    "    \"z_headway_score\",\n",
    "\n",
    "    # MedZentren\n",
    "    \"z_medzentrum_distance\",\n",
    "    \"z_medzentrum_near_500\",\n",
    "    \"z_medzentrum_near_800\",\n",
    "    \"z_medzentrum_near_1000\",\n",
    "\n",
    "    # Gr√ºnfl√§chen\n",
    "    \"z_gruen_distance\",\n",
    "    \"z_gruen_near_500\",\n",
    "    \"z_gruen_near_800\",\n",
    "    \"z_gruen_near_1000\",\n",
    "\n",
    "    # Distanzen zu Gro√üfl√§chen\n",
    "    \"z_dist_gross_gewerbe\",\n",
    "    \"z_dist_gross_gruen\",\n",
    "    \"z_dist_gross_sonstiges\",\n",
    "\n",
    "    # Barriere\n",
    "    \"behind_rail_from_center\"\n",
    "]\n",
    "\n",
    "# ---------------------------------------\n",
    "# Validierung\n",
    "# ---------------------------------------\n",
    "missing = [c for c in z_vars if c not in gdf.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Diese Z-Variablen fehlen im gdf: {missing}\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# Datenmatrix: nur vollst√§ndige Zeilen\n",
    "# ---------------------------------------\n",
    "X = gdf[z_vars].dropna().values\n",
    "\n",
    "# ---------------------------------------\n",
    "# Elbow-Methode\n",
    "# ---------------------------------------\n",
    "inertia = []\n",
    "cluster_range = range(2, 20)\n",
    "\n",
    "for k in cluster_range:\n",
    "    model = KMeans(n_clusters=k, random_state=42)\n",
    "    model.fit(X)\n",
    "    inertia.append(model.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(cluster_range, inertia, marker='o')\n",
    "plt.title(\"Elbow-Methode: KMeans-Inertia vs. Clusteranzahl\")\n",
    "plt.xlabel(\"Anzahl Cluster (k)\")\n",
    "plt.ylabel(\"Inertia (Distanz innerhalb der Cluster)\")\n",
    "plt.xticks(cluster_range)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "a25fef9d8bf060c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Silhouetten-Analyse\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouettes = []\n",
    "\n",
    "for k in cluster_range:\n",
    "    model = KMeans(n_clusters=k, random_state=42)\n",
    "    labels = model.fit_predict(X)\n",
    "    score = silhouette_score(X, labels, random_state=42)\n",
    "    silhouettes.append(score)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(cluster_range, silhouettes, marker='o', color=\"green\")\n",
    "plt.title(\"Silhouetten-Score pro Clusteranzahl\")\n",
    "plt.xlabel(\"Anzahl Cluster (k)\")\n",
    "plt.ylabel(\"Durchschn. Silhouetten-Koeffizient\")\n",
    "plt.xticks(cluster_range)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "dd61e3f41e78504d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------\n",
    "# 1) KMeans\n",
    "# ----------------------------\n",
    "X = gdf[z_vars].dropna().values  # vollst√§ndige Zeilen\n",
    "\n",
    "NUMBER_OF_CLUSTERS = 14\n",
    "\n",
    "model = KMeans(n_clusters=NUMBER_OF_CLUSTERS, random_state=42).fit(X)\n",
    "\n",
    "mask_complete = gdf[z_vars].notna().all(axis=1)\n",
    "gdf.loc[mask_complete, \"cluster\"] = model.labels_\n",
    "\n",
    "cluster_centers = pd.DataFrame(model.cluster_centers_, columns=z_vars)\n",
    "cluster_centers.index.name = \"Cluster\"\n",
    "\n",
    "print(cluster_centers.round(2))\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2) PCA (3 Komponenten)\n",
    "# ----------------------------\n",
    "pca3 = PCA(n_components=3, random_state=42)\n",
    "\n",
    "X_pca3 = pca3.fit_transform(X)\n",
    "centers_pca3 = pca3.transform(cluster_centers.to_numpy())\n",
    "\n",
    "print(\"Explained variance ratio (3 PCs):\", pca3.explained_variance_ratio_)\n",
    "\n",
    "\n",
    "# Datenframe f√ºr Punkte\n",
    "df_pca = pd.DataFrame({\n",
    "    \"PC1\": X_pca3[:, 0],\n",
    "    \"PC2\": X_pca3[:, 1],\n",
    "    \"PC3\": X_pca3[:, 2],\n",
    "    \"cluster\": model.labels_\n",
    "})\n",
    "\n",
    "# Datenframe f√ºr Cluster-Zentren\n",
    "df_centers = pd.DataFrame({\n",
    "    \"PC1\": centers_pca3[:, 0],\n",
    "    \"PC2\": centers_pca3[:, 1],\n",
    "    \"PC3\": centers_pca3[:, 2],\n",
    "    \"cluster\": range(NUMBER_OF_CLUSTERS)\n",
    "})\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Interaktive 3D-Plotly-Grafik\n",
    "# ----------------------------\n",
    "colors = px.colors.qualitative.Dark24  # 24 Farben ‚Üí genug Reserve\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Clusterpunkte einzeichnen\n",
    "for cl in sorted(df_pca[\"cluster\"].unique()):\n",
    "    sub = df_pca[df_pca.cluster == cl]\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=sub[\"PC1\"],\n",
    "        y=sub[\"PC2\"],\n",
    "        z=sub[\"PC3\"],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(\n",
    "            size=3.5,\n",
    "            color=colors[cl % len(colors)],\n",
    "            opacity=0.65\n",
    "        ),\n",
    "        name=f\"Cluster {cl}\"\n",
    "    ))\n",
    "\n",
    "# Clusterzentren\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=df_centers[\"PC1\"],\n",
    "    y=df_centers[\"PC2\"],\n",
    "    z=df_centers[\"PC3\"],\n",
    "    mode=\"markers\",\n",
    "    marker=dict(\n",
    "        size=6,\n",
    "        color=\"black\",\n",
    "        symbol=\"x\",\n",
    "        opacity=0.9\n",
    "    ),\n",
    "    name=\"Cluster-Zentren\"\n",
    "))\n",
    "\n",
    "# Layout\n",
    "fig.update_layout(\n",
    "    title=\"Hauptkomponentenprojektion (PCA) ‚Äì KMeans-Cluster\",\n",
    "    scene=dict(\n",
    "        xaxis_title=\"PC1\",\n",
    "        yaxis_title=\"PC2\",\n",
    "        zaxis_title=\"PC3\"\n",
    "    ),\n",
    "    height=750,\n",
    "    legend=dict(itemsizing=\"constant\")\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ],
   "id": "2a3ba24b6de7a923",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "\n",
    "gdf = gdf[gdf[\"lat\"].notna() & gdf[\"lon\"].notna() & gdf[\"cluster\"].notna()]\n",
    "gdf[\"cluster\"] = gdf[\"cluster\"].astype(int)\n",
    "\n",
    "def get_cluster_colors(n_clusters):\n",
    "    cmap = plt.get_cmap(\"tab20\")   # 20 unterscheidbare Farben\n",
    "    colors = {\n",
    "        i: mcolors.to_hex(cmap(i % 20))\n",
    "        for i in range(n_clusters)\n",
    "    }\n",
    "    return colors\n",
    "\n",
    "cluster_colors = get_cluster_colors(NUMBER_OF_CLUSTERS)\n",
    "\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Add layer markers\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/einzelhandel_geocoded.csv\", color=\"blue\", icon=\"shopping-cart\", layer_name=\"Einzelhandel\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/grundschulen_geocoded.csv\", color=\"green\", icon=\"graduation-cap\", layer_name=\"Grundschulen\")\n",
    "add_markers_from_csv(map_obj=m, csv_path=\"out/kitas_geocoded.csv\", color=\"beige\", icon=\"child\", layer_name=\"Kitas\")\n",
    "#add_markers_from_csv(map_obj=m,csv_path=\"out/haltestellen_geocoded.csv\",color=\"lightgray\", icon=\"bus\", layer_name=\"Haltestellen\")\n",
    "\n",
    "valid_kita_json = gdf[\"kitas_route\"].apply(lambda x: isinstance(x, str))\n",
    "print(\"G√ºltige JSON-Eintr√§ge:\", valid_kita_json.sum(), \"/\", len(gdf))\n",
    "\n",
    "for _, r in gdf.iterrows():\n",
    "    c = cluster_colors.get(r.cluster, \"#666666\")\n",
    "    folium.CircleMarker(\n",
    "        location=[r.lat, r.lon],\n",
    "        radius=3,\n",
    "        color=c,\n",
    "        fill=True,\n",
    "        fill_color=c,\n",
    "        fill_opacity=0.85,\n",
    "        tooltip=f\"{r.Stra√üenname} {r.Hsnr} ‚Äì Cluster {r.cluster}\"\n",
    "    ).add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "m"
   ],
   "id": "19db7c7c67edc72a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Nur Spalten verwenden, die im gdf enthalten sind\n",
    "cols = [col for col in z_vars if col in gdf.columns]\n",
    "\n",
    "# Korrelationsmatrix berechnen\n",
    "corr = gdf[cols].corr()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(corr, annot=True, cmap=\"vlag\", center=0)\n",
    "plt.title(\"Korrelationsmatrix der Z-Scores\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "3884a510fe473e01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Die Korrelationsanalyse zeigt, dass einige Variablen stark korreliert sind, z. B. die verschiedenen Distanzen zu Einzelhandelsstandorten und die Anzahl der Standorte in der N√§he. Dies ist zu erwarten, da Adressen, die n√§her an Einzelhandelsstandorten liegen, tendenziell auch mehr Standorte in ihrer Umgebung haben. Gleichzeitig ist die Zentralit√§t erwartungskonform leicht mit der Verf√ºgbarkeit von Nahversorgung (Einkaufsm√∂glichkeiten, medizinische Versorgung, Kitas) korreliert. Diese Erkenntnisse sind Hinweise auf die Plausibilit√§t des Modells, wobei gleichzeitg keine perfekten Korrelationen vorliegen, die auf Redundanzen hindeuten w√ºrden. Alle bisher betrachteten Kriterien scheinen relevante und unterschiedliche Aspekte der Wohnlage zu erfassen.",
   "id": "93a582f2058f2e79"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Interaktive Karte zur Bewertung einzelner Adressen",
   "id": "1495801883de52ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "# Widget f√ºr Adresseingabe\n",
    "text_input = widgets.Text(\n",
    "    value='Haselnussweg 10',\n",
    "    placeholder='Stra√üenname Hausnummer',\n",
    "    description='Adresse:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "button = widgets.Button(description=\"Zeige Routen\")\n",
    "output = widgets.Output()\n",
    "\n",
    "# Hilfsfunktion\n",
    "def load_geojson(geo):\n",
    "    \"\"\"Konvertiert GeoJSON-Felder sicher in ein Python-Dict.\"\"\"\n",
    "    if geo is None:\n",
    "        return None\n",
    "    if isinstance(geo, float):  # NaN\n",
    "        return None\n",
    "    if isinstance(geo, dict):   # bereits dict\n",
    "        return geo\n",
    "    if isinstance(geo, str) and geo.strip() == \"\":\n",
    "        return None\n",
    "    if isinstance(geo, str):\n",
    "        try:\n",
    "            return json.loads(geo)\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def scale_score(z):\n",
    "    \"\"\"Skaliert Z-Score linear auf 0 - 10 (f√ºr B√ºrgerverst√§ndlichkeit).\"\"\"\n",
    "    if pd.isna(z):\n",
    "        return None\n",
    "    score = (z + 3) / 6 * 10\n",
    "    return max(0, min(10, round(score, 2)))\n",
    "\n",
    "gdf[\"score_total_scaled\"]        = gdf[\"score_total\"].apply(scale_score)\n",
    "gdf[\"score_zentralitaet_scaled\"] = gdf[\"score_zentralitaet\"].apply(scale_score)\n",
    "gdf[\"score_versorgung_scaled\"]   = gdf[\"score_versorgung\"].apply(scale_score)\n",
    "gdf[\"score_bildung_scaled\"]      = gdf[\"score_bildung\"].apply(scale_score)\n",
    "gdf[\"score_mobilitaet_scaled\"]   = gdf[\"score_mobilitaet\"].apply(scale_score)\n",
    "gdf[\"score_umwelt_scaled\"]       = gdf[\"score_umwelt\"].apply(scale_score)\n",
    "\n",
    "def score_color(value):\n",
    "    if value is None:\n",
    "        return \"gray\"\n",
    "    if value >= 8:\n",
    "        return \"#2ecc71\"   # gr√ºn\n",
    "    if value >= 5:\n",
    "        return \"#f1c40f\"   # gelb\n",
    "    return \"#e74c3c\"        # rot\n",
    "\n",
    "# Funktion zum Einf√ºgen einer Route + Zielmarker\n",
    "def add_route(m, geojson_raw, color, label, icon, distance=None):\n",
    "    geo = load_geojson(geojson_raw)\n",
    "    if not geo:\n",
    "        return  # keine Route vorhanden\n",
    "\n",
    "    if geo.get(\"type\") == \"LineString\":\n",
    "        try:\n",
    "            coords = [(y, x) for x, y in geo[\"coordinates\"]]\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Lesen der Koordinaten f√ºr {label}: {e}\")\n",
    "            return\n",
    "\n",
    "        distance_text = f\" ‚Äì {int(distance)} m\" if distance else \"\"\n",
    "        tooltip_text = f\"{label}{distance_text}\"\n",
    "\n",
    "        folium.PolyLine(\n",
    "            locations=coords,\n",
    "            color=color,\n",
    "            weight=4,\n",
    "            opacity=0.9,\n",
    "            tooltip=tooltip_text\n",
    "        ).add_to(m)\n",
    "\n",
    "        # Zielpunkt markieren\n",
    "        end = coords[-1]\n",
    "        folium.Marker(\n",
    "            location=end,\n",
    "            icon=folium.Icon(color=color, icon=icon, prefix=\"fa\"),\n",
    "            tooltip=f\"Ziel: {label}{distance_text}\"\n",
    "        ).add_to(m)\n",
    "\n",
    "# Funktion zum Anzeigen der Karte\n",
    "def show_routes(_=None):\n",
    "    output.clear_output(wait=True)\n",
    "    with output:\n",
    "        addr = text_input.value.strip().lower()\n",
    "\n",
    "        filtered = gdf[gdf[\"Adresse_merge\"].str.lower().str.contains(addr)]\n",
    "        if filtered.empty:\n",
    "            print(\"Keine passende Adresse gefunden.\")\n",
    "            return\n",
    "\n",
    "        row = filtered.iloc[0]\n",
    "\n",
    "        m = folium.Map(\n",
    "            tiles=\"cartodbpositron\",\n",
    "            location=CITY_CENTER,\n",
    "            zoom_start=12,\n",
    "        )\n",
    "\n",
    "        # Farbige Score-Badges\n",
    "        def badge(label, val):\n",
    "            col = score_color(val)\n",
    "            return f\"<div style='padding:4px 8px;margin:2px;background:{col};color:white;border-radius:4px;display:inline-block;'>{label}: {val}</div>\"\n",
    "\n",
    "        popup_html = f\"\"\"\n",
    "        <div style=\"width:420px;font-family:Arial, sans-serif;\">\n",
    "          <h2>{row['Stra√üenname']} {row['Hsnr']}</h2>\n",
    "\n",
    "          <h3>Gesamtbewertung</h3>\n",
    "          {badge(\"Gesamt\", row.get('score_total_scaled'))}\n",
    "\n",
    "          <h3>Teilbereiche</h3>\n",
    "          {badge(\"Zentralit√§t\", row.get('score_zentralitaet_scaled'))}\n",
    "          {badge(\"Versorgung\", row.get('score_versorgung_scaled'))}\n",
    "          {badge(\"Bildung\", row.get('score_bildung_scaled'))}\n",
    "          {badge(\"Mobilit√§t\", row.get('score_mobilitaet_scaled'))}\n",
    "          {badge(\"Umwelt\", row.get('score_umwelt_scaled'))}\n",
    "\n",
    "\n",
    "          <h3 style=\"margin-top:15px;\">Basisdaten</h3>\n",
    "          <ul>\n",
    "            <li><b>Entfernung Zentrum:</b> {int(row.get(\"center_distance_m\",0))} m</li>\n",
    "            <li><b>L√§rmindex (Tag):</b> {row.get(\"laerm_index_tag\",'‚Äì')}</li>\n",
    "            <li><b>N√§chste Haltestelle:</b> {int(row.get(\"haltestellen_min_distance_m\",0))} m</li>\n",
    "            <li><b>Durchschnittlicher Takt:</b> {row.get(\"headway_avg\",'‚Äì')} min</li>\n",
    "            <li><b>N√§chster Einzelhandel:</b> {int(row.get(\"einzelhandel_min_distance_m\",0))} m</li>\n",
    "            <li><b>N√§chste Kita:</b> {int(row.get(\"kitas_min_distance_m\",0))} m</li>\n",
    "            <li><b>N√§chste Grundschule:</b> {int(row.get(\"grundschulen_min_distance_m\",0))} m</li>\n",
    "            <li><b>Med. Zentrum:</b> {int(row.get(\"medzentren_min_distance_m\",0))} m</li>\n",
    "            <li><b>Gr√ºnfl√§che:</b> {int(row.get(\"gruen_min_distance_m\",0))} m</li>\n",
    "          </ul>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "        popup = folium.Popup(popup_html, max_width=450)\n",
    "\n",
    "        marker = folium.Marker(\n",
    "            location=[row.lat, row.lon],\n",
    "            popup=popup,\n",
    "            icon=folium.Icon(color=\"blue\", icon=\"info-sign\")\n",
    "        ).add_to(m)\n",
    "\n",
    "        # Popup automatisch √∂ffnen\n",
    "        marker.add_child(folium.Popup(popup_html, max_width=450))\n",
    "        marker.add_child(folium.map.Tooltip(\"\"))  # kein Tooltip\n",
    "\n",
    "        # Popup sofort anzeigen\n",
    "        marker._popup = popup\n",
    "\n",
    "        # Startmarker\n",
    "        folium.Marker(\n",
    "            location=[row.lat, row.lon],\n",
    "            popup=popup_html,\n",
    "        ).add_to(m)\n",
    "\n",
    "        # ‚ñ∏ Routen einf√ºgen\n",
    "        add_route(m, row.get(\"center_route\"), \"lightgray\", \"Weg zum Zentrum\", \"arrows-to-circle\", row.get(\"center_distance_m\"))\n",
    "        add_route(m, row.get(\"kitas_route\"), \"cadetblue\", \"N√§chste Kita\", \"child\", row.get(\"kitas_min_distance_m\"))\n",
    "        add_route(m, row.get(\"grundschulen_route\"), \"cadetblue\", \"N√§chste Grundschule\", \"graduation-cap\", row.get(\"grundschulen_min_distance_m\"))\n",
    "        add_route(m, row.get(\"haltestellen_route\"), \"beige\", \"N√§chste Haltestelle\", \"bus\", row.get(\"haltestellen_min_distance_m\"))\n",
    "        add_route(m, row.get(\"medzentren_route\"), \"red\", \"N√§chstes Medizinisches Zentrum\", \"staff-snake\", row.get(\"medzentren_min_distance_m\"))\n",
    "        add_route(m, row.get(\"einzelhandel_route\"), \"purple\", \"N√§chster Einzelhandel\", \"shop\", row.get(\"einzelhandel_min_distance_m\"))\n",
    "        add_route(m, row.get(\"gruen_route\"), \"darkgreen\", \"N√§chste Freizeit- und Erholungsfl√§che\", \"tree\", row.get(\"gruen_min_distance_m\"))\n",
    "\n",
    "        display(m)\n",
    "\n",
    "# Button-Event\n",
    "button.on_click(show_routes)\n",
    "\n",
    "# UI anzeigen\n",
    "display(text_input, button, output)"
   ],
   "id": "1505678dc5e76d43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# R√§umliches Clustering\n",
    "Ein Ziel der Analyse ist die Entwicklung zusammenh√§ngender Gebiete, die einer gemeinsamen Wohnlage zugeordnet werden k√∂nnen. Damit sollen \"Insellagen\", also mehrere abgeschnittene Bereiche mit derselben Wohnlage vermieden werden. Daf√ºr wenden wir im Folgenden eine Gl√§ttung mit dem SKATER-Ansatz an (vgl. [Assun√ß√£o et al. 2006](https://www.tandfonline.com/doi/abs/10.1080/13658810600665111]))."
   ],
   "id": "e06cb92a06290d6b"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from libpysal import weights\n",
    "from spopt.region import Skater\n",
    "\n",
    "# Metrische Projektion f√ºr korrekte Berechnung\n",
    "gdf = gdf.to_crs(epsg=32633)\n",
    "\n",
    "# Schritt 1: Erzeuge Gewichtsmatrix f√ºr SKATER mit Queen-Kontiguit√§t\n",
    "W = weights.contiguity.Queen.from_dataframe(gdf, use_index=True)\n",
    "\n",
    "# Schritt 2: W√§hle Attribute f√ºr SKATER\n",
    "# Keine Routen-Variablen\n",
    "score_vars = [var for var in score_vars if not var.endswith(\"_route\")]\n",
    "\n",
    "# Keine Zentrumsdistanz, um konzentrische Cluster zu vermeiden\n",
    "if \"center_distance_m\" in score_vars:\n",
    "    score_vars.remove(\"center_distance_m\")\n",
    "\n",
    "# Auswahl der Variablen basierend auf Korrelationsanalyse und inhaltlicher Relevanz\n",
    "attrs = [\n",
    "    # Lage\n",
    "    \"z_centrality\",\n",
    "    \"z_laerm_index_tag\",\n",
    "\n",
    "    # Gr√ºn/Wasser\n",
    "    \"z_gruen_distance\",\n",
    "    \"z_dist_gross_gruen\",\n",
    "    \"z_dist_gross_sonstiges\",\n",
    "\n",
    "    # √ñPNV\n",
    "    \"z_haltestelle_distance\",\n",
    "    \"z_headway_score\",\n",
    "\n",
    "    # Bildung\n",
    "    \"z_kita_distance\",\n",
    "    \"z_grundschulen_distance\",\n",
    "\n",
    "    # Versorgung\n",
    "    \"z_medzentrum_distance\",\n",
    "    \"z_einzelhandel_distance\",\n",
    "\n",
    "    # Industrie (negativ)\n",
    "    \"z_dist_gross_gewerbe\",\n",
    "\n",
    "    # Barriere\n",
    "    \"behind_rail_from_center\",\n",
    "\n",
    "    # Nutzungsklassen (weiche Struktur)\n",
    "    \"nutz_Wohnen\",\n",
    "    \"nutz_Gruen\",\n",
    "    \"nutz_Gemischt\",\n",
    "    \"nutz_Gewerbe\",\n",
    "    \"nutz_Verkehr\",\n",
    "]\n",
    "\n",
    "# Schritt 3: SKATER ausf√ºhren\n",
    "sk = Skater(\n",
    "    gdf, W, attrs,\n",
    "    n_clusters=NUMBER_OF_CLUSTERS,\n",
    "    islands = \"increase\",\n",
    ")\n",
    "sk.solve()\n",
    "\n",
    "gdf[\"cluster_skater\"] = sk.labels_"
   ],
   "id": "99063ccb0de835ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd, folium\n",
    "\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"cartodbpositron\")\n",
    "cluster_colors = get_cluster_colors(NUMBER_OF_CLUSTERS)\n",
    "\n",
    "for _, r in gdf.iterrows():\n",
    "    c = cluster_colors.get(r.cluster_skater, \"#666666\")\n",
    "    folium.CircleMarker(\n",
    "        location=[r.lat, r.lon],\n",
    "        radius=3,\n",
    "        color=c,\n",
    "        fill=True,\n",
    "        fill_color=c,\n",
    "        fill_opacity=0.85,\n",
    "        tooltip=f\"{r.Stra√üenname} {r.Hsnr} ‚Äì Cluster {r.cluster_skater}\"\n",
    "    ).add_to(m)\n",
    "\n",
    "m"
   ],
   "id": "37bb9529b5b0103a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Lageklassen\n",
    "Abschlie√üend werden die Adressen basierend auf ihrem Gesamt-Score in Lageklassen eingeteilt."
   ],
   "id": "384123854336c785"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def classify_lage_5(score_series):\n",
    "    \"\"\"\n",
    "    5 Klassen: A‚ÄìE, basierend auf Quintilen\n",
    "    \"\"\"\n",
    "    q20 = score_series.quantile(0.20)\n",
    "    q40 = score_series.quantile(0.40)\n",
    "    q60 = score_series.quantile(0.60)\n",
    "    q80 = score_series.quantile(0.80)\n",
    "\n",
    "    def classify(x):\n",
    "        if pd.isna(x):\n",
    "            return None\n",
    "        if x >= q80:\n",
    "            return \"A ‚Äì H√∂chstlage\"\n",
    "        elif x >= q60:\n",
    "            return \"B ‚Äì Sehr gute Lage\"\n",
    "        elif x >= q40:\n",
    "            return \"C ‚Äì Gute Lage\"\n",
    "        elif x >= q20:\n",
    "            return \"D ‚Äì Mittlere Lage\"\n",
    "        else:\n",
    "            return \"E ‚Äì Einfache Lage\"\n",
    "\n",
    "    return score_series.apply(classify)\n",
    "\n",
    "# Anwendung:\n",
    "gdf[\"lageklasse_5\"] = classify_lage_5(gdf[\"score_total\"])\n",
    "\n",
    "# Farben f√ºr Wohnlagen (gr√ºn - gelb)\n",
    "color_map = {\n",
    "    \"A ‚Äì H√∂chstlage\":             \"#1a9850\",\n",
    "    \"B ‚Äì Sehr gute Lage\":         \"#66bd63\",\n",
    "    \"C ‚Äì Gute Lage\":              \"#a6d96a\",\n",
    "    \"D ‚Äì Mittlere Lage\":          \"#d9ef8b\",\n",
    "    \"E ‚Äì Einfache Lage\":          \"#fee08b\",\n",
    "}\n",
    "\n",
    "# Kartendarstellung\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=13, tiles=\"cartodbpositron\")\n",
    "for _, r in gdf.iterrows():\n",
    "    color = color_map.get(r.lageklasse_5, \"lightgray\")\n",
    "    folium.CircleMarker(\n",
    "        location=[r.lat, r.lon],\n",
    "        radius=3,\n",
    "        color=color,\n",
    "        fill=True,\n",
    "        fill_color=color,\n",
    "        fill_opacity=0.85,\n",
    "        tooltip=f\"{r.Stra√üenname} {r.Hsnr} ‚Äì Lageklasse: {r.lageklasse_5}\"\n",
    "    ).add_to(m)\n",
    "# Optional: Layer Control\n",
    "folium.LayerControl().add_to(m)\n",
    "m"
   ],
   "id": "f7d880c3117a24a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Abgleich mit Ortsteilen, Quartieren und Mietkategorien\n",
    "Zum Abgleich der ermittelten Wohnlagen mit bestehenden Strukturen werden die Cluster mit den Quartieren und Ortsteilen der Adressen sowie den Mietkategorien (sofern vorhanden) verglichen. In der Kreuztabelle k√∂nnen die Verteilungen der Cluster √ºber die verschiedenen r√§umlichen Einheiten analysiert werden."
   ],
   "id": "b6194bac21991433"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Ortsteile erg√§nzen",
   "id": "12be6a23f0356a20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "\n",
    "# Datei laden\n",
    "with open(\"data/ortsteile_brandenburg.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "# FeatureCollection extrahieren\n",
    "features = raw[\"features\"]\n",
    "gdf_ortsteile = gpd.GeoDataFrame.from_features(features)\n",
    "gdf_ortsteile.set_crs(EPSG_4326, inplace=True)\n",
    "gdf_ortsteile = gdf_ortsteile.clip(CITY_BOUNDING_BOX)\n",
    "\n",
    "# Karte zentrieren\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=12, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Tooltip konfigurieren\n",
    "tooltip_fields = [\"otl_name\"]\n",
    "\n",
    "# GeoJSON mit Tooltip zur Karte hinzuf√ºgen\n",
    "folium.GeoJson(\n",
    "    gdf_ortsteile,\n",
    "    name=\"Ortsteile\",\n",
    "    tooltip=folium.GeoJsonTooltip(\n",
    "    fields=tooltip_fields,\n",
    "    aliases=[\"Ortsteil\"],\n",
    "    localize=True,\n",
    "    sticky=True\n",
    ")\n",
    ").add_to(m)\n",
    "\n",
    "gdf = gdf.to_crs(EPSG_4326)\n",
    "gdf_ortsteile = gdf_ortsteile.to_crs(EPSG_4326)\n",
    "\n",
    "assert gdf.crs.to_epsg() == 4326\n",
    "assert gdf_ortsteile.crs.to_epsg() == 4326\n",
    "\n",
    "gdf = clean_index_cols(gdf)\n",
    "gdf = gpd.sjoin(gdf, gdf_ortsteile[[\"geometry\", \"otl_name\"]], how=\"left\", predicate=\"within\")\n",
    "gdf = gdf.rename(columns={\"otl_name\": \"ortsteil\"})\n",
    "gdf = gdf.drop(columns=[\"index_right\"], errors=\"ignore\")\n",
    "\n",
    "# Drop rows with NaN lat/lon\n",
    "gdf = gdf.dropna(subset=[\"lat\"])\n",
    "\n",
    "# Karte anzeigen\n",
    "m"
   ],
   "id": "26ee59f7db25614e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Wohnquartiere erg√§nzen\n",
    "Innerhalb des Stadtgebiets liegen verschiedene Wohnquartiere mit unterschiedlichen Merkmalen. Diese werden den Adressen zugeordnet und zusammen mit den Wohnbezirken visualisiert."
   ],
   "id": "aab87e4f1fa7b642"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "\n",
    "# Geopackage aus Datei laden\n",
    "gdf_quartiere = gpd.read_file(\"data/Quartiere/2024_Quartiere.gpkg\")\n",
    "\n",
    "# Karte zentrieren\n",
    "m = folium.Map(location=CITY_CENTER, zoom_start=12, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Ortsteile hinzuf√ºgen (s.o.)\n",
    "tooltip_fields = [\"otl_name\"]\n",
    "folium.GeoJson(\n",
    "    gdf_ortsteile,\n",
    "    name=\"Ortsteile\",\n",
    "    tooltip=folium.GeoJsonTooltip(\n",
    "    fields=tooltip_fields,\n",
    "    aliases=[\"Ortsteil\"],\n",
    "    localize=True,\n",
    "    sticky=True\n",
    ")\n",
    ").add_to(m)\n",
    "\n",
    "# Tooltip konfigurieren\n",
    "tooltip_fields = [\"bezeichnun\", \"mietkatego\"]\n",
    "tooltip = folium.GeoJsonTooltip(\n",
    "    fields=tooltip_fields,\n",
    "    aliases=[\"Quartier\", \"Mietkategorie\"],\n",
    "    localize=True,\n",
    "    sticky=True\n",
    ")\n",
    "\n",
    "# GeoJSON mit Tooltip zur Karte hinzuf√ºgen als orangefarbener Layer\n",
    "folium.GeoJson(\n",
    "    gdf_quartiere,\n",
    "        style_function=lambda feature: {\n",
    "            'fillColor': 'orange',\n",
    "            'color': 'orange',\n",
    "            'weight': 1,\n",
    "            'fillOpacity': 0.2,\n",
    "        },\n",
    "    name=\"Ortsteile\",\n",
    "    tooltip=tooltip\n",
    ").add_to(m)\n",
    "\n",
    "# CRS angleichen (WGS84)\n",
    "gdf_quartiere = gdf_quartiere.to_crs(4326)\n",
    "gdf = gdf.to_crs(4326)\n",
    "assert gdf.crs.to_epsg() == 4326\n",
    "assert gdf_quartiere.crs.to_epsg() == 4326\n",
    "\n",
    "# alte Spalten sicher entfernen\n",
    "gdf = gdf.drop(columns=[\"index_right\", \"mietkatego\", \"bezeichnun\"], errors=\"ignore\")\n",
    "# Fr√ºhere Merge-Spalten entfernen (endet auf _quartier)\n",
    "cols_to_drop = [col for col in gdf.columns if col.endswith(\"_quartier\")]\n",
    "gdf = gdf.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "# sauberes Spatial Join\n",
    "gdf = gpd.sjoin(\n",
    "    gdf,\n",
    "    gdf_quartiere[[\"bezeichnun\", \"mietkatego\", \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    predicate=\"within\",\n",
    ")\n",
    "\n",
    "# Merkmale benennen\n",
    "gdf = gdf.rename(columns={\n",
    "    \"bezeichnun\": \"quartier\",\n",
    "    \"mietkatego\": \"mietkategorie\"\n",
    "})\n",
    "\n",
    "# Karte anzeigen\n",
    "m"
   ],
   "id": "989267310711fa5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Kreuztabelle\n",
    "Innerhalb des Stadtgebiets liegen verschiedene Wohnquartiere mit unterschiedlichen Merkmalen. Diese werden den Adressen zugeordnet und zusammen mit den Wohnbezirken visualisiert.\n"
   ],
   "id": "8c3b97a7c5b43ca7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ct = pd.crosstab(gdf[\"quartier\"], gdf[\"cluster_skater\"], normalize=\"index\")\n",
    "plt.figure(figsize=(14,10))\n",
    "sns.heatmap(ct, cmap=\"viridis\", annot=False)\n",
    "plt.title(\"Quartier vs. SKATER-Cluster (Zeilen normalize: Anteil pro Quartier)\")\n",
    "plt.xlabel(\"SKATER-Cluster\")\n",
    "plt.ylabel(\"Quartier\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "c1c20c5935a39a9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Die Darstellung zeigt, wie sich die automatisch gebildeten SKATER-Cluster auf die bestehenden Wohnquartiere verteilen. Deutlich wird, dass mehrere Quartiere eine klare Dominanz einzelner Cluster aufweisen (z. B. Zentrum, Nord, G√∂rden oder Hohenst√ºcken), was auf eine vergleichsweise homogene interne Struktur schlie√üen l√§sst. Andere Quartiere, insbesondere jene mit gemischten Nutzungen oder gro√üen r√§umlichen Ausdehnungen, verteilen sich st√§rker auf mehrere Cluster. Diese Heterogenit√§t ist erwartbar und spiegelt eher die interne Vielfalt der Quartiere wider als Schw√§chen im Clustering. Insgesamt zeigt die Heatmap, dass die Clusterbildung bestehende r√§umliche Zusammenh√§nge gut trifft.",
   "id": "c598f2340d709d0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ct = pd.crosstab(gdf[\"ortsteil\"], gdf[\"cluster_skater\"], normalize=\"index\")\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(ct, cmap=\"magma\", annot=False)\n",
    "plt.title(\"Ortsteil vs. SKATER-Cluster\")\n",
    "plt.xlabel(\"SKATER-Cluster\")\n",
    "plt.ylabel(\"Ortsteil\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "4a6e1ed31d9df962",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Die Zuordnung der SKATER-Cluster zu den Ortsteilen zeigt √ºberwiegend klare Muster. Viele Ortsteile werden √ºberwiegend einem oder zwei Clustern zugeordnet, was auf eine konsistente und funktional nachvollziehbare Lagecharakteristik schlie√üen l√§sst. Dies ist besonders bei peripheren oder d√∂rflichen Ortsteilen sichtbar, die sich typischerweise durch √§hnliche Infrastrukturausstattung und Distanzlagen auszeichnen. Gleichzeitig treten - abh√§ngig von Gr√∂√üe und Struktur des Ortsteils ‚Äì einzelne Streuungen auf, die auf interne Unterschiede oder √úbergangsbereiche hindeuten k√∂nnen. Insgesamt best√§tigt die Darstellung, dass die Cluster auch au√üerhalb des Kernstadtgebiets sinnvolle, zusammenh√§ngende Lagemuster abbilden.",
   "id": "1e25aeb4bf491452"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ct = pd.crosstab(gdf[\"mietkategorie\"], gdf[\"cluster_skater\"], normalize=\"columns\")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(ct, cmap=\"coolwarm\", annot=True, fmt=\".2f\")\n",
    "plt.title(\"Mietkategorie vs. SKATER-Cluster (Spalten normalize)\")\n",
    "plt.xlabel(\"SKATER-Cluster\")\n",
    "plt.ylabel(\"Mietkategorie\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "895529dbe50c2b6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Die Kreuztabelle zwischen Mietkategorien und SKATER-Clustern dient der √∂konomischen Validierung des Modells. Hier zeigt sich, dass bestimmte Cluster deutlich mit niedrigeren, mittleren oder h√∂heren Mietkategorien assoziiert sind. Mehrere Cluster weisen eine hohe √úbereinstimmung mit spezifischen Mietniveaus auf, was darauf hinweist, dass die algorithmisch erkannten Lagegruppen auch sozio√∂konomische Unterschiede in der Wohnlagequalit√§t widerspiegeln. Streuungen in einzelnen Kategorien sind zu erwarten und spiegeln nat√ºrliche √úberg√§nge oder heterogene Stra√üenz√ºge wider. Insgesamt deutet die Struktur jedoch auf eine plausibel differenzierende Wirkung der Cluster hin.",
   "id": "2f060d1b7ee1eac5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Alle relevanten Z-Variablen f√ºr die Clusterinterpretation\n",
    "z_vars = [col for col in gdf.columns if col.startswith(\"z_\")]\n",
    "\n",
    "cluster_profile = gdf.groupby(\"cluster_skater\")[z_vars].mean()\n",
    "\n",
    "plt.figure(figsize=(18,10))\n",
    "sns.heatmap(cluster_profile, cmap=\"coolwarm\", center=0, annot=False)\n",
    "plt.title(\"Feature-Profil der SKATER-Cluster (alle Z-Scores)\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Cluster\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "afa697c7c36a17d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Export-Pipeline",
   "id": "d630ac1d11f4b4f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save GeoDataFrame with scores and clusters as CSV\n",
    "import os\n",
    "\n",
    "# -------------------------------------------\n",
    "# 0) EXPORT-PFAD\n",
    "# -------------------------------------------\n",
    "EXPORT_PATH = \"out\"\n",
    "EXPORT_FILE = os.path.join(EXPORT_PATH, \"wohnlagen_brb.gpkg\")\n",
    "\n",
    "# Ordner anlegen\n",
    "os.makedirs(EXPORT_PATH, exist_ok=True)\n",
    "\n",
    "# Falls alte Datei existiert: l√∂schen (sonst doppelte Layer)\n",
    "if os.path.exists(EXPORT_FILE):\n",
    "    os.remove(EXPORT_FILE)\n",
    "    print(f\"Alte Datei gel√∂scht: {EXPORT_FILE}\")\n",
    "\n",
    "# -------------------------------------------\n",
    "# 1) HILFSFUNKTION: Sicheres Schreiben\n",
    "# -------------------------------------------\n",
    "\n",
    "def write_layer(gdf, layer_name, crs=EPSG_4326):\n",
    "    \"\"\"\n",
    "    Schreibt einen GeoDataFrame als Layer in die GeoPackage-Datei.\n",
    "    Stellt sicher, dass das CRS korrekt ist.\n",
    "    \"\"\"\n",
    "    if gdf is None or len(gdf) == 0:\n",
    "        print(f\"‚ö† Layer '{layer_name}' √ºbersprungen: leer oder None\")\n",
    "        return\n",
    "\n",
    "    # CRS pr√ºfen\n",
    "    if gdf.crs is None:\n",
    "        print(f\"‚ö† GDF '{layer_name}' hat kein CRS ‚Äì setze auf {crs}\")\n",
    "        gdf = gdf.set_crs(crs)\n",
    "    elif gdf.crs.to_string() != crs:\n",
    "        print(f\"üîÑ Reprojiziere '{layer_name}' nach {crs}\")\n",
    "        gdf = gdf.to_crs(crs)\n",
    "\n",
    "    # Schreiben\n",
    "    gdf.to_file(EXPORT_FILE, layer=layer_name, driver=\"GPKG\")\n",
    "    print(f\"‚úî Exportiert: {layer_name}  ‚Üí  {EXPORT_FILE}\")\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# 2) LAYER DEFINIEREN\n",
    "# -------------------------------------------\n",
    "layers = {\n",
    "    \"wohnadressen\": gdf,\n",
    "    \"wohnlagen_score\": gdf[[col for col in gdf.columns if col.startswith(\"score_\") or col in [\"geometry\"]]],\n",
    "    \"cluster_skater\": gdf[[\"cluster_skater\", \"geometry\"]] if \"cluster_skater\" in gdf.columns else None,\n",
    "    \"cluster_kmeans\": gdf[[\"cluster\", \"geometry\"]] if \"cluster\" in gdf.columns else None,\n",
    "    \"lageklassen\": gdf[[\"lageklasse\", \"score_total\", \"geometry\"]] if \"lageklasse\" in gdf.columns else None,\n",
    "\n",
    "    # Infrastruktur-Daten\n",
    "    \"bahnlinien\": rails,\n",
    "    \"gruenflaechen\": gdf_gruen_shape,\n",
    "    #\"laerm_lden\": gdf_laerm,                      # falls du gdf_laerm hei√üt\n",
    "    \"haltestellen\": gdf_haltestellen if 'gdf_haltestellen' in globals() else None,\n",
    "    #\"medzentren\": gdf_medzentren if 'gdf_medzentren' in globals() else None,\n",
    "    \"kitas\": gdf_kitas if 'gdf_kitas' in globals() else None,\n",
    "    \"grundschulen\": gdf_grundschulen if 'gdf_grundschulen' in globals() else None,\n",
    "    #\"einzelhandel\": gdf_einzelhandel if 'gdf_einzelhandel' in globals() else None,\n",
    "\n",
    "    # Debug-Daten\n",
    "    \"bahnschnitt_debug\": gdf[[\"behind_rail_from_center\", \"center_route\", \"geometry\"]] if \"behind_rail_from_center\" in gdf.columns else None,\n",
    "}\n",
    "\n",
    "# -------------------------------------------\n",
    "# 3) EXPORT AUSF√úHREN\n",
    "# -------------------------------------------\n",
    "\n",
    "print(\"üîÅ Exportiere alle Layer ‚Ä¶\\n\")\n",
    "\n",
    "for layer_name, layer_gdf in layers.items():\n",
    "    write_layer(layer_gdf, layer_name)\n",
    "\n",
    "print(\"\\nüéâ Fertig! Die GeoPackage-Datei liegt hier:\")\n",
    "print(f\"üì¶ {EXPORT_FILE}\")\n"
   ],
   "id": "4856ef3797db369e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WohnlagenBRB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
